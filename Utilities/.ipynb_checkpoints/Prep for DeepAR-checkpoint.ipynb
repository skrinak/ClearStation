{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !conda install -c anaconda pandas-datareader -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/skrinak/miniconda3/envs/sagemaker/lib/python3.7/site-packages/pandas_datareader/compat/__init__.py:7: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  from pandas.util.testing import assert_frame_equal\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import boto3\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "import pandas_datareader.data as web\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_job_name = 'sparkSummitDemo'\n",
    "start_date = '2014-01-01'\n",
    "end_date = '2016-01-01'\n",
    "\n",
    "start_date_full = start_date + ' 00:00:00'\n",
    "end_date_full = end_date + ' 00:00:00'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session = sagemaker.Session()\n",
    "s3_bucket = '2021-demos'\n",
    "s3_prefix = 'sparkSummit'\n",
    "\n",
    "# role = sagemaker.get_execution_role()\n",
    "# role = \"your-sagemaker-role-arn\"\n",
    "role = 'arn:aws:iam::921212210452:role/service-role/AmazonSageMaker-ExecutionRole-20191122T164449'\n",
    "\n",
    "region = sagemaker_session.boto_region_name\n",
    "\n",
    "s3_data_path = \"s3://{}/{}/data\".format(s3_bucket, s3_prefix)\n",
    "s3_output_path = \"s3://{}/{}/output\".format(s3_bucket, s3_prefix)\n",
    "\n",
    "image_name = sagemaker.amazon.amazon_estimator.get_image_uri(region, \"forecasting-deepar\", \"latest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol  = web.DataReader('SPY', data_source = 'yahoo', start=start_date, end=end_date)\n",
    "symbol0 = web.DataReader('AMZN', data_source = 'yahoo', start=start_date, end=end_date)\n",
    "symbol1 = web.DataReader('GOOG', data_source = 'yahoo', start=start_date, end=end_date)\n",
    "symbol2 = web.DataReader('AAPL', data_source = 'yahoo', start=start_date, end=end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_rows = round(symbol.shape[0]*.8)\n",
    "test_rows = symbol.shape[0] - training_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "training_data = [\n",
    "    {\n",
    "        \"start\": start_date_full,\n",
    "        \"target\": symbol[:training_rows].Close.tolist()  # We use -1, because pandas indexing includes the upper bound \n",
    "    }\n",
    "    for ts in symbol\n",
    "]\n",
    "print(len(training_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "test_data = [\n",
    "    {\n",
    "        \"start\": start_date_full,\n",
    "        \"target\": symbol[:test_rows].Close.tolist()  # We use -1, because pandas indexing includes the upper bound \n",
    "    }\n",
    "    for ts in symbol\n",
    "]\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_dicts_to_file(path, data):\n",
    "    with open(path, 'wb') as fp:\n",
    "        for d in data:\n",
    "            fp.write(json.dumps(d).encode(\"utf-8\"))\n",
    "            fp.write(\"\\n\".encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_dicts_to_file(\"train.json\", training_data)\n",
    "write_dicts_to_file(\"test.json\", test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded file to s3.Object(bucket_name='2021-demos', key='sparkSummit/data/train/train.json')\n",
      "Uploaded file to s3.Object(bucket_name='2021-demos', key='sparkSummit/data/test/test.json')\n"
     ]
    }
   ],
   "source": [
    "s3 = boto3.resource('s3')\n",
    "bucket = s3.Bucket(s3_bucket)\n",
    "\n",
    "for dataset in ['train', 'test']:\n",
    "    filename = dataset + '.json'\n",
    "    with open(filename, 'rb') as data:\n",
    "        key = s3_prefix + '/data/' + dataset + '/' + filename\n",
    "        result = bucket.put_object(Key=key, Body=data)\n",
    "        print('Uploaded file to {}'.format(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = sagemaker.estimator.Estimator(\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    image_name=image_name,\n",
    "    role=role,\n",
    "    train_instance_count=1,\n",
    "    train_instance_type='ml.c4.2xlarge',\n",
    "    base_job_name=base_job_name,\n",
    "    output_path=s3_output_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict for 14 days\n",
    "prediction_length = 14\n",
    "\n",
    "# Use 14 days as context length, \n",
    "# This is the number of state updates accomplished before making predictions\n",
    "context_length = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    \"time_freq\": 'D',\n",
    "    \"epochs\": \"400\",\n",
    "    \"early_stopping_patience\": \"40\",\n",
    "    \"mini_batch_size\": \"64\",\n",
    "    \"learning_rate\": \"5E-4\",\n",
    "    \"context_length\": str(context_length),\n",
    "    \"prediction_length\": str(prediction_length)\n",
    "}\n",
    "estimator.set_hyperparameters(**hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-15 18:04:39 Starting - Starting the training job...\n",
      "2020-05-15 18:04:43 Starting - Launching requested ML instances......\n",
      "2020-05-15 18:05:43 Starting - Preparing the instances for training...\n",
      "2020-05-15 18:06:36 Downloading - Downloading input data\n",
      "2020-05-15 18:06:36 Training - Downloading the training image...\n",
      "2020-05-15 18:07:13 Training - Training image download completed. Training in progress..\u001b[34mArguments: train\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:16 INFO 140645276194624] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/resources/default-input.json: {u'num_dynamic_feat': u'auto', u'dropout_rate': u'0.10', u'mini_batch_size': u'128', u'test_quantiles': u'[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]', u'_tuning_objective_metric': u'', u'_num_gpus': u'auto', u'num_eval_samples': u'100', u'learning_rate': u'0.001', u'num_cells': u'40', u'num_layers': u'2', u'embedding_dimension': u'10', u'_kvstore': u'auto', u'_num_kv_servers': u'auto', u'cardinality': u'auto', u'likelihood': u'student-t', u'early_stopping_patience': u''}\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:16 INFO 140645276194624] Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'learning_rate': u'5E-4', u'prediction_length': u'14', u'epochs': u'400', u'time_freq': u'D', u'context_length': u'14', u'mini_batch_size': u'64', u'early_stopping_patience': u'40'}\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:16 INFO 140645276194624] Final configuration: {u'dropout_rate': u'0.10', u'test_quantiles': u'[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]', u'_tuning_objective_metric': u'', u'num_eval_samples': u'100', u'learning_rate': u'5E-4', u'num_layers': u'2', u'epochs': u'400', u'embedding_dimension': u'10', u'num_cells': u'40', u'_num_kv_servers': u'auto', u'mini_batch_size': u'64', u'likelihood': u'student-t', u'num_dynamic_feat': u'auto', u'cardinality': u'auto', u'_num_gpus': u'auto', u'prediction_length': u'14', u'time_freq': u'D', u'context_length': u'14', u'_kvstore': u'auto', u'early_stopping_patience': u'40'}\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:16 INFO 140645276194624] Detected entry point for worker worker\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:16 INFO 140645276194624] Using early stopping with patience 40\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:16 INFO 140645276194624] [cardinality=auto] `cat` field was NOT found in the file `/opt/ml/input/data/train/train.json` and will NOT be used for training.\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:16 INFO 140645276194624] [num_dynamic_feat=auto] `dynamic_feat` field was NOT found in the file `/opt/ml/input/data/train/train.json` and will NOT be used for training.\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:16 INFO 140645276194624] Training set statistics:\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:16 INFO 140645276194624] Real time series\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:16 INFO 140645276194624] number of time series: 6\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:16 INFO 140645276194624] number of observations: 2418\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:16 INFO 140645276194624] mean target length: 403\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:16 INFO 140645276194624] min/mean/max target: 174.169998169/198.946921526/213.5\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:16 INFO 140645276194624] mean abs(target): 198.946921526\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:16 INFO 140645276194624] contains missing values: no\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:16 INFO 140645276194624] Small number of time series. Doing 107 passes over dataset with prob 0.996884735202 per epoch.\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:16 INFO 140645276194624] Test set statistics:\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:16 INFO 140645276194624] Real time series\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:16 INFO 140645276194624] number of time series: 6\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:16 INFO 140645276194624] number of observations: 606\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:16 INFO 140645276194624] mean target length: 101\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:16 INFO 140645276194624] min/mean/max target: 174.169998169/185.106048886/191.520004272\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:16 INFO 140645276194624] mean abs(target): 185.106048886\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:16 INFO 140645276194624] contains missing values: no\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:16 INFO 140645276194624] nvidia-smi took: 0.0252239704132 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:16 INFO 140645276194624] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:16 INFO 140645276194624] Create Store: local\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"get_graph.time\": {\"count\": 1, \"max\": 76.63416862487793, \"sum\": 76.63416862487793, \"min\": 76.63416862487793}}, \"EndTime\": 1589566036.643481, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566036.565945}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:16 INFO 140645276194624] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"initialize.time\": {\"count\": 1, \"max\": 197.79205322265625, \"sum\": 197.79205322265625, \"min\": 197.79205322265625}}, \"EndTime\": 1589566036.76387, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566036.643562}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:17 INFO 140645276194624] Epoch[0] Batch[0] avg_epoch_loss=6.167983\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:17 INFO 140645276194624] #quality_metric: host=algo-1, epoch=0, batch=0 train loss <loss>=6.16798305511\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:17 INFO 140645276194624] Epoch[0] Batch[5] avg_epoch_loss=5.994233\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:17 INFO 140645276194624] #quality_metric: host=algo-1, epoch=0, batch=5 train loss <loss>=5.99423329035\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:17 INFO 140645276194624] Epoch[0] Batch [5]#011Speed: 1748.41 samples/sec#011loss=5.994233\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:17 INFO 140645276194624] processed a total of 628 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"epochs\": {\"count\": 1, \"max\": 400, \"sum\": 400.0, \"min\": 400}, \"update.time\": {\"count\": 1, \"max\": 658.7009429931641, \"sum\": 658.7009429931641, \"min\": 658.7009429931641}}, \"EndTime\": 1589566037.422736, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566036.763933}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:17 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=953.193300781 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:17 INFO 140645276194624] #progress_metric: host=algo-1, completed 0 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:17 INFO 140645276194624] #quality_metric: host=algo-1, epoch=0, train loss <loss>=5.87877388\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:17 INFO 140645276194624] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:17 INFO 140645276194624] Saved checkpoint to \"/opt/ml/model/state_e687227e-5c8c-4793-a899-e5505d4d7731-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 15.577077865600586, \"sum\": 15.577077865600586, \"min\": 15.577077865600586}}, \"EndTime\": 1589566037.439129, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566037.422832}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:17 INFO 140645276194624] Epoch[1] Batch[0] avg_epoch_loss=5.585773\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:17 INFO 140645276194624] #quality_metric: host=algo-1, epoch=1, batch=0 train loss <loss>=5.58577251434\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:17 INFO 140645276194624] Epoch[1] Batch[5] avg_epoch_loss=5.346013\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:17 INFO 140645276194624] #quality_metric: host=algo-1, epoch=1, batch=5 train loss <loss>=5.3460132281\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:17 INFO 140645276194624] Epoch[1] Batch [5]#011Speed: 1851.00 samples/sec#011loss=5.346013\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:18 INFO 140645276194624] Epoch[1] Batch[10] avg_epoch_loss=5.199508\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:18 INFO 140645276194624] #quality_metric: host=algo-1, epoch=1, batch=10 train loss <loss>=5.02370138168\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:18 INFO 140645276194624] Epoch[1] Batch [10]#011Speed: 1614.59 samples/sec#011loss=5.023701\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:18 INFO 140645276194624] processed a total of 678 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 619.7719573974609, \"sum\": 619.7719573974609, \"min\": 619.7719573974609}}, \"EndTime\": 1589566038.059063, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566037.439222}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:18 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1093.64195234 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:18 INFO 140645276194624] #progress_metric: host=algo-1, completed 0 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:18 INFO 140645276194624] #quality_metric: host=algo-1, epoch=1, train loss <loss>=5.19950784336\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:18 INFO 140645276194624] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:18 INFO 140645276194624] Saved checkpoint to \"/opt/ml/model/state_56958ca0-12c8-4b60-ba2c-6ed7a1a05aa2-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 12.735128402709961, \"sum\": 12.735128402709961, \"min\": 12.735128402709961}}, \"EndTime\": 1589566038.072499, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566038.059158}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:18 INFO 140645276194624] Epoch[2] Batch[0] avg_epoch_loss=4.870192\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:18 INFO 140645276194624] #quality_metric: host=algo-1, epoch=2, batch=0 train loss <loss>=4.87019205093\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:18 INFO 140645276194624] Epoch[2] Batch[5] avg_epoch_loss=4.734791\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:18 INFO 140645276194624] #quality_metric: host=algo-1, epoch=2, batch=5 train loss <loss>=4.73479135831\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:18 INFO 140645276194624] Epoch[2] Batch [5]#011Speed: 1972.68 samples/sec#011loss=4.734791\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:18 INFO 140645276194624] processed a total of 611 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 539.8380756378174, \"sum\": 539.8380756378174, \"min\": 539.8380756378174}}, \"EndTime\": 1589566038.612484, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566038.072577}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:18 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1131.59247618 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:18 INFO 140645276194624] #progress_metric: host=algo-1, completed 0 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:18 INFO 140645276194624] #quality_metric: host=algo-1, epoch=2, train loss <loss>=4.62114701271\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:18 INFO 140645276194624] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:18 INFO 140645276194624] Saved checkpoint to \"/opt/ml/model/state_d3a5baec-f597-4c28-b683-900c020f9716-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 12.368917465209961, \"sum\": 12.368917465209961, \"min\": 12.368917465209961}}, \"EndTime\": 1589566038.625455, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566038.612553}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:18 INFO 140645276194624] Epoch[3] Batch[0] avg_epoch_loss=4.314366\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:18 INFO 140645276194624] #quality_metric: host=algo-1, epoch=3, batch=0 train loss <loss>=4.31436634064\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:19 INFO 140645276194624] Epoch[3] Batch[5] avg_epoch_loss=4.187675\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:19 INFO 140645276194624] #quality_metric: host=algo-1, epoch=3, batch=5 train loss <loss>=4.18767491976\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:19 INFO 140645276194624] Epoch[3] Batch [5]#011Speed: 1516.17 samples/sec#011loss=4.187675\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:19 INFO 140645276194624] processed a total of 627 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 594.5901870727539, \"sum\": 594.5901870727539, \"min\": 594.5901870727539}}, \"EndTime\": 1589566039.220177, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566038.625522}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:19 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1054.29897698 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:19 INFO 140645276194624] #progress_metric: host=algo-1, completed 1 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:19 INFO 140645276194624] #quality_metric: host=algo-1, epoch=3, train loss <loss>=4.08659052849\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:19 INFO 140645276194624] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:19 INFO 140645276194624] Saved checkpoint to \"/opt/ml/model/state_96d3ec71-9469-425b-9b5e-1bd7b0130305-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 19.556045532226562, \"sum\": 19.556045532226562, \"min\": 19.556045532226562}}, \"EndTime\": 1589566039.240319, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566039.220258}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:19 INFO 140645276194624] Epoch[4] Batch[0] avg_epoch_loss=3.856883\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:19 INFO 140645276194624] #quality_metric: host=algo-1, epoch=4, batch=0 train loss <loss>=3.85688328743\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:19 INFO 140645276194624] Epoch[4] Batch[5] avg_epoch_loss=3.775892\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:19 INFO 140645276194624] #quality_metric: host=algo-1, epoch=4, batch=5 train loss <loss>=3.7758919398\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:19 INFO 140645276194624] Epoch[4] Batch [5]#011Speed: 1930.63 samples/sec#011loss=3.775892\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:19 INFO 140645276194624] Epoch[4] Batch[10] avg_epoch_loss=3.682061\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:19 INFO 140645276194624] #quality_metric: host=algo-1, epoch=4, batch=10 train loss <loss>=3.5694642067\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:19 INFO 140645276194624] Epoch[4] Batch [10]#011Speed: 1935.37 samples/sec#011loss=3.569464\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:19 INFO 140645276194624] processed a total of 664 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 578.0608654022217, \"sum\": 578.0608654022217, \"min\": 578.0608654022217}}, \"EndTime\": 1589566039.818521, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566039.240397}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:19 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1148.44486964 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:19 INFO 140645276194624] #progress_metric: host=algo-1, completed 1 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:19 INFO 140645276194624] #quality_metric: host=algo-1, epoch=4, train loss <loss>=3.68206115202\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:19 INFO 140645276194624] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:19 INFO 140645276194624] Saved checkpoint to \"/opt/ml/model/state_67fecac3-a0c5-42df-b608-a3832961652a-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 20.010948181152344, \"sum\": 20.010948181152344, \"min\": 20.010948181152344}}, \"EndTime\": 1589566039.83907, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566039.818596}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:20 INFO 140645276194624] Epoch[5] Batch[0] avg_epoch_loss=3.527164\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:20 INFO 140645276194624] #quality_metric: host=algo-1, epoch=5, batch=0 train loss <loss>=3.52716398239\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:20 INFO 140645276194624] Epoch[5] Batch[5] avg_epoch_loss=3.414153\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:20 INFO 140645276194624] #quality_metric: host=algo-1, epoch=5, batch=5 train loss <loss>=3.41415274143\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:20 INFO 140645276194624] Epoch[5] Batch [5]#011Speed: 1414.36 samples/sec#011loss=3.414153\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:20 INFO 140645276194624] processed a total of 640 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 701.88307762146, \"sum\": 701.88307762146, \"min\": 701.88307762146}}, \"EndTime\": 1589566040.541115, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566039.839169}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:20 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=911.671749143 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:20 INFO 140645276194624] #progress_metric: host=algo-1, completed 1 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:20 INFO 140645276194624] #quality_metric: host=algo-1, epoch=5, train loss <loss>=3.38531825542\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:20 INFO 140645276194624] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:20 INFO 140645276194624] Saved checkpoint to \"/opt/ml/model/state_7eec41ec-d202-4e61-886d-790e79a5604e-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 20.67399024963379, \"sum\": 20.67399024963379, \"min\": 20.67399024963379}}, \"EndTime\": 1589566040.562357, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566040.541201}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:20 INFO 140645276194624] Epoch[6] Batch[0] avg_epoch_loss=3.236045\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:20 INFO 140645276194624] #quality_metric: host=algo-1, epoch=6, batch=0 train loss <loss>=3.23604488373\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:21 INFO 140645276194624] Epoch[6] Batch[5] avg_epoch_loss=3.203560\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:21 INFO 140645276194624] #quality_metric: host=algo-1, epoch=6, batch=5 train loss <loss>=3.2035595576\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:21 INFO 140645276194624] Epoch[6] Batch [5]#011Speed: 1845.51 samples/sec#011loss=3.203560\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:21 INFO 140645276194624] Epoch[6] Batch[10] avg_epoch_loss=3.160643\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:21 INFO 140645276194624] #quality_metric: host=algo-1, epoch=6, batch=10 train loss <loss>=3.10914268494\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:21 INFO 140645276194624] Epoch[6] Batch [10]#011Speed: 1960.93 samples/sec#011loss=3.109143\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:21 INFO 140645276194624] processed a total of 649 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 632.9081058502197, \"sum\": 632.9081058502197, \"min\": 632.9081058502197}}, \"EndTime\": 1589566041.195407, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566040.562434}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:21 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1025.24264637 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:21 INFO 140645276194624] #progress_metric: host=algo-1, completed 1 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:21 INFO 140645276194624] #quality_metric: host=algo-1, epoch=6, train loss <loss>=3.1606427973\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:21 INFO 140645276194624] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:21 INFO 140645276194624] Saved checkpoint to \"/opt/ml/model/state_fbe330f3-cac2-4257-ac6a-0cf283f07793-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 19.284963607788086, \"sum\": 19.284963607788086, \"min\": 19.284963607788086}}, \"EndTime\": 1589566041.215221, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566041.195483}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:21 INFO 140645276194624] Epoch[7] Batch[0] avg_epoch_loss=3.047430\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:21 INFO 140645276194624] #quality_metric: host=algo-1, epoch=7, batch=0 train loss <loss>=3.04742980003\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:21 INFO 140645276194624] Epoch[7] Batch[5] avg_epoch_loss=3.123957\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:21 INFO 140645276194624] #quality_metric: host=algo-1, epoch=7, batch=5 train loss <loss>=3.12395719687\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:21 INFO 140645276194624] Epoch[7] Batch [5]#011Speed: 1849.60 samples/sec#011loss=3.123957\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:21 INFO 140645276194624] processed a total of 638 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 564.1000270843506, \"sum\": 564.1000270843506, \"min\": 564.1000270843506}}, \"EndTime\": 1589566041.779454, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566041.215295}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:21 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1130.77042617 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:21 INFO 140645276194624] #progress_metric: host=algo-1, completed 2 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:21 INFO 140645276194624] #quality_metric: host=algo-1, epoch=7, train loss <loss>=3.12542686462\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:21 INFO 140645276194624] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:21 INFO 140645276194624] Saved checkpoint to \"/opt/ml/model/state_3f370e92-d413-41c6-b725-4482d6f98091-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 19.70982551574707, \"sum\": 19.70982551574707, \"min\": 19.70982551574707}}, \"EndTime\": 1589566041.799741, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566041.779535}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:22 INFO 140645276194624] Epoch[8] Batch[0] avg_epoch_loss=3.405193\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:22 INFO 140645276194624] #quality_metric: host=algo-1, epoch=8, batch=0 train loss <loss>=3.40519309044\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:22 INFO 140645276194624] Epoch[8] Batch[5] avg_epoch_loss=3.186634\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:22 INFO 140645276194624] #quality_metric: host=algo-1, epoch=8, batch=5 train loss <loss>=3.18663386504\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:22 INFO 140645276194624] Epoch[8] Batch [5]#011Speed: 1965.72 samples/sec#011loss=3.186634\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:22 INFO 140645276194624] processed a total of 594 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 562.5491142272949, \"sum\": 562.5491142272949, \"min\": 562.5491142272949}}, \"EndTime\": 1589566042.362433, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566041.799818}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:22 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1055.70914589 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:22 INFO 140645276194624] #progress_metric: host=algo-1, completed 2 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:22 INFO 140645276194624] #quality_metric: host=algo-1, epoch=8, train loss <loss>=3.22582864761\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:22 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:22 INFO 140645276194624] Epoch[9] Batch[0] avg_epoch_loss=3.077694\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:22 INFO 140645276194624] #quality_metric: host=algo-1, epoch=9, batch=0 train loss <loss>=3.07769370079\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:22 INFO 140645276194624] Epoch[9] Batch[5] avg_epoch_loss=3.058973\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:22 INFO 140645276194624] #quality_metric: host=algo-1, epoch=9, batch=5 train loss <loss>=3.05897307396\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:22 INFO 140645276194624] Epoch[9] Batch [5]#011Speed: 1843.84 samples/sec#011loss=3.058973\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:22 INFO 140645276194624] processed a total of 634 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 535.0608825683594, \"sum\": 535.0608825683594, \"min\": 535.0608825683594}}, \"EndTime\": 1589566042.898069, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566042.362499}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:22 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1184.64795243 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:22 INFO 140645276194624] #progress_metric: host=algo-1, completed 2 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:22 INFO 140645276194624] #quality_metric: host=algo-1, epoch=9, train loss <loss>=3.0221088171\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:22 INFO 140645276194624] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:22 INFO 140645276194624] Saved checkpoint to \"/opt/ml/model/state_99a049b9-2e50-4e84-9743-6627737a1419-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 19.83809471130371, \"sum\": 19.83809471130371, \"min\": 19.83809471130371}}, \"EndTime\": 1589566042.918495, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566042.898149}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:23 INFO 140645276194624] Epoch[10] Batch[0] avg_epoch_loss=2.992307\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:23 INFO 140645276194624] #quality_metric: host=algo-1, epoch=10, batch=0 train loss <loss>=2.99230742455\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:23 INFO 140645276194624] Epoch[10] Batch[5] avg_epoch_loss=2.937865\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:23 INFO 140645276194624] #quality_metric: host=algo-1, epoch=10, batch=5 train loss <loss>=2.93786537647\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:23 INFO 140645276194624] Epoch[10] Batch [5]#011Speed: 1844.78 samples/sec#011loss=2.937865\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:23 INFO 140645276194624] Epoch[10] Batch[10] avg_epoch_loss=2.896599\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:23 INFO 140645276194624] #quality_metric: host=algo-1, epoch=10, batch=10 train loss <loss>=2.84707913399\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:23 INFO 140645276194624] Epoch[10] Batch [10]#011Speed: 1940.59 samples/sec#011loss=2.847079\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:23 INFO 140645276194624] processed a total of 668 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 626.8079280853271, \"sum\": 626.8079280853271, \"min\": 626.8079280853271}}, \"EndTime\": 1589566043.545447, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566042.918575}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:23 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1065.5230808 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:23 INFO 140645276194624] #progress_metric: host=algo-1, completed 2 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:23 INFO 140645276194624] #quality_metric: host=algo-1, epoch=10, train loss <loss>=2.89659890262\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:23 INFO 140645276194624] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:23 INFO 140645276194624] Saved checkpoint to \"/opt/ml/model/state_e4cbf57b-8562-457d-be6e-4a0d4f11ef0d-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 20.05600929260254, \"sum\": 20.05600929260254, \"min\": 20.05600929260254}}, \"EndTime\": 1589566043.566058, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566043.545525}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:23 INFO 140645276194624] Epoch[11] Batch[0] avg_epoch_loss=3.023392\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:23 INFO 140645276194624] #quality_metric: host=algo-1, epoch=11, batch=0 train loss <loss>=3.02339196205\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:24 INFO 140645276194624] Epoch[11] Batch[5] avg_epoch_loss=3.104927\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:24 INFO 140645276194624] #quality_metric: host=algo-1, epoch=11, batch=5 train loss <loss>=3.10492662589\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:24 INFO 140645276194624] Epoch[11] Batch [5]#011Speed: 1839.46 samples/sec#011loss=3.104927\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:24 INFO 140645276194624] processed a total of 639 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 603.1970977783203, \"sum\": 603.1970977783203, \"min\": 603.1970977783203}}, \"EndTime\": 1589566044.169392, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566043.566134}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:24 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1059.14842287 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:24 INFO 140645276194624] #progress_metric: host=algo-1, completed 3 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:24 INFO 140645276194624] #quality_metric: host=algo-1, epoch=11, train loss <loss>=3.06098015308\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:24 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:24 INFO 140645276194624] Epoch[12] Batch[0] avg_epoch_loss=2.941007\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:24 INFO 140645276194624] #quality_metric: host=algo-1, epoch=12, batch=0 train loss <loss>=2.9410071373\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:24 INFO 140645276194624] Epoch[12] Batch[5] avg_epoch_loss=2.885632\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:24 INFO 140645276194624] #quality_metric: host=algo-1, epoch=12, batch=5 train loss <loss>=2.88563156128\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:24 INFO 140645276194624] Epoch[12] Batch [5]#011Speed: 1938.44 samples/sec#011loss=2.885632\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:24 INFO 140645276194624] processed a total of 623 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 555.1600456237793, \"sum\": 555.1600456237793, \"min\": 555.1600456237793}}, \"EndTime\": 1589566044.725098, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566044.169474}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:24 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1121.96281322 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:24 INFO 140645276194624] #progress_metric: host=algo-1, completed 3 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:24 INFO 140645276194624] #quality_metric: host=algo-1, epoch=12, train loss <loss>=2.8945723772\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:24 INFO 140645276194624] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:24 INFO 140645276194624] Saved checkpoint to \"/opt/ml/model/state_6bd5301f-e5c4-497e-8c52-bb0be1b4cb3f-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 19.514083862304688, \"sum\": 19.514083862304688, \"min\": 19.514083862304688}}, \"EndTime\": 1589566044.74518, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566044.725178}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:24 INFO 140645276194624] Epoch[13] Batch[0] avg_epoch_loss=2.806519\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:24 INFO 140645276194624] #quality_metric: host=algo-1, epoch=13, batch=0 train loss <loss>=2.80651903152\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:25 INFO 140645276194624] Epoch[13] Batch[5] avg_epoch_loss=2.894955\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:25 INFO 140645276194624] #quality_metric: host=algo-1, epoch=13, batch=5 train loss <loss>=2.89495484034\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:25 INFO 140645276194624] Epoch[13] Batch [5]#011Speed: 1823.55 samples/sec#011loss=2.894955\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:25 INFO 140645276194624] processed a total of 612 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 540.2841567993164, \"sum\": 540.2841567993164, \"min\": 540.2841567993164}}, \"EndTime\": 1589566045.285607, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566044.745257}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:25 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1132.4798999 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:25 INFO 140645276194624] #progress_metric: host=algo-1, completed 3 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:25 INFO 140645276194624] #quality_metric: host=algo-1, epoch=13, train loss <loss>=2.86898014545\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:25 INFO 140645276194624] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:25 INFO 140645276194624] Saved checkpoint to \"/opt/ml/model/state_4badad78-3a13-47a7-85f0-4d7d842447ac-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 13.482093811035156, \"sum\": 13.482093811035156, \"min\": 13.482093811035156}}, \"EndTime\": 1589566045.299714, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566045.285691}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:25 INFO 140645276194624] Epoch[14] Batch[0] avg_epoch_loss=2.769284\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:25 INFO 140645276194624] #quality_metric: host=algo-1, epoch=14, batch=0 train loss <loss>=2.76928377151\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:25 INFO 140645276194624] Epoch[14] Batch[5] avg_epoch_loss=2.873379\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:25 INFO 140645276194624] #quality_metric: host=algo-1, epoch=14, batch=5 train loss <loss>=2.87337891261\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:25 INFO 140645276194624] Epoch[14] Batch [5]#011Speed: 1497.97 samples/sec#011loss=2.873379\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:25 INFO 140645276194624] Epoch[14] Batch[10] avg_epoch_loss=2.913065\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:25 INFO 140645276194624] #quality_metric: host=algo-1, epoch=14, batch=10 train loss <loss>=2.96068806648\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:25 INFO 140645276194624] Epoch[14] Batch [10]#011Speed: 1915.51 samples/sec#011loss=2.960688\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:25 INFO 140645276194624] processed a total of 650 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 624.0179538726807, \"sum\": 624.0179538726807, \"min\": 624.0179538726807}}, \"EndTime\": 1589566045.923853, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566045.299777}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:25 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1041.44132581 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:25 INFO 140645276194624] #progress_metric: host=algo-1, completed 3 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:25 INFO 140645276194624] #quality_metric: host=algo-1, epoch=14, train loss <loss>=2.91306489164\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:25 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:26 INFO 140645276194624] Epoch[15] Batch[0] avg_epoch_loss=2.701798\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:26 INFO 140645276194624] #quality_metric: host=algo-1, epoch=15, batch=0 train loss <loss>=2.70179820061\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:26 INFO 140645276194624] Epoch[15] Batch[5] avg_epoch_loss=2.849328\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:26 INFO 140645276194624] #quality_metric: host=algo-1, epoch=15, batch=5 train loss <loss>=2.84932816029\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:26 INFO 140645276194624] Epoch[15] Batch [5]#011Speed: 1942.30 samples/sec#011loss=2.849328\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:26 INFO 140645276194624] Epoch[15] Batch[10] avg_epoch_loss=2.888208\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:26 INFO 140645276194624] #quality_metric: host=algo-1, epoch=15, batch=10 train loss <loss>=2.93486404419\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:26 INFO 140645276194624] Epoch[15] Batch [10]#011Speed: 1979.97 samples/sec#011loss=2.934864\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:26 INFO 140645276194624] processed a total of 680 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 564.8238658905029, \"sum\": 564.8238658905029, \"min\": 564.8238658905029}}, \"EndTime\": 1589566046.489239, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566045.923932}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:26 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1203.68039738 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:26 INFO 140645276194624] #progress_metric: host=algo-1, completed 4 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:26 INFO 140645276194624] #quality_metric: host=algo-1, epoch=15, train loss <loss>=2.88820810751\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:26 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:26 INFO 140645276194624] Epoch[16] Batch[0] avg_epoch_loss=2.939256\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:26 INFO 140645276194624] #quality_metric: host=algo-1, epoch=16, batch=0 train loss <loss>=2.93925619125\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:26 INFO 140645276194624] Epoch[16] Batch[5] avg_epoch_loss=2.947138\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:26 INFO 140645276194624] #quality_metric: host=algo-1, epoch=16, batch=5 train loss <loss>=2.94713819027\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:26 INFO 140645276194624] Epoch[16] Batch [5]#011Speed: 1987.19 samples/sec#011loss=2.947138\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:27 INFO 140645276194624] Epoch[16] Batch[10] avg_epoch_loss=2.898894\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:27 INFO 140645276194624] #quality_metric: host=algo-1, epoch=16, batch=10 train loss <loss>=2.84100074768\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:27 INFO 140645276194624] Epoch[16] Batch [10]#011Speed: 1930.67 samples/sec#011loss=2.841001\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:27 INFO 140645276194624] processed a total of 656 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 554.4860363006592, \"sum\": 554.4860363006592, \"min\": 554.4860363006592}}, \"EndTime\": 1589566047.044254, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566046.489314}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:27 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1182.85125496 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:27 INFO 140645276194624] #progress_metric: host=algo-1, completed 4 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:27 INFO 140645276194624] #quality_metric: host=algo-1, epoch=16, train loss <loss>=2.89889389818\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:27 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:27 INFO 140645276194624] Epoch[17] Batch[0] avg_epoch_loss=3.054852\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:27 INFO 140645276194624] #quality_metric: host=algo-1, epoch=17, batch=0 train loss <loss>=3.05485200882\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:27 INFO 140645276194624] Epoch[17] Batch[5] avg_epoch_loss=2.984014\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:27 INFO 140645276194624] #quality_metric: host=algo-1, epoch=17, batch=5 train loss <loss>=2.98401375612\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:27 INFO 140645276194624] Epoch[17] Batch [5]#011Speed: 1970.83 samples/sec#011loss=2.984014\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:27 INFO 140645276194624] Epoch[17] Batch[10] avg_epoch_loss=2.923871\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:27 INFO 140645276194624] #quality_metric: host=algo-1, epoch=17, batch=10 train loss <loss>=2.85169911385\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:27 INFO 140645276194624] Epoch[17] Batch [10]#011Speed: 1955.24 samples/sec#011loss=2.851699\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:27 INFO 140645276194624] processed a total of 677 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 563.5068416595459, \"sum\": 563.5068416595459, \"min\": 563.5068416595459}}, \"EndTime\": 1589566047.60833, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566047.044321}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:27 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1201.1916585 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:27 INFO 140645276194624] #progress_metric: host=algo-1, completed 4 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:27 INFO 140645276194624] #quality_metric: host=algo-1, epoch=17, train loss <loss>=2.9238707369\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:27 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:27 INFO 140645276194624] Epoch[18] Batch[0] avg_epoch_loss=2.733174\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:27 INFO 140645276194624] #quality_metric: host=algo-1, epoch=18, batch=0 train loss <loss>=2.73317408562\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:28 INFO 140645276194624] Epoch[18] Batch[5] avg_epoch_loss=2.797586\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:28 INFO 140645276194624] #quality_metric: host=algo-1, epoch=18, batch=5 train loss <loss>=2.79758608341\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:28 INFO 140645276194624] Epoch[18] Batch [5]#011Speed: 1992.77 samples/sec#011loss=2.797586\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:28 INFO 140645276194624] Epoch[18] Batch[10] avg_epoch_loss=2.882931\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:28 INFO 140645276194624] #quality_metric: host=algo-1, epoch=18, batch=10 train loss <loss>=2.98534393311\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:28 INFO 140645276194624] Epoch[18] Batch [10]#011Speed: 1953.28 samples/sec#011loss=2.985344\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:28 INFO 140645276194624] processed a total of 654 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 557.765007019043, \"sum\": 557.765007019043, \"min\": 557.765007019043}}, \"EndTime\": 1589566048.166639, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566047.608394}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:28 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1172.29277032 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:28 INFO 140645276194624] #progress_metric: host=algo-1, completed 4 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:28 INFO 140645276194624] #quality_metric: host=algo-1, epoch=18, train loss <loss>=2.88293056055\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:28 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:28 INFO 140645276194624] Epoch[19] Batch[0] avg_epoch_loss=3.798758\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:28 INFO 140645276194624] #quality_metric: host=algo-1, epoch=19, batch=0 train loss <loss>=3.79875826836\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:28 INFO 140645276194624] Epoch[19] Batch[5] avg_epoch_loss=3.279749\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:28 INFO 140645276194624] #quality_metric: host=algo-1, epoch=19, batch=5 train loss <loss>=3.27974927425\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:28 INFO 140645276194624] Epoch[19] Batch [5]#011Speed: 1980.74 samples/sec#011loss=3.279749\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:28 INFO 140645276194624] processed a total of 638 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 531.6648483276367, \"sum\": 531.6648483276367, \"min\": 531.6648483276367}}, \"EndTime\": 1589566048.698916, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566048.166717}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:28 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1199.73725241 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:28 INFO 140645276194624] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:28 INFO 140645276194624] #quality_metric: host=algo-1, epoch=19, train loss <loss>=3.24707708359\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:28 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:28 INFO 140645276194624] Epoch[20] Batch[0] avg_epoch_loss=3.002678\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:28 INFO 140645276194624] #quality_metric: host=algo-1, epoch=20, batch=0 train loss <loss>=3.00267791748\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:29 INFO 140645276194624] Epoch[20] Batch[5] avg_epoch_loss=2.998269\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:29 INFO 140645276194624] #quality_metric: host=algo-1, epoch=20, batch=5 train loss <loss>=2.99826920033\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:29 INFO 140645276194624] Epoch[20] Batch [5]#011Speed: 1812.03 samples/sec#011loss=2.998269\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:29 INFO 140645276194624] Epoch[20] Batch[10] avg_epoch_loss=2.937292\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:29 INFO 140645276194624] #quality_metric: host=algo-1, epoch=20, batch=10 train loss <loss>=2.86411862373\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:29 INFO 140645276194624] Epoch[20] Batch [10]#011Speed: 1915.35 samples/sec#011loss=2.864119\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:29 INFO 140645276194624] processed a total of 659 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 607.280969619751, \"sum\": 607.280969619751, \"min\": 607.280969619751}}, \"EndTime\": 1589566049.306757, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566048.698996}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:29 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1084.96471215 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:29 INFO 140645276194624] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:29 INFO 140645276194624] #quality_metric: host=algo-1, epoch=20, train loss <loss>=2.93729166551\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:29 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:29 INFO 140645276194624] Epoch[21] Batch[0] avg_epoch_loss=3.013823\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:29 INFO 140645276194624] #quality_metric: host=algo-1, epoch=21, batch=0 train loss <loss>=3.01382255554\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:29 INFO 140645276194624] Epoch[21] Batch[5] avg_epoch_loss=2.910969\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:29 INFO 140645276194624] #quality_metric: host=algo-1, epoch=21, batch=5 train loss <loss>=2.91096949577\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:29 INFO 140645276194624] Epoch[21] Batch [5]#011Speed: 1945.04 samples/sec#011loss=2.910969\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:29 INFO 140645276194624] Epoch[21] Batch[10] avg_epoch_loss=2.915302\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:29 INFO 140645276194624] #quality_metric: host=algo-1, epoch=21, batch=10 train loss <loss>=2.92050037384\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:29 INFO 140645276194624] Epoch[21] Batch [10]#011Speed: 1976.04 samples/sec#011loss=2.920500\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:29 INFO 140645276194624] processed a total of 651 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 617.448091506958, \"sum\": 617.448091506958, \"min\": 617.448091506958}}, \"EndTime\": 1589566049.924741, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566049.306834}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:29 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1054.15362235 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:29 INFO 140645276194624] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:29 INFO 140645276194624] #quality_metric: host=algo-1, epoch=21, train loss <loss>=2.91530171308\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:29 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:30 INFO 140645276194624] Epoch[22] Batch[0] avg_epoch_loss=2.848468\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:30 INFO 140645276194624] #quality_metric: host=algo-1, epoch=22, batch=0 train loss <loss>=2.84846806526\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:30 INFO 140645276194624] Epoch[22] Batch[5] avg_epoch_loss=2.807463\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:30 INFO 140645276194624] #quality_metric: host=algo-1, epoch=22, batch=5 train loss <loss>=2.80746320883\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:30 INFO 140645276194624] Epoch[22] Batch [5]#011Speed: 1939.52 samples/sec#011loss=2.807463\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:30 INFO 140645276194624] Epoch[22] Batch[10] avg_epoch_loss=2.783591\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:30 INFO 140645276194624] #quality_metric: host=algo-1, epoch=22, batch=10 train loss <loss>=2.75494508743\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:30 INFO 140645276194624] Epoch[22] Batch [10]#011Speed: 1908.01 samples/sec#011loss=2.754945\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:30 INFO 140645276194624] processed a total of 649 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 630.3400993347168, \"sum\": 630.3400993347168, \"min\": 630.3400993347168}}, \"EndTime\": 1589566050.555536, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566049.924816}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:30 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1029.41835003 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:30 INFO 140645276194624] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:30 INFO 140645276194624] #quality_metric: host=algo-1, epoch=22, train loss <loss>=2.78359133547\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:30 INFO 140645276194624] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:30 INFO 140645276194624] Saved checkpoint to \"/opt/ml/model/state_d2a53b2b-7eab-4f76-a8c4-df078afc3b00-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 19.99497413635254, \"sum\": 19.99497413635254, \"min\": 19.99497413635254}}, \"EndTime\": 1589566050.576103, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566050.555613}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:30 INFO 140645276194624] Epoch[23] Batch[0] avg_epoch_loss=2.729393\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:30 INFO 140645276194624] #quality_metric: host=algo-1, epoch=23, batch=0 train loss <loss>=2.72939300537\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:31 INFO 140645276194624] Epoch[23] Batch[5] avg_epoch_loss=2.796906\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:31 INFO 140645276194624] #quality_metric: host=algo-1, epoch=23, batch=5 train loss <loss>=2.79690623283\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:31 INFO 140645276194624] Epoch[23] Batch [5]#011Speed: 1874.30 samples/sec#011loss=2.796906\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:31 INFO 140645276194624] Epoch[23] Batch[10] avg_epoch_loss=2.762889\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:31 INFO 140645276194624] #quality_metric: host=algo-1, epoch=23, batch=10 train loss <loss>=2.722067976\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:31 INFO 140645276194624] Epoch[23] Batch [10]#011Speed: 1928.05 samples/sec#011loss=2.722068\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:31 INFO 140645276194624] processed a total of 649 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 633.2509517669678, \"sum\": 633.2509517669678, \"min\": 633.2509517669678}}, \"EndTime\": 1589566051.209497, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566050.576181}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:31 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1024.69037268 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:31 INFO 140645276194624] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:31 INFO 140645276194624] #quality_metric: host=algo-1, epoch=23, train loss <loss>=2.76288884336\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:31 INFO 140645276194624] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:31 INFO 140645276194624] Saved checkpoint to \"/opt/ml/model/state_cdd7ec01-f400-490a-92a5-34f0ffbaae61-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 16.343116760253906, \"sum\": 16.343116760253906, \"min\": 16.343116760253906}}, \"EndTime\": 1589566051.226379, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566051.209572}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:31 INFO 140645276194624] Epoch[24] Batch[0] avg_epoch_loss=2.791015\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:31 INFO 140645276194624] #quality_metric: host=algo-1, epoch=24, batch=0 train loss <loss>=2.79101538658\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:31 INFO 140645276194624] Epoch[24] Batch[5] avg_epoch_loss=2.839421\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:31 INFO 140645276194624] #quality_metric: host=algo-1, epoch=24, batch=5 train loss <loss>=2.8394210736\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:31 INFO 140645276194624] Epoch[24] Batch [5]#011Speed: 1991.98 samples/sec#011loss=2.839421\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:31 INFO 140645276194624] Epoch[24] Batch[10] avg_epoch_loss=2.799975\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:31 INFO 140645276194624] #quality_metric: host=algo-1, epoch=24, batch=10 train loss <loss>=2.75263881683\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:31 INFO 140645276194624] Epoch[24] Batch [10]#011Speed: 1952.04 samples/sec#011loss=2.752639\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:31 INFO 140645276194624] processed a total of 650 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 562.4680519104004, \"sum\": 562.4680519104004, \"min\": 562.4680519104004}}, \"EndTime\": 1589566051.788975, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566051.226455}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:31 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1155.39345837 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:31 INFO 140645276194624] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:31 INFO 140645276194624] #quality_metric: host=algo-1, epoch=24, train loss <loss>=2.79997459325\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:31 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:32 INFO 140645276194624] Epoch[25] Batch[0] avg_epoch_loss=2.939778\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:32 INFO 140645276194624] #quality_metric: host=algo-1, epoch=25, batch=0 train loss <loss>=2.9397778511\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:32 INFO 140645276194624] Epoch[25] Batch[5] avg_epoch_loss=2.831977\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:32 INFO 140645276194624] #quality_metric: host=algo-1, epoch=25, batch=5 train loss <loss>=2.83197665215\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:32 INFO 140645276194624] Epoch[25] Batch [5]#011Speed: 1632.06 samples/sec#011loss=2.831977\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:32 INFO 140645276194624] processed a total of 623 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 617.332935333252, \"sum\": 617.332935333252, \"min\": 617.332935333252}}, \"EndTime\": 1589566052.406805, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566051.789052}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:32 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1008.98858394 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:32 INFO 140645276194624] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:32 INFO 140645276194624] #quality_metric: host=algo-1, epoch=25, train loss <loss>=2.82958211899\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:32 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:32 INFO 140645276194624] Epoch[26] Batch[0] avg_epoch_loss=2.707048\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:32 INFO 140645276194624] #quality_metric: host=algo-1, epoch=26, batch=0 train loss <loss>=2.70704770088\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:32 INFO 140645276194624] Epoch[26] Batch[5] avg_epoch_loss=2.767387\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:32 INFO 140645276194624] #quality_metric: host=algo-1, epoch=26, batch=5 train loss <loss>=2.76738723119\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:32 INFO 140645276194624] Epoch[26] Batch [5]#011Speed: 1947.56 samples/sec#011loss=2.767387\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:32 INFO 140645276194624] Epoch[26] Batch[10] avg_epoch_loss=2.828987\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:32 INFO 140645276194624] #quality_metric: host=algo-1, epoch=26, batch=10 train loss <loss>=2.90290589333\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:32 INFO 140645276194624] Epoch[26] Batch [10]#011Speed: 1946.71 samples/sec#011loss=2.902906\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:32 INFO 140645276194624] processed a total of 646 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 574.833869934082, \"sum\": 574.833869934082, \"min\": 574.833869934082}}, \"EndTime\": 1589566052.982202, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566052.406885}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:32 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1123.58765079 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:32 INFO 140645276194624] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:32 INFO 140645276194624] #quality_metric: host=algo-1, epoch=26, train loss <loss>=2.82898662307\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:32 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:33 INFO 140645276194624] Epoch[27] Batch[0] avg_epoch_loss=3.016486\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:33 INFO 140645276194624] #quality_metric: host=algo-1, epoch=27, batch=0 train loss <loss>=3.01648616791\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:33 INFO 140645276194624] Epoch[27] Batch[5] avg_epoch_loss=2.975026\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:33 INFO 140645276194624] #quality_metric: host=algo-1, epoch=27, batch=5 train loss <loss>=2.97502585252\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:33 INFO 140645276194624] Epoch[27] Batch [5]#011Speed: 1976.69 samples/sec#011loss=2.975026\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:33 INFO 140645276194624] Epoch[27] Batch[10] avg_epoch_loss=2.914228\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:33 INFO 140645276194624] #quality_metric: host=algo-1, epoch=27, batch=10 train loss <loss>=2.84127163887\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:33 INFO 140645276194624] Epoch[27] Batch [10]#011Speed: 1941.61 samples/sec#011loss=2.841272\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:33 INFO 140645276194624] processed a total of 681 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 577.1520137786865, \"sum\": 577.1520137786865, \"min\": 577.1520137786865}}, \"EndTime\": 1589566053.559843, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566052.982277}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:33 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1179.70273015 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:33 INFO 140645276194624] #progress_metric: host=algo-1, completed 7 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:33 INFO 140645276194624] #quality_metric: host=algo-1, epoch=27, train loss <loss>=2.91422848268\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:33 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:33 INFO 140645276194624] Epoch[28] Batch[0] avg_epoch_loss=3.083863\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:33 INFO 140645276194624] #quality_metric: host=algo-1, epoch=28, batch=0 train loss <loss>=3.08386301994\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:33 INFO 140645276194624] Epoch[28] Batch[5] avg_epoch_loss=2.877874\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:33 INFO 140645276194624] #quality_metric: host=algo-1, epoch=28, batch=5 train loss <loss>=2.87787433465\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:33 INFO 140645276194624] Epoch[28] Batch [5]#011Speed: 2007.45 samples/sec#011loss=2.877874\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:34 INFO 140645276194624] Epoch[28] Batch[10] avg_epoch_loss=2.870306\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:34 INFO 140645276194624] #quality_metric: host=algo-1, epoch=28, batch=10 train loss <loss>=2.86122398376\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:34 INFO 140645276194624] Epoch[28] Batch [10]#011Speed: 1833.76 samples/sec#011loss=2.861224\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:34 INFO 140645276194624] processed a total of 670 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 586.0490798950195, \"sum\": 586.0490798950195, \"min\": 586.0490798950195}}, \"EndTime\": 1589566054.146383, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566053.559919}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:34 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1143.04435048 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:34 INFO 140645276194624] #progress_metric: host=algo-1, completed 7 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:34 INFO 140645276194624] #quality_metric: host=algo-1, epoch=28, train loss <loss>=2.87030599334\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:34 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:34 INFO 140645276194624] Epoch[29] Batch[0] avg_epoch_loss=2.785877\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:34 INFO 140645276194624] #quality_metric: host=algo-1, epoch=29, batch=0 train loss <loss>=2.78587675095\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:34 INFO 140645276194624] Epoch[29] Batch[5] avg_epoch_loss=2.797947\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:34 INFO 140645276194624] #quality_metric: host=algo-1, epoch=29, batch=5 train loss <loss>=2.79794736703\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:34 INFO 140645276194624] Epoch[29] Batch [5]#011Speed: 1963.45 samples/sec#011loss=2.797947\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:34 INFO 140645276194624] Epoch[29] Batch[10] avg_epoch_loss=2.797156\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:34 INFO 140645276194624] #quality_metric: host=algo-1, epoch=29, batch=10 train loss <loss>=2.79620604515\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:34 INFO 140645276194624] Epoch[29] Batch [10]#011Speed: 1952.18 samples/sec#011loss=2.796206\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:34 INFO 140645276194624] processed a total of 691 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 590.2907848358154, \"sum\": 590.2907848358154, \"min\": 590.2907848358154}}, \"EndTime\": 1589566054.737133, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566054.146454}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:34 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1170.39110196 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:34 INFO 140645276194624] #progress_metric: host=algo-1, completed 7 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:34 INFO 140645276194624] #quality_metric: host=algo-1, epoch=29, train loss <loss>=2.79715585709\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:34 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:34 INFO 140645276194624] Epoch[30] Batch[0] avg_epoch_loss=2.784287\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:34 INFO 140645276194624] #quality_metric: host=algo-1, epoch=30, batch=0 train loss <loss>=2.78428697586\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:35 INFO 140645276194624] Epoch[30] Batch[5] avg_epoch_loss=2.781134\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:35 INFO 140645276194624] #quality_metric: host=algo-1, epoch=30, batch=5 train loss <loss>=2.78113424778\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:35 INFO 140645276194624] Epoch[30] Batch [5]#011Speed: 1996.14 samples/sec#011loss=2.781134\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:35 INFO 140645276194624] processed a total of 598 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 526.0050296783447, \"sum\": 526.0050296783447, \"min\": 526.0050296783447}}, \"EndTime\": 1589566055.263622, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566054.737209}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:35 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1136.67702286 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:35 INFO 140645276194624] #progress_metric: host=algo-1, completed 7 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:35 INFO 140645276194624] #quality_metric: host=algo-1, epoch=30, train loss <loss>=2.75451936722\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:35 INFO 140645276194624] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:35 INFO 140645276194624] Saved checkpoint to \"/opt/ml/model/state_d4e16131-be72-4c84-938b-994a395e2f97-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 13.803958892822266, \"sum\": 13.803958892822266, \"min\": 13.803958892822266}}, \"EndTime\": 1589566055.277964, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566055.263682}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:35 INFO 140645276194624] Epoch[31] Batch[0] avg_epoch_loss=2.705329\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:35 INFO 140645276194624] #quality_metric: host=algo-1, epoch=31, batch=0 train loss <loss>=2.70532894135\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:35 INFO 140645276194624] Epoch[31] Batch[5] avg_epoch_loss=2.760733\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:35 INFO 140645276194624] #quality_metric: host=algo-1, epoch=31, batch=5 train loss <loss>=2.76073300838\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:35 INFO 140645276194624] Epoch[31] Batch [5]#011Speed: 1851.00 samples/sec#011loss=2.760733\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:35 INFO 140645276194624] processed a total of 620 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 557.5079917907715, \"sum\": 557.5079917907715, \"min\": 557.5079917907715}}, \"EndTime\": 1589566055.835593, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566055.278028}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:35 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1111.8506113 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:35 INFO 140645276194624] #progress_metric: host=algo-1, completed 8 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:35 INFO 140645276194624] #quality_metric: host=algo-1, epoch=31, train loss <loss>=2.73625349998\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:35 INFO 140645276194624] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:35 INFO 140645276194624] Saved checkpoint to \"/opt/ml/model/state_0858d082-3399-49f7-b618-4b0f479fa75b-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 12.619972229003906, \"sum\": 12.619972229003906, \"min\": 12.619972229003906}}, \"EndTime\": 1589566055.848854, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566055.835676}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:36 INFO 140645276194624] Epoch[32] Batch[0] avg_epoch_loss=2.823033\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:36 INFO 140645276194624] #quality_metric: host=algo-1, epoch=32, batch=0 train loss <loss>=2.82303309441\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:36 INFO 140645276194624] Epoch[32] Batch[5] avg_epoch_loss=2.741035\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:36 INFO 140645276194624] #quality_metric: host=algo-1, epoch=32, batch=5 train loss <loss>=2.74103502433\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:36 INFO 140645276194624] Epoch[32] Batch [5]#011Speed: 1975.02 samples/sec#011loss=2.741035\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:36 INFO 140645276194624] processed a total of 608 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 519.8960304260254, \"sum\": 519.8960304260254, \"min\": 519.8960304260254}}, \"EndTime\": 1589566056.368893, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566055.848929}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:36 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1169.20347221 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:36 INFO 140645276194624] #progress_metric: host=algo-1, completed 8 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:36 INFO 140645276194624] #quality_metric: host=algo-1, epoch=32, train loss <loss>=2.74795944691\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:36 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:36 INFO 140645276194624] Epoch[33] Batch[0] avg_epoch_loss=3.008153\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:36 INFO 140645276194624] #quality_metric: host=algo-1, epoch=33, batch=0 train loss <loss>=3.00815320015\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:36 INFO 140645276194624] Epoch[33] Batch[5] avg_epoch_loss=2.810248\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:36 INFO 140645276194624] #quality_metric: host=algo-1, epoch=33, batch=5 train loss <loss>=2.81024841468\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:36 INFO 140645276194624] Epoch[33] Batch [5]#011Speed: 1839.76 samples/sec#011loss=2.810248\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:36 INFO 140645276194624] processed a total of 617 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 533.9210033416748, \"sum\": 533.9210033416748, \"min\": 533.9210033416748}}, \"EndTime\": 1589566056.903322, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566056.36897}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:36 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1155.37878411 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:36 INFO 140645276194624] #progress_metric: host=algo-1, completed 8 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:36 INFO 140645276194624] #quality_metric: host=algo-1, epoch=33, train loss <loss>=2.77335531712\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:36 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:37 INFO 140645276194624] Epoch[34] Batch[0] avg_epoch_loss=2.764165\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:37 INFO 140645276194624] #quality_metric: host=algo-1, epoch=34, batch=0 train loss <loss>=2.7641646862\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:37 INFO 140645276194624] Epoch[34] Batch[5] avg_epoch_loss=2.765777\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:37 INFO 140645276194624] #quality_metric: host=algo-1, epoch=34, batch=5 train loss <loss>=2.76577723026\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:37 INFO 140645276194624] Epoch[34] Batch [5]#011Speed: 1946.06 samples/sec#011loss=2.765777\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:37 INFO 140645276194624] Epoch[34] Batch[10] avg_epoch_loss=2.735631\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:37 INFO 140645276194624] #quality_metric: host=algo-1, epoch=34, batch=10 train loss <loss>=2.69945497513\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:37 INFO 140645276194624] Epoch[34] Batch [10]#011Speed: 1895.54 samples/sec#011loss=2.699455\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:37 INFO 140645276194624] processed a total of 651 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 557.3480129241943, \"sum\": 557.3480129241943, \"min\": 557.3480129241943}}, \"EndTime\": 1589566057.461261, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566056.903391}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:37 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1167.80114176 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:37 INFO 140645276194624] #progress_metric: host=algo-1, completed 8 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:37 INFO 140645276194624] #quality_metric: host=algo-1, epoch=34, train loss <loss>=2.73563075066\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:37 INFO 140645276194624] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:37 INFO 140645276194624] Saved checkpoint to \"/opt/ml/model/state_d3e0fe51-d1eb-47c8-95f8-91a90084a29f-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 14.149904251098633, \"sum\": 14.149904251098633, \"min\": 14.149904251098633}}, \"EndTime\": 1589566057.476011, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566057.461335}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:37 INFO 140645276194624] Epoch[35] Batch[0] avg_epoch_loss=2.750133\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:37 INFO 140645276194624] #quality_metric: host=algo-1, epoch=35, batch=0 train loss <loss>=2.75013279915\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:37 INFO 140645276194624] Epoch[35] Batch[5] avg_epoch_loss=2.772912\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:37 INFO 140645276194624] #quality_metric: host=algo-1, epoch=35, batch=5 train loss <loss>=2.77291186651\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:37 INFO 140645276194624] Epoch[35] Batch [5]#011Speed: 1997.80 samples/sec#011loss=2.772912\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:38 INFO 140645276194624] Epoch[35] Batch[10] avg_epoch_loss=2.744970\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:38 INFO 140645276194624] #quality_metric: host=algo-1, epoch=35, batch=10 train loss <loss>=2.71143946648\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:38 INFO 140645276194624] Epoch[35] Batch [10]#011Speed: 1936.17 samples/sec#011loss=2.711439\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:38 INFO 140645276194624] processed a total of 657 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 561.4719390869141, \"sum\": 561.4719390869141, \"min\": 561.4719390869141}}, \"EndTime\": 1589566058.037633, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566057.476089}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:38 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1169.91755133 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:38 INFO 140645276194624] #progress_metric: host=algo-1, completed 9 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:38 INFO 140645276194624] #quality_metric: host=algo-1, epoch=35, train loss <loss>=2.74496986649\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:38 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:38 INFO 140645276194624] Epoch[36] Batch[0] avg_epoch_loss=2.723962\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:38 INFO 140645276194624] #quality_metric: host=algo-1, epoch=36, batch=0 train loss <loss>=2.72396230698\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:38 INFO 140645276194624] Epoch[36] Batch[5] avg_epoch_loss=2.810898\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:38 INFO 140645276194624] #quality_metric: host=algo-1, epoch=36, batch=5 train loss <loss>=2.81089802583\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:38 INFO 140645276194624] Epoch[36] Batch [5]#011Speed: 1943.65 samples/sec#011loss=2.810898\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:38 INFO 140645276194624] processed a total of 632 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 536.9620323181152, \"sum\": 536.9620323181152, \"min\": 536.9620323181152}}, \"EndTime\": 1589566058.575107, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566058.037699}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:38 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1176.6722248 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:38 INFO 140645276194624] #progress_metric: host=algo-1, completed 9 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:38 INFO 140645276194624] #quality_metric: host=algo-1, epoch=36, train loss <loss>=2.78281576633\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:38 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:38 INFO 140645276194624] Epoch[37] Batch[0] avg_epoch_loss=2.774280\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:38 INFO 140645276194624] #quality_metric: host=algo-1, epoch=37, batch=0 train loss <loss>=2.77428007126\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:38 INFO 140645276194624] Epoch[37] Batch[5] avg_epoch_loss=2.741156\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:38 INFO 140645276194624] #quality_metric: host=algo-1, epoch=37, batch=5 train loss <loss>=2.74115586281\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:38 INFO 140645276194624] Epoch[37] Batch [5]#011Speed: 1976.96 samples/sec#011loss=2.741156\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:39 INFO 140645276194624] processed a total of 604 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 526.1201858520508, \"sum\": 526.1201858520508, \"min\": 526.1201858520508}}, \"EndTime\": 1589566059.101763, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566058.575217}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:39 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1147.76555742 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:39 INFO 140645276194624] #progress_metric: host=algo-1, completed 9 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:39 INFO 140645276194624] #quality_metric: host=algo-1, epoch=37, train loss <loss>=2.71452414989\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:39 INFO 140645276194624] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:39 INFO 140645276194624] Saved checkpoint to \"/opt/ml/model/state_18d14453-9e8d-49a2-99e6-bdcb2cbaa646-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 20.142793655395508, \"sum\": 20.142793655395508, \"min\": 20.142793655395508}}, \"EndTime\": 1589566059.122494, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566059.101845}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:39 INFO 140645276194624] Epoch[38] Batch[0] avg_epoch_loss=2.881834\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:39 INFO 140645276194624] #quality_metric: host=algo-1, epoch=38, batch=0 train loss <loss>=2.88183379173\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:39 INFO 140645276194624] Epoch[38] Batch[5] avg_epoch_loss=2.810393\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:39 INFO 140645276194624] #quality_metric: host=algo-1, epoch=38, batch=5 train loss <loss>=2.81039337317\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:39 INFO 140645276194624] Epoch[38] Batch [5]#011Speed: 1983.39 samples/sec#011loss=2.810393\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:39 INFO 140645276194624] Epoch[38] Batch[10] avg_epoch_loss=2.946752\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:39 INFO 140645276194624] #quality_metric: host=algo-1, epoch=38, batch=10 train loss <loss>=3.11038208008\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:39 INFO 140645276194624] Epoch[38] Batch [10]#011Speed: 1890.78 samples/sec#011loss=3.110382\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:39 INFO 140645276194624] processed a total of 643 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 567.5461292266846, \"sum\": 567.5461292266846, \"min\": 567.5461292266846}}, \"EndTime\": 1589566059.690184, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566059.122572}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:39 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1132.72819185 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:39 INFO 140645276194624] #progress_metric: host=algo-1, completed 9 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:39 INFO 140645276194624] #quality_metric: host=algo-1, epoch=38, train loss <loss>=2.94675187631\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:39 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:39 INFO 140645276194624] Epoch[39] Batch[0] avg_epoch_loss=3.097398\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:39 INFO 140645276194624] #quality_metric: host=algo-1, epoch=39, batch=0 train loss <loss>=3.09739756584\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:40 INFO 140645276194624] Epoch[39] Batch[5] avg_epoch_loss=2.914738\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:40 INFO 140645276194624] #quality_metric: host=algo-1, epoch=39, batch=5 train loss <loss>=2.91473774115\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:40 INFO 140645276194624] Epoch[39] Batch [5]#011Speed: 1902.37 samples/sec#011loss=2.914738\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:40 INFO 140645276194624] Epoch[39] Batch[10] avg_epoch_loss=2.850112\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:40 INFO 140645276194624] #quality_metric: host=algo-1, epoch=39, batch=10 train loss <loss>=2.77256188393\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:40 INFO 140645276194624] Epoch[39] Batch [10]#011Speed: 1950.43 samples/sec#011loss=2.772562\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:40 INFO 140645276194624] processed a total of 655 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 617.0239448547363, \"sum\": 617.0239448547363, \"min\": 617.0239448547363}}, \"EndTime\": 1589566060.307693, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566059.690258}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:40 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1061.35602283 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:40 INFO 140645276194624] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:40 INFO 140645276194624] #quality_metric: host=algo-1, epoch=39, train loss <loss>=2.8501123515\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:40 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:40 INFO 140645276194624] Epoch[40] Batch[0] avg_epoch_loss=3.323877\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:40 INFO 140645276194624] #quality_metric: host=algo-1, epoch=40, batch=0 train loss <loss>=3.32387661934\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:40 INFO 140645276194624] Epoch[40] Batch[5] avg_epoch_loss=3.059597\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:40 INFO 140645276194624] #quality_metric: host=algo-1, epoch=40, batch=5 train loss <loss>=3.05959737301\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:40 INFO 140645276194624] Epoch[40] Batch [5]#011Speed: 1980.21 samples/sec#011loss=3.059597\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:40 INFO 140645276194624] Epoch[40] Batch[10] avg_epoch_loss=3.058065\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:40 INFO 140645276194624] #quality_metric: host=algo-1, epoch=40, batch=10 train loss <loss>=3.05622611046\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:40 INFO 140645276194624] Epoch[40] Batch [10]#011Speed: 1927.12 samples/sec#011loss=3.056226\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:40 INFO 140645276194624] processed a total of 664 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 568.8040256500244, \"sum\": 568.8040256500244, \"min\": 568.8040256500244}}, \"EndTime\": 1589566060.876999, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566060.307768}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:40 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1167.14198139 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:40 INFO 140645276194624] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:40 INFO 140645276194624] #quality_metric: host=algo-1, epoch=40, train loss <loss>=3.05806498094\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:40 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:41 INFO 140645276194624] Epoch[41] Batch[0] avg_epoch_loss=2.848678\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:41 INFO 140645276194624] #quality_metric: host=algo-1, epoch=41, batch=0 train loss <loss>=2.84867787361\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:41 INFO 140645276194624] Epoch[41] Batch[5] avg_epoch_loss=2.833381\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:41 INFO 140645276194624] #quality_metric: host=algo-1, epoch=41, batch=5 train loss <loss>=2.83338089784\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:41 INFO 140645276194624] Epoch[41] Batch [5]#011Speed: 1797.21 samples/sec#011loss=2.833381\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:41 INFO 140645276194624] Epoch[41] Batch[10] avg_epoch_loss=2.777220\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:41 INFO 140645276194624] #quality_metric: host=algo-1, epoch=41, batch=10 train loss <loss>=2.70982723236\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:41 INFO 140645276194624] Epoch[41] Batch [10]#011Speed: 1947.59 samples/sec#011loss=2.709827\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:41 INFO 140645276194624] processed a total of 657 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 571.5250968933105, \"sum\": 571.5250968933105, \"min\": 571.5250968933105}}, \"EndTime\": 1589566061.449035, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566060.877068}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:41 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1149.31896812 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:41 INFO 140645276194624] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:41 INFO 140645276194624] #quality_metric: host=algo-1, epoch=41, train loss <loss>=2.7772201408\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:41 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:41 INFO 140645276194624] Epoch[42] Batch[0] avg_epoch_loss=2.691503\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:41 INFO 140645276194624] #quality_metric: host=algo-1, epoch=42, batch=0 train loss <loss>=2.69150257111\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:41 INFO 140645276194624] Epoch[42] Batch[5] avg_epoch_loss=2.740099\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:41 INFO 140645276194624] #quality_metric: host=algo-1, epoch=42, batch=5 train loss <loss>=2.74009943008\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:41 INFO 140645276194624] Epoch[42] Batch [5]#011Speed: 1994.28 samples/sec#011loss=2.740099\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:41 INFO 140645276194624] processed a total of 606 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 512.3040676116943, \"sum\": 512.3040676116943, \"min\": 512.3040676116943}}, \"EndTime\": 1589566061.961913, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566061.449118}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:41 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1182.68375012 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:41 INFO 140645276194624] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:41 INFO 140645276194624] #quality_metric: host=algo-1, epoch=42, train loss <loss>=2.74514045715\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:41 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:42 INFO 140645276194624] Epoch[43] Batch[0] avg_epoch_loss=2.834857\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:42 INFO 140645276194624] #quality_metric: host=algo-1, epoch=43, batch=0 train loss <loss>=2.83485674858\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:42 INFO 140645276194624] Epoch[43] Batch[5] avg_epoch_loss=2.732346\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:42 INFO 140645276194624] #quality_metric: host=algo-1, epoch=43, batch=5 train loss <loss>=2.73234566053\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:42 INFO 140645276194624] Epoch[43] Batch [5]#011Speed: 1896.42 samples/sec#011loss=2.732346\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:42 INFO 140645276194624] processed a total of 589 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 521.8768119812012, \"sum\": 521.8768119812012, \"min\": 521.8768119812012}}, \"EndTime\": 1589566062.484295, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566061.961973}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:42 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1128.36315238 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:42 INFO 140645276194624] #progress_metric: host=algo-1, completed 11 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:42 INFO 140645276194624] #quality_metric: host=algo-1, epoch=43, train loss <loss>=2.69647336006\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:42 INFO 140645276194624] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:42 INFO 140645276194624] Saved checkpoint to \"/opt/ml/model/state_24b8af6b-6a54-4656-9c63-aad4aaef198b-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 20.048141479492188, \"sum\": 20.048141479492188, \"min\": 20.048141479492188}}, \"EndTime\": 1589566062.50492, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566062.484375}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:42 INFO 140645276194624] Epoch[44] Batch[0] avg_epoch_loss=2.782896\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:42 INFO 140645276194624] #quality_metric: host=algo-1, epoch=44, batch=0 train loss <loss>=2.78289580345\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:42 INFO 140645276194624] Epoch[44] Batch[5] avg_epoch_loss=2.747961\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:42 INFO 140645276194624] #quality_metric: host=algo-1, epoch=44, batch=5 train loss <loss>=2.74796100458\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:42 INFO 140645276194624] Epoch[44] Batch [5]#011Speed: 1993.43 samples/sec#011loss=2.747961\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:43 INFO 140645276194624] Epoch[44] Batch[10] avg_epoch_loss=2.732581\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:43 INFO 140645276194624] #quality_metric: host=algo-1, epoch=44, batch=10 train loss <loss>=2.71412467957\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:43 INFO 140645276194624] Epoch[44] Batch [10]#011Speed: 1707.16 samples/sec#011loss=2.714125\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:43 INFO 140645276194624] processed a total of 668 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 574.2709636688232, \"sum\": 574.2709636688232, \"min\": 574.2709636688232}}, \"EndTime\": 1589566063.079331, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566062.504996}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:43 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1163.01116232 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:43 INFO 140645276194624] #progress_metric: host=algo-1, completed 11 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:43 INFO 140645276194624] #quality_metric: host=algo-1, epoch=44, train loss <loss>=2.73258085684\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:43 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:43 INFO 140645276194624] Epoch[45] Batch[0] avg_epoch_loss=2.683149\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:43 INFO 140645276194624] #quality_metric: host=algo-1, epoch=45, batch=0 train loss <loss>=2.68314862251\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:43 INFO 140645276194624] Epoch[45] Batch[5] avg_epoch_loss=2.737706\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:43 INFO 140645276194624] #quality_metric: host=algo-1, epoch=45, batch=5 train loss <loss>=2.7377055486\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:43 INFO 140645276194624] Epoch[45] Batch [5]#011Speed: 1969.60 samples/sec#011loss=2.737706\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:43 INFO 140645276194624] Epoch[45] Batch[10] avg_epoch_loss=2.743324\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:43 INFO 140645276194624] #quality_metric: host=algo-1, epoch=45, batch=10 train loss <loss>=2.75006651878\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:43 INFO 140645276194624] Epoch[45] Batch [10]#011Speed: 1949.47 samples/sec#011loss=2.750067\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:43 INFO 140645276194624] processed a total of 657 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 565.7939910888672, \"sum\": 565.7939910888672, \"min\": 565.7939910888672}}, \"EndTime\": 1589566063.645625, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566063.079392}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:43 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1160.97254397 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:43 INFO 140645276194624] #progress_metric: host=algo-1, completed 11 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:43 INFO 140645276194624] #quality_metric: host=algo-1, epoch=45, train loss <loss>=2.74332417141\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:43 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:43 INFO 140645276194624] Epoch[46] Batch[0] avg_epoch_loss=2.663929\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:43 INFO 140645276194624] #quality_metric: host=algo-1, epoch=46, batch=0 train loss <loss>=2.66392946243\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:44 INFO 140645276194624] Epoch[46] Batch[5] avg_epoch_loss=2.697917\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:44 INFO 140645276194624] #quality_metric: host=algo-1, epoch=46, batch=5 train loss <loss>=2.69791734219\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:44 INFO 140645276194624] Epoch[46] Batch [5]#011Speed: 1952.70 samples/sec#011loss=2.697917\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:44 INFO 140645276194624] Epoch[46] Batch[10] avg_epoch_loss=2.806108\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:44 INFO 140645276194624] #quality_metric: host=algo-1, epoch=46, batch=10 train loss <loss>=2.93593730927\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:44 INFO 140645276194624] Epoch[46] Batch [10]#011Speed: 1848.32 samples/sec#011loss=2.935937\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:44 INFO 140645276194624] processed a total of 659 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 570.7659721374512, \"sum\": 570.7659721374512, \"min\": 570.7659721374512}}, \"EndTime\": 1589566064.216871, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566063.645701}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:44 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1154.36602646 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:44 INFO 140645276194624] #progress_metric: host=algo-1, completed 11 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:44 INFO 140645276194624] #quality_metric: host=algo-1, epoch=46, train loss <loss>=2.80610823631\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:44 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:44 INFO 140645276194624] Epoch[47] Batch[0] avg_epoch_loss=2.905009\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:44 INFO 140645276194624] #quality_metric: host=algo-1, epoch=47, batch=0 train loss <loss>=2.90500926971\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:44 INFO 140645276194624] Epoch[47] Batch[5] avg_epoch_loss=2.807173\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:44 INFO 140645276194624] #quality_metric: host=algo-1, epoch=47, batch=5 train loss <loss>=2.80717329184\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:44 INFO 140645276194624] Epoch[47] Batch [5]#011Speed: 1999.13 samples/sec#011loss=2.807173\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:44 INFO 140645276194624] processed a total of 632 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 539.4930839538574, \"sum\": 539.4930839538574, \"min\": 539.4930839538574}}, \"EndTime\": 1589566064.756858, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566064.216946}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:44 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1171.21437623 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:44 INFO 140645276194624] #progress_metric: host=algo-1, completed 12 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:44 INFO 140645276194624] #quality_metric: host=algo-1, epoch=47, train loss <loss>=2.77992243767\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:44 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:45 INFO 140645276194624] Epoch[48] Batch[0] avg_epoch_loss=2.875826\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:45 INFO 140645276194624] #quality_metric: host=algo-1, epoch=48, batch=0 train loss <loss>=2.87582612038\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:45 INFO 140645276194624] Epoch[48] Batch[5] avg_epoch_loss=2.758016\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:45 INFO 140645276194624] #quality_metric: host=algo-1, epoch=48, batch=5 train loss <loss>=2.75801563263\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:45 INFO 140645276194624] Epoch[48] Batch [5]#011Speed: 2000.46 samples/sec#011loss=2.758016\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:45 INFO 140645276194624] Epoch[48] Batch[10] avg_epoch_loss=2.709903\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:45 INFO 140645276194624] #quality_metric: host=algo-1, epoch=48, batch=10 train loss <loss>=2.65216889381\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:45 INFO 140645276194624] Epoch[48] Batch [10]#011Speed: 1814.87 samples/sec#011loss=2.652169\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:45 INFO 140645276194624] processed a total of 646 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 619.8289394378662, \"sum\": 619.8289394378662, \"min\": 619.8289394378662}}, \"EndTime\": 1589566065.377216, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566064.75694}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:45 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1042.03625467 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:45 INFO 140645276194624] #progress_metric: host=algo-1, completed 12 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:45 INFO 140645276194624] #quality_metric: host=algo-1, epoch=48, train loss <loss>=2.70990347862\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:45 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:45 INFO 140645276194624] Epoch[49] Batch[0] avg_epoch_loss=2.758492\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:45 INFO 140645276194624] #quality_metric: host=algo-1, epoch=49, batch=0 train loss <loss>=2.75849199295\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:45 INFO 140645276194624] Epoch[49] Batch[5] avg_epoch_loss=2.643169\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:45 INFO 140645276194624] #quality_metric: host=algo-1, epoch=49, batch=5 train loss <loss>=2.64316928387\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:45 INFO 140645276194624] Epoch[49] Batch [5]#011Speed: 1689.03 samples/sec#011loss=2.643169\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:45 INFO 140645276194624] Epoch[49] Batch[10] avg_epoch_loss=2.649989\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:45 INFO 140645276194624] #quality_metric: host=algo-1, epoch=49, batch=10 train loss <loss>=2.65817375183\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:45 INFO 140645276194624] Epoch[49] Batch [10]#011Speed: 1940.54 samples/sec#011loss=2.658174\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:45 INFO 140645276194624] processed a total of 645 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 589.9200439453125, \"sum\": 589.9200439453125, \"min\": 589.9200439453125}}, \"EndTime\": 1589566065.967619, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566065.377291}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:45 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1093.16307098 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:45 INFO 140645276194624] #progress_metric: host=algo-1, completed 12 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:45 INFO 140645276194624] #quality_metric: host=algo-1, epoch=49, train loss <loss>=2.64998949658\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:45 INFO 140645276194624] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:45 INFO 140645276194624] Saved checkpoint to \"/opt/ml/model/state_980aa778-3fb5-47a5-9b34-ef5f3babff85-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 19.627094268798828, \"sum\": 19.627094268798828, \"min\": 19.627094268798828}}, \"EndTime\": 1589566065.987787, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566065.967694}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:46 INFO 140645276194624] Epoch[50] Batch[0] avg_epoch_loss=2.673664\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:46 INFO 140645276194624] #quality_metric: host=algo-1, epoch=50, batch=0 train loss <loss>=2.6736638546\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:46 INFO 140645276194624] Epoch[50] Batch[5] avg_epoch_loss=2.672819\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:46 INFO 140645276194624] #quality_metric: host=algo-1, epoch=50, batch=5 train loss <loss>=2.67281937599\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:46 INFO 140645276194624] Epoch[50] Batch [5]#011Speed: 1754.06 samples/sec#011loss=2.672819\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:46 INFO 140645276194624] processed a total of 603 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 544.1479682922363, \"sum\": 544.1479682922363, \"min\": 544.1479682922363}}, \"EndTime\": 1589566066.532076, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566065.987864}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:46 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1107.91417446 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:46 INFO 140645276194624] #progress_metric: host=algo-1, completed 12 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:46 INFO 140645276194624] #quality_metric: host=algo-1, epoch=50, train loss <loss>=2.71742045879\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:46 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:46 INFO 140645276194624] Epoch[51] Batch[0] avg_epoch_loss=2.638832\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:46 INFO 140645276194624] #quality_metric: host=algo-1, epoch=51, batch=0 train loss <loss>=2.63883185387\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:46 INFO 140645276194624] Epoch[51] Batch[5] avg_epoch_loss=2.693851\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:46 INFO 140645276194624] #quality_metric: host=algo-1, epoch=51, batch=5 train loss <loss>=2.693851312\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:46 INFO 140645276194624] Epoch[51] Batch [5]#011Speed: 2016.81 samples/sec#011loss=2.693851\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:47 INFO 140645276194624] Epoch[51] Batch[10] avg_epoch_loss=2.674957\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:47 INFO 140645276194624] #quality_metric: host=algo-1, epoch=51, batch=10 train loss <loss>=2.652283144\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:47 INFO 140645276194624] Epoch[51] Batch [10]#011Speed: 1992.12 samples/sec#011loss=2.652283\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:47 INFO 140645276194624] processed a total of 643 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 543.9531803131104, \"sum\": 543.9531803131104, \"min\": 543.9531803131104}}, \"EndTime\": 1589566067.076568, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566066.532156}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:47 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1181.86790819 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:47 INFO 140645276194624] #progress_metric: host=algo-1, completed 13 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:47 INFO 140645276194624] #quality_metric: host=algo-1, epoch=51, train loss <loss>=2.67495669018\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:47 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:47 INFO 140645276194624] Epoch[52] Batch[0] avg_epoch_loss=2.815549\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:47 INFO 140645276194624] #quality_metric: host=algo-1, epoch=52, batch=0 train loss <loss>=2.81554865837\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:47 INFO 140645276194624] Epoch[52] Batch[5] avg_epoch_loss=2.775953\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:47 INFO 140645276194624] #quality_metric: host=algo-1, epoch=52, batch=5 train loss <loss>=2.77595325311\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:47 INFO 140645276194624] Epoch[52] Batch [5]#011Speed: 1972.26 samples/sec#011loss=2.775953\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:47 INFO 140645276194624] processed a total of 632 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 512.8002166748047, \"sum\": 512.8002166748047, \"min\": 512.8002166748047}}, \"EndTime\": 1589566067.589839, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566067.076632}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:47 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1232.2018602 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:47 INFO 140645276194624] #progress_metric: host=algo-1, completed 13 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:47 INFO 140645276194624] #quality_metric: host=algo-1, epoch=52, train loss <loss>=2.76391506195\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:47 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:47 INFO 140645276194624] Epoch[53] Batch[0] avg_epoch_loss=2.706797\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:47 INFO 140645276194624] #quality_metric: host=algo-1, epoch=53, batch=0 train loss <loss>=2.70679688454\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:47 INFO 140645276194624] Epoch[53] Batch[5] avg_epoch_loss=2.704425\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:47 INFO 140645276194624] #quality_metric: host=algo-1, epoch=53, batch=5 train loss <loss>=2.70442505678\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:47 INFO 140645276194624] Epoch[53] Batch [5]#011Speed: 2008.74 samples/sec#011loss=2.704425\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:48 INFO 140645276194624] processed a total of 620 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 516.4220333099365, \"sum\": 516.4220333099365, \"min\": 516.4220333099365}}, \"EndTime\": 1589566068.106784, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566067.589913}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:48 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1200.29470235 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:48 INFO 140645276194624] #progress_metric: host=algo-1, completed 13 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:48 INFO 140645276194624] #quality_metric: host=algo-1, epoch=53, train loss <loss>=2.66352288723\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:48 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:48 INFO 140645276194624] Epoch[54] Batch[0] avg_epoch_loss=2.608446\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:48 INFO 140645276194624] #quality_metric: host=algo-1, epoch=54, batch=0 train loss <loss>=2.60844564438\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:48 INFO 140645276194624] Epoch[54] Batch[5] avg_epoch_loss=2.657849\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:48 INFO 140645276194624] #quality_metric: host=algo-1, epoch=54, batch=5 train loss <loss>=2.65784899394\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:48 INFO 140645276194624] Epoch[54] Batch [5]#011Speed: 2011.65 samples/sec#011loss=2.657849\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:48 INFO 140645276194624] processed a total of 600 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 503.95894050598145, \"sum\": 503.95894050598145, \"min\": 503.95894050598145}}, \"EndTime\": 1589566068.611348, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566068.106865}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:48 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1190.33216109 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:48 INFO 140645276194624] #progress_metric: host=algo-1, completed 13 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:48 INFO 140645276194624] #quality_metric: host=algo-1, epoch=54, train loss <loss>=2.6778639555\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:48 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:48 INFO 140645276194624] Epoch[55] Batch[0] avg_epoch_loss=2.614113\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:48 INFO 140645276194624] #quality_metric: host=algo-1, epoch=55, batch=0 train loss <loss>=2.614112854\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:48 INFO 140645276194624] Epoch[55] Batch[5] avg_epoch_loss=2.677136\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:48 INFO 140645276194624] #quality_metric: host=algo-1, epoch=55, batch=5 train loss <loss>=2.67713558674\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:48 INFO 140645276194624] Epoch[55] Batch [5]#011Speed: 2002.25 samples/sec#011loss=2.677136\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:49 INFO 140645276194624] Epoch[55] Batch[10] avg_epoch_loss=2.899021\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:49 INFO 140645276194624] #quality_metric: host=algo-1, epoch=55, batch=10 train loss <loss>=3.16528315544\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:49 INFO 140645276194624] Epoch[55] Batch [10]#011Speed: 1967.44 samples/sec#011loss=3.165283\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:49 INFO 140645276194624] processed a total of 643 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 543.1511402130127, \"sum\": 543.1511402130127, \"min\": 543.1511402130127}}, \"EndTime\": 1589566069.155051, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566068.611411}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:49 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1183.5166892 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:49 INFO 140645276194624] #progress_metric: host=algo-1, completed 14 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:49 INFO 140645276194624] #quality_metric: host=algo-1, epoch=55, train loss <loss>=2.89902084524\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:49 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:49 INFO 140645276194624] Epoch[56] Batch[0] avg_epoch_loss=2.782882\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:49 INFO 140645276194624] #quality_metric: host=algo-1, epoch=56, batch=0 train loss <loss>=2.78288197517\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:49 INFO 140645276194624] Epoch[56] Batch[5] avg_epoch_loss=2.791419\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:49 INFO 140645276194624] #quality_metric: host=algo-1, epoch=56, batch=5 train loss <loss>=2.79141875108\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:49 INFO 140645276194624] Epoch[56] Batch [5]#011Speed: 1962.24 samples/sec#011loss=2.791419\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:49 INFO 140645276194624] processed a total of 628 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 556.818962097168, \"sum\": 556.818962097168, \"min\": 556.818962097168}}, \"EndTime\": 1589566069.71244, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566069.155155}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:49 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1127.62850401 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:49 INFO 140645276194624] #progress_metric: host=algo-1, completed 14 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:49 INFO 140645276194624] #quality_metric: host=algo-1, epoch=56, train loss <loss>=2.76728925705\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:49 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:49 INFO 140645276194624] Epoch[57] Batch[0] avg_epoch_loss=2.628201\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:49 INFO 140645276194624] #quality_metric: host=algo-1, epoch=57, batch=0 train loss <loss>=2.62820100784\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:50 INFO 140645276194624] Epoch[57] Batch[5] avg_epoch_loss=2.683560\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:50 INFO 140645276194624] #quality_metric: host=algo-1, epoch=57, batch=5 train loss <loss>=2.68356021245\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:50 INFO 140645276194624] Epoch[57] Batch [5]#011Speed: 1996.82 samples/sec#011loss=2.683560\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:50 INFO 140645276194624] processed a total of 631 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 510.7741355895996, \"sum\": 510.7741355895996, \"min\": 510.7741355895996}}, \"EndTime\": 1589566070.223757, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566069.712511}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:50 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1235.13121735 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:50 INFO 140645276194624] #progress_metric: host=algo-1, completed 14 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:50 INFO 140645276194624] #quality_metric: host=algo-1, epoch=57, train loss <loss>=2.68219511509\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:50 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:50 INFO 140645276194624] Epoch[58] Batch[0] avg_epoch_loss=2.625875\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:50 INFO 140645276194624] #quality_metric: host=algo-1, epoch=58, batch=0 train loss <loss>=2.62587499619\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:50 INFO 140645276194624] Epoch[58] Batch[5] avg_epoch_loss=2.686966\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:50 INFO 140645276194624] #quality_metric: host=algo-1, epoch=58, batch=5 train loss <loss>=2.68696606159\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:50 INFO 140645276194624] Epoch[58] Batch [5]#011Speed: 1969.54 samples/sec#011loss=2.686966\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:50 INFO 140645276194624] Epoch[58] Batch[10] avg_epoch_loss=2.655793\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:50 INFO 140645276194624] #quality_metric: host=algo-1, epoch=58, batch=10 train loss <loss>=2.61838450432\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:50 INFO 140645276194624] Epoch[58] Batch [10]#011Speed: 1705.89 samples/sec#011loss=2.618385\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:50 INFO 140645276194624] processed a total of 671 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 572.3268985748291, \"sum\": 572.3268985748291, \"min\": 572.3268985748291}}, \"EndTime\": 1589566070.796658, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566070.223827}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:50 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1172.18959432 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:50 INFO 140645276194624] #progress_metric: host=algo-1, completed 14 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:50 INFO 140645276194624] #quality_metric: host=algo-1, epoch=58, train loss <loss>=2.65579262647\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:50 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:51 INFO 140645276194624] Epoch[59] Batch[0] avg_epoch_loss=2.721908\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:51 INFO 140645276194624] #quality_metric: host=algo-1, epoch=59, batch=0 train loss <loss>=2.72190761566\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:51 INFO 140645276194624] Epoch[59] Batch[5] avg_epoch_loss=2.677993\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:51 INFO 140645276194624] #quality_metric: host=algo-1, epoch=59, batch=5 train loss <loss>=2.67799305916\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:51 INFO 140645276194624] Epoch[59] Batch [5]#011Speed: 1890.93 samples/sec#011loss=2.677993\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:51 INFO 140645276194624] processed a total of 631 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 542.0329570770264, \"sum\": 542.0329570770264, \"min\": 542.0329570770264}}, \"EndTime\": 1589566071.339195, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566070.796727}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:51 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1163.87834758 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:51 INFO 140645276194624] #progress_metric: host=algo-1, completed 15 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:51 INFO 140645276194624] #quality_metric: host=algo-1, epoch=59, train loss <loss>=2.64086828232\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:51 INFO 140645276194624] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:51 INFO 140645276194624] Saved checkpoint to \"/opt/ml/model/state_d8fa9364-39c5-4d8e-b81e-3f33f7884749-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 13.426065444946289, \"sum\": 13.426065444946289, \"min\": 13.426065444946289}}, \"EndTime\": 1589566071.353205, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566071.339277}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:51 INFO 140645276194624] Epoch[60] Batch[0] avg_epoch_loss=2.630993\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:51 INFO 140645276194624] #quality_metric: host=algo-1, epoch=60, batch=0 train loss <loss>=2.63099336624\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:51 INFO 140645276194624] Epoch[60] Batch[5] avg_epoch_loss=2.652240\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:51 INFO 140645276194624] #quality_metric: host=algo-1, epoch=60, batch=5 train loss <loss>=2.65223952134\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:51 INFO 140645276194624] Epoch[60] Batch [5]#011Speed: 2000.28 samples/sec#011loss=2.652240\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:51 INFO 140645276194624] processed a total of 619 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 510.08081436157227, \"sum\": 510.08081436157227, \"min\": 510.08081436157227}}, \"EndTime\": 1589566071.863424, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566071.353279}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:51 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1213.28536907 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:51 INFO 140645276194624] #progress_metric: host=algo-1, completed 15 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:51 INFO 140645276194624] #quality_metric: host=algo-1, epoch=60, train loss <loss>=2.64027993679\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:51 INFO 140645276194624] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:51 INFO 140645276194624] Saved checkpoint to \"/opt/ml/model/state_2cd4c221-bbc9-4d84-8be3-5ff2fd018624-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 12.172937393188477, \"sum\": 12.172937393188477, \"min\": 12.172937393188477}}, \"EndTime\": 1589566071.876177, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566071.863489}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:52 INFO 140645276194624] Epoch[61] Batch[0] avg_epoch_loss=2.743074\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:52 INFO 140645276194624] #quality_metric: host=algo-1, epoch=61, batch=0 train loss <loss>=2.74307394028\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:52 INFO 140645276194624] Epoch[61] Batch[5] avg_epoch_loss=2.691503\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:52 INFO 140645276194624] #quality_metric: host=algo-1, epoch=61, batch=5 train loss <loss>=2.69150257111\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:52 INFO 140645276194624] Epoch[61] Batch [5]#011Speed: 1759.04 samples/sec#011loss=2.691503\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:52 INFO 140645276194624] processed a total of 639 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 552.5460243225098, \"sum\": 552.5460243225098, \"min\": 552.5460243225098}}, \"EndTime\": 1589566072.428848, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566071.876246}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:52 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1156.21580081 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:52 INFO 140645276194624] #progress_metric: host=algo-1, completed 15 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:52 INFO 140645276194624] #quality_metric: host=algo-1, epoch=61, train loss <loss>=2.64195196629\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:52 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:52 INFO 140645276194624] Epoch[62] Batch[0] avg_epoch_loss=2.644976\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:52 INFO 140645276194624] #quality_metric: host=algo-1, epoch=62, batch=0 train loss <loss>=2.64497637749\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:52 INFO 140645276194624] Epoch[62] Batch[5] avg_epoch_loss=2.644899\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:52 INFO 140645276194624] #quality_metric: host=algo-1, epoch=62, batch=5 train loss <loss>=2.6448987325\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:52 INFO 140645276194624] Epoch[62] Batch [5]#011Speed: 1993.93 samples/sec#011loss=2.644899\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:52 INFO 140645276194624] processed a total of 596 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 546.0309982299805, \"sum\": 546.0309982299805, \"min\": 546.0309982299805}}, \"EndTime\": 1589566072.975454, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566072.428931}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:52 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1091.3053658 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:52 INFO 140645276194624] #progress_metric: host=algo-1, completed 15 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:52 INFO 140645276194624] #quality_metric: host=algo-1, epoch=62, train loss <loss>=2.61575660706\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:52 INFO 140645276194624] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:52 INFO 140645276194624] Saved checkpoint to \"/opt/ml/model/state_7dfe1f0f-4835-4b69-8686-90b0e2d806b1-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 13.685941696166992, \"sum\": 13.685941696166992, \"min\": 13.685941696166992}}, \"EndTime\": 1589566072.989704, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566072.975527}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:53 INFO 140645276194624] Epoch[63] Batch[0] avg_epoch_loss=2.690850\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:53 INFO 140645276194624] #quality_metric: host=algo-1, epoch=63, batch=0 train loss <loss>=2.69085025787\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:53 INFO 140645276194624] Epoch[63] Batch[5] avg_epoch_loss=2.717477\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:53 INFO 140645276194624] #quality_metric: host=algo-1, epoch=63, batch=5 train loss <loss>=2.71747684479\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:53 INFO 140645276194624] Epoch[63] Batch [5]#011Speed: 2009.24 samples/sec#011loss=2.717477\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:53 INFO 140645276194624] Epoch[63] Batch[10] avg_epoch_loss=2.764127\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:53 INFO 140645276194624] #quality_metric: host=algo-1, epoch=63, batch=10 train loss <loss>=2.8201066494\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:53 INFO 140645276194624] Epoch[63] Batch [10]#011Speed: 1921.62 samples/sec#011loss=2.820107\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:53 INFO 140645276194624] processed a total of 668 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 551.6490936279297, \"sum\": 551.6490936279297, \"min\": 551.6490936279297}}, \"EndTime\": 1589566073.541483, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566072.989769}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:53 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1210.67139794 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:53 INFO 140645276194624] #progress_metric: host=algo-1, completed 16 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:53 INFO 140645276194624] #quality_metric: host=algo-1, epoch=63, train loss <loss>=2.76412675597\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:53 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:53 INFO 140645276194624] Epoch[64] Batch[0] avg_epoch_loss=2.553363\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:53 INFO 140645276194624] #quality_metric: host=algo-1, epoch=64, batch=0 train loss <loss>=2.55336308479\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:53 INFO 140645276194624] Epoch[64] Batch[5] avg_epoch_loss=2.687776\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:53 INFO 140645276194624] #quality_metric: host=algo-1, epoch=64, batch=5 train loss <loss>=2.68777557214\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:53 INFO 140645276194624] Epoch[64] Batch [5]#011Speed: 1812.86 samples/sec#011loss=2.687776\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:54 INFO 140645276194624] processed a total of 617 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 548.5520362854004, \"sum\": 548.5520362854004, \"min\": 548.5520362854004}}, \"EndTime\": 1589566074.090527, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566073.541559}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:54 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1124.56428507 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:54 INFO 140645276194624] #progress_metric: host=algo-1, completed 16 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:54 INFO 140645276194624] #quality_metric: host=algo-1, epoch=64, train loss <loss>=2.66743984222\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:54 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:54 INFO 140645276194624] Epoch[65] Batch[0] avg_epoch_loss=2.695848\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:54 INFO 140645276194624] #quality_metric: host=algo-1, epoch=65, batch=0 train loss <loss>=2.69584846497\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:54 INFO 140645276194624] Epoch[65] Batch[5] avg_epoch_loss=2.692894\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:54 INFO 140645276194624] #quality_metric: host=algo-1, epoch=65, batch=5 train loss <loss>=2.6928943793\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:54 INFO 140645276194624] Epoch[65] Batch [5]#011Speed: 2006.68 samples/sec#011loss=2.692894\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:54 INFO 140645276194624] processed a total of 594 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 526.5898704528809, \"sum\": 526.5898704528809, \"min\": 526.5898704528809}}, \"EndTime\": 1589566074.61765, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566074.090603}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:54 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1127.77259649 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:54 INFO 140645276194624] #progress_metric: host=algo-1, completed 16 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:54 INFO 140645276194624] #quality_metric: host=algo-1, epoch=65, train loss <loss>=2.70175800323\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:54 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:54 INFO 140645276194624] Epoch[66] Batch[0] avg_epoch_loss=2.552256\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:54 INFO 140645276194624] #quality_metric: host=algo-1, epoch=66, batch=0 train loss <loss>=2.55225586891\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:54 INFO 140645276194624] Epoch[66] Batch[5] avg_epoch_loss=2.642481\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:55 INFO 140645276194624] #quality_metric: host=algo-1, epoch=66, batch=5 train loss <loss>=2.64248085022\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:55 INFO 140645276194624] Epoch[66] Batch [5]#011Speed: 1994.66 samples/sec#011loss=2.642481\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:55 INFO 140645276194624] Epoch[66] Batch[10] avg_epoch_loss=2.653110\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:55 INFO 140645276194624] #quality_metric: host=algo-1, epoch=66, batch=10 train loss <loss>=2.66586494446\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:55 INFO 140645276194624] Epoch[66] Batch [10]#011Speed: 1950.50 samples/sec#011loss=2.665865\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:55 INFO 140645276194624] processed a total of 670 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 546.4920997619629, \"sum\": 546.4920997619629, \"min\": 546.4920997619629}}, \"EndTime\": 1589566075.16469, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566074.617722}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:55 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1225.7616804 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:55 INFO 140645276194624] #progress_metric: host=algo-1, completed 16 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:55 INFO 140645276194624] #quality_metric: host=algo-1, epoch=66, train loss <loss>=2.65310998396\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:55 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:55 INFO 140645276194624] Epoch[67] Batch[0] avg_epoch_loss=2.778814\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:55 INFO 140645276194624] #quality_metric: host=algo-1, epoch=67, batch=0 train loss <loss>=2.77881360054\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:55 INFO 140645276194624] Epoch[67] Batch[5] avg_epoch_loss=2.655526\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:55 INFO 140645276194624] #quality_metric: host=algo-1, epoch=67, batch=5 train loss <loss>=2.65552576383\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:55 INFO 140645276194624] Epoch[67] Batch [5]#011Speed: 1958.76 samples/sec#011loss=2.655526\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:55 INFO 140645276194624] processed a total of 640 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 520.5490589141846, \"sum\": 520.5490589141846, \"min\": 520.5490589141846}}, \"EndTime\": 1589566075.685729, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566075.164758}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:55 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1229.26329961 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:55 INFO 140645276194624] #progress_metric: host=algo-1, completed 17 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:55 INFO 140645276194624] #quality_metric: host=algo-1, epoch=67, train loss <loss>=2.62915420532\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:55 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:55 INFO 140645276194624] Epoch[68] Batch[0] avg_epoch_loss=2.718496\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:55 INFO 140645276194624] #quality_metric: host=algo-1, epoch=68, batch=0 train loss <loss>=2.71849632263\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:56 INFO 140645276194624] Epoch[68] Batch[5] avg_epoch_loss=2.697446\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:56 INFO 140645276194624] #quality_metric: host=algo-1, epoch=68, batch=5 train loss <loss>=2.69744578997\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:56 INFO 140645276194624] Epoch[68] Batch [5]#011Speed: 2019.10 samples/sec#011loss=2.697446\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:56 INFO 140645276194624] Epoch[68] Batch[10] avg_epoch_loss=2.670617\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:56 INFO 140645276194624] #quality_metric: host=algo-1, epoch=68, batch=10 train loss <loss>=2.63842225075\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:56 INFO 140645276194624] Epoch[68] Batch [10]#011Speed: 1955.77 samples/sec#011loss=2.638422\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:56 INFO 140645276194624] processed a total of 676 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 545.6819534301758, \"sum\": 545.6819534301758, \"min\": 545.6819534301758}}, \"EndTime\": 1589566076.231944, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566075.685788}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:56 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1238.58307138 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:56 INFO 140645276194624] #progress_metric: host=algo-1, completed 17 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:56 INFO 140645276194624] #quality_metric: host=algo-1, epoch=68, train loss <loss>=2.67061690851\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:56 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:56 INFO 140645276194624] Epoch[69] Batch[0] avg_epoch_loss=2.663828\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:56 INFO 140645276194624] #quality_metric: host=algo-1, epoch=69, batch=0 train loss <loss>=2.66382837296\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:56 INFO 140645276194624] Epoch[69] Batch[5] avg_epoch_loss=2.663557\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:56 INFO 140645276194624] #quality_metric: host=algo-1, epoch=69, batch=5 train loss <loss>=2.66355709235\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:56 INFO 140645276194624] Epoch[69] Batch [5]#011Speed: 1951.89 samples/sec#011loss=2.663557\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:56 INFO 140645276194624] Epoch[69] Batch[10] avg_epoch_loss=2.621493\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:56 INFO 140645276194624] #quality_metric: host=algo-1, epoch=69, batch=10 train loss <loss>=2.57101716995\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:56 INFO 140645276194624] Epoch[69] Batch [10]#011Speed: 1940.04 samples/sec#011loss=2.571017\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:56 INFO 140645276194624] processed a total of 680 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 563.8730525970459, \"sum\": 563.8730525970459, \"min\": 563.8730525970459}}, \"EndTime\": 1589566076.796299, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566076.232017}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:56 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1205.70610148 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:56 INFO 140645276194624] #progress_metric: host=algo-1, completed 17 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:56 INFO 140645276194624] #quality_metric: host=algo-1, epoch=69, train loss <loss>=2.62149349126\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:56 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:57 INFO 140645276194624] Epoch[70] Batch[0] avg_epoch_loss=2.775956\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:57 INFO 140645276194624] #quality_metric: host=algo-1, epoch=70, batch=0 train loss <loss>=2.77595615387\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:57 INFO 140645276194624] Epoch[70] Batch[5] avg_epoch_loss=2.679003\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:57 INFO 140645276194624] #quality_metric: host=algo-1, epoch=70, batch=5 train loss <loss>=2.6790027221\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:57 INFO 140645276194624] Epoch[70] Batch [5]#011Speed: 1986.61 samples/sec#011loss=2.679003\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:57 INFO 140645276194624] processed a total of 608 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 517.1120166778564, \"sum\": 517.1120166778564, \"min\": 517.1120166778564}}, \"EndTime\": 1589566077.313936, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566076.796372}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:57 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1175.51520851 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:57 INFO 140645276194624] #progress_metric: host=algo-1, completed 17 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:57 INFO 140645276194624] #quality_metric: host=algo-1, epoch=70, train loss <loss>=2.64032869339\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:57 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:57 INFO 140645276194624] Epoch[71] Batch[0] avg_epoch_loss=2.668695\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:57 INFO 140645276194624] #quality_metric: host=algo-1, epoch=71, batch=0 train loss <loss>=2.66869521141\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:57 INFO 140645276194624] Epoch[71] Batch[5] avg_epoch_loss=2.652549\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:57 INFO 140645276194624] #quality_metric: host=algo-1, epoch=71, batch=5 train loss <loss>=2.65254918734\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:57 INFO 140645276194624] Epoch[71] Batch [5]#011Speed: 1781.12 samples/sec#011loss=2.652549\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:57 INFO 140645276194624] Epoch[71] Batch[10] avg_epoch_loss=2.629854\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:57 INFO 140645276194624] #quality_metric: host=algo-1, epoch=71, batch=10 train loss <loss>=2.60261898041\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:57 INFO 140645276194624] Epoch[71] Batch [10]#011Speed: 1958.95 samples/sec#011loss=2.602619\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:57 INFO 140645276194624] processed a total of 644 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 580.9459686279297, \"sum\": 580.9459686279297, \"min\": 580.9459686279297}}, \"EndTime\": 1589566077.895416, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566077.314003}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:57 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1108.32895699 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:57 INFO 140645276194624] #progress_metric: host=algo-1, completed 18 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:57 INFO 140645276194624] #quality_metric: host=algo-1, epoch=71, train loss <loss>=2.62985363874\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:57 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:58 INFO 140645276194624] Epoch[72] Batch[0] avg_epoch_loss=2.641102\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:58 INFO 140645276194624] #quality_metric: host=algo-1, epoch=72, batch=0 train loss <loss>=2.64110183716\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:58 INFO 140645276194624] Epoch[72] Batch[5] avg_epoch_loss=2.593201\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:58 INFO 140645276194624] #quality_metric: host=algo-1, epoch=72, batch=5 train loss <loss>=2.59320088228\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:58 INFO 140645276194624] Epoch[72] Batch [5]#011Speed: 1989.69 samples/sec#011loss=2.593201\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:58 INFO 140645276194624] Epoch[72] Batch[10] avg_epoch_loss=2.608682\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:58 INFO 140645276194624] #quality_metric: host=algo-1, epoch=72, batch=10 train loss <loss>=2.6272585392\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:58 INFO 140645276194624] Epoch[72] Batch [10]#011Speed: 1849.48 samples/sec#011loss=2.627259\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:58 INFO 140645276194624] processed a total of 681 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 566.4050579071045, \"sum\": 566.4050579071045, \"min\": 566.4050579071045}}, \"EndTime\": 1589566078.462394, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566077.895493}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:58 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1202.08448324 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:58 INFO 140645276194624] #progress_metric: host=algo-1, completed 18 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:58 INFO 140645276194624] #quality_metric: host=algo-1, epoch=72, train loss <loss>=2.60868163542\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:58 INFO 140645276194624] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:58 INFO 140645276194624] Saved checkpoint to \"/opt/ml/model/state_fde70e5e-aa31-42fa-b102-8de4ea957b45-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 20.040035247802734, \"sum\": 20.040035247802734, \"min\": 20.040035247802734}}, \"EndTime\": 1589566078.482982, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566078.46247}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:58 INFO 140645276194624] Epoch[73] Batch[0] avg_epoch_loss=2.708746\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:58 INFO 140645276194624] #quality_metric: host=algo-1, epoch=73, batch=0 train loss <loss>=2.70874643326\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:58 INFO 140645276194624] Epoch[73] Batch[5] avg_epoch_loss=2.642452\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:58 INFO 140645276194624] #quality_metric: host=algo-1, epoch=73, batch=5 train loss <loss>=2.64245160421\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:58 INFO 140645276194624] Epoch[73] Batch [5]#011Speed: 2003.34 samples/sec#011loss=2.642452\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:59 INFO 140645276194624] processed a total of 617 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 520.7312107086182, \"sum\": 520.7312107086182, \"min\": 520.7312107086182}}, \"EndTime\": 1589566079.003853, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566078.483057}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:59 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1184.62228562 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:59 INFO 140645276194624] #progress_metric: host=algo-1, completed 18 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:59 INFO 140645276194624] #quality_metric: host=algo-1, epoch=73, train loss <loss>=2.62763745785\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:59 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:59 INFO 140645276194624] Epoch[74] Batch[0] avg_epoch_loss=2.649167\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:59 INFO 140645276194624] #quality_metric: host=algo-1, epoch=74, batch=0 train loss <loss>=2.64916729927\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:59 INFO 140645276194624] Epoch[74] Batch[5] avg_epoch_loss=2.637619\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:59 INFO 140645276194624] #quality_metric: host=algo-1, epoch=74, batch=5 train loss <loss>=2.6376191775\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:59 INFO 140645276194624] Epoch[74] Batch [5]#011Speed: 1729.45 samples/sec#011loss=2.637619\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:59 INFO 140645276194624] Epoch[74] Batch[10] avg_epoch_loss=2.577367\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:59 INFO 140645276194624] #quality_metric: host=algo-1, epoch=74, batch=10 train loss <loss>=2.50506434441\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:59 INFO 140645276194624] Epoch[74] Batch [10]#011Speed: 1955.44 samples/sec#011loss=2.505064\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:59 INFO 140645276194624] processed a total of 660 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 568.0520534515381, \"sum\": 568.0520534515381, \"min\": 568.0520534515381}}, \"EndTime\": 1589566079.572465, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566079.003924}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:59 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1161.632304 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:59 INFO 140645276194624] #progress_metric: host=algo-1, completed 18 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:59 INFO 140645276194624] #quality_metric: host=algo-1, epoch=74, train loss <loss>=2.57736698064\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:59 INFO 140645276194624] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:59 INFO 140645276194624] Saved checkpoint to \"/opt/ml/model/state_2882df06-5053-48b8-a73a-63e258b87cb6-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 20.148038864135742, \"sum\": 20.148038864135742, \"min\": 20.148038864135742}}, \"EndTime\": 1589566079.593149, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566079.572542}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:59 INFO 140645276194624] Epoch[75] Batch[0] avg_epoch_loss=2.680056\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:07:59 INFO 140645276194624] #quality_metric: host=algo-1, epoch=75, batch=0 train loss <loss>=2.68005609512\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:00 INFO 140645276194624] Epoch[75] Batch[5] avg_epoch_loss=2.588125\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:00 INFO 140645276194624] #quality_metric: host=algo-1, epoch=75, batch=5 train loss <loss>=2.58812510967\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:00 INFO 140645276194624] Epoch[75] Batch [5]#011Speed: 2002.07 samples/sec#011loss=2.588125\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:00 INFO 140645276194624] processed a total of 608 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 591.2790298461914, \"sum\": 591.2790298461914, \"min\": 591.2790298461914}}, \"EndTime\": 1589566080.184561, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566079.593224}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:00 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1028.10396436 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:00 INFO 140645276194624] #progress_metric: host=algo-1, completed 19 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:00 INFO 140645276194624] #quality_metric: host=algo-1, epoch=75, train loss <loss>=2.66606616974\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:00 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:00 INFO 140645276194624] Epoch[76] Batch[0] avg_epoch_loss=2.785122\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:00 INFO 140645276194624] #quality_metric: host=algo-1, epoch=76, batch=0 train loss <loss>=2.78512167931\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:00 INFO 140645276194624] Epoch[76] Batch[5] avg_epoch_loss=2.698705\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:00 INFO 140645276194624] #quality_metric: host=algo-1, epoch=76, batch=5 train loss <loss>=2.69870515664\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:00 INFO 140645276194624] Epoch[76] Batch [5]#011Speed: 1981.97 samples/sec#011loss=2.698705\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:00 INFO 140645276194624] processed a total of 625 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 512.2599601745605, \"sum\": 512.2599601745605, \"min\": 512.2599601745605}}, \"EndTime\": 1589566080.697362, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566080.184629}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:00 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1219.84292214 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:00 INFO 140645276194624] #progress_metric: host=algo-1, completed 19 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:00 INFO 140645276194624] #quality_metric: host=algo-1, epoch=76, train loss <loss>=2.7275673151\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:00 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:00 INFO 140645276194624] Epoch[77] Batch[0] avg_epoch_loss=2.650634\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:00 INFO 140645276194624] #quality_metric: host=algo-1, epoch=77, batch=0 train loss <loss>=2.65063357353\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:01 INFO 140645276194624] Epoch[77] Batch[5] avg_epoch_loss=2.685607\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:01 INFO 140645276194624] #quality_metric: host=algo-1, epoch=77, batch=5 train loss <loss>=2.68560679754\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:01 INFO 140645276194624] Epoch[77] Batch [5]#011Speed: 1904.19 samples/sec#011loss=2.685607\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:01 INFO 140645276194624] Epoch[77] Batch[10] avg_epoch_loss=2.681387\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:01 INFO 140645276194624] #quality_metric: host=algo-1, epoch=77, batch=10 train loss <loss>=2.67632255554\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:01 INFO 140645276194624] Epoch[77] Batch [10]#011Speed: 1954.27 samples/sec#011loss=2.676323\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:01 INFO 140645276194624] processed a total of 644 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 549.5970249176025, \"sum\": 549.5970249176025, \"min\": 549.5970249176025}}, \"EndTime\": 1589566081.247485, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566080.697425}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:01 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1171.53130278 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:01 INFO 140645276194624] #progress_metric: host=algo-1, completed 19 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:01 INFO 140645276194624] #quality_metric: host=algo-1, epoch=77, train loss <loss>=2.68138668754\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:01 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:01 INFO 140645276194624] Epoch[78] Batch[0] avg_epoch_loss=2.682301\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:01 INFO 140645276194624] #quality_metric: host=algo-1, epoch=78, batch=0 train loss <loss>=2.68230128288\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:01 INFO 140645276194624] Epoch[78] Batch[5] avg_epoch_loss=2.662795\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:01 INFO 140645276194624] #quality_metric: host=algo-1, epoch=78, batch=5 train loss <loss>=2.66279455026\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:01 INFO 140645276194624] Epoch[78] Batch [5]#011Speed: 1940.82 samples/sec#011loss=2.662795\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:01 INFO 140645276194624] Epoch[78] Batch[10] avg_epoch_loss=2.675638\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:01 INFO 140645276194624] #quality_metric: host=algo-1, epoch=78, batch=10 train loss <loss>=2.69104971886\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:01 INFO 140645276194624] Epoch[78] Batch [10]#011Speed: 1856.86 samples/sec#011loss=2.691050\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:01 INFO 140645276194624] processed a total of 665 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 574.7990608215332, \"sum\": 574.7990608215332, \"min\": 574.7990608215332}}, \"EndTime\": 1589566081.822794, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566081.247561}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:01 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1156.72692331 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:01 INFO 140645276194624] #progress_metric: host=algo-1, completed 19 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:01 INFO 140645276194624] #quality_metric: host=algo-1, epoch=78, train loss <loss>=2.67563780871\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:01 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:02 INFO 140645276194624] Epoch[79] Batch[0] avg_epoch_loss=2.754361\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:02 INFO 140645276194624] #quality_metric: host=algo-1, epoch=79, batch=0 train loss <loss>=2.75436115265\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:02 INFO 140645276194624] Epoch[79] Batch[5] avg_epoch_loss=2.808061\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:02 INFO 140645276194624] #quality_metric: host=algo-1, epoch=79, batch=5 train loss <loss>=2.80806100368\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:02 INFO 140645276194624] Epoch[79] Batch [5]#011Speed: 1973.96 samples/sec#011loss=2.808061\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:02 INFO 140645276194624] Epoch[79] Batch[10] avg_epoch_loss=2.842038\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:02 INFO 140645276194624] #quality_metric: host=algo-1, epoch=79, batch=10 train loss <loss>=2.88280949593\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:02 INFO 140645276194624] Epoch[79] Batch [10]#011Speed: 1469.39 samples/sec#011loss=2.882809\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:02 INFO 140645276194624] processed a total of 660 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 615.4770851135254, \"sum\": 615.4770851135254, \"min\": 615.4770851135254}}, \"EndTime\": 1589566082.438846, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566081.822857}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:02 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1072.14574337 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:02 INFO 140645276194624] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:02 INFO 140645276194624] #quality_metric: host=algo-1, epoch=79, train loss <loss>=2.84203759107\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:02 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:02 INFO 140645276194624] Epoch[80] Batch[0] avg_epoch_loss=3.858674\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:02 INFO 140645276194624] #quality_metric: host=algo-1, epoch=80, batch=0 train loss <loss>=3.85867381096\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:02 INFO 140645276194624] Epoch[80] Batch[5] avg_epoch_loss=3.217602\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:02 INFO 140645276194624] #quality_metric: host=algo-1, epoch=80, batch=5 train loss <loss>=3.21760189533\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:02 INFO 140645276194624] Epoch[80] Batch [5]#011Speed: 1958.61 samples/sec#011loss=3.217602\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:03 INFO 140645276194624] Epoch[80] Batch[10] avg_epoch_loss=3.102553\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:03 INFO 140645276194624] #quality_metric: host=algo-1, epoch=80, batch=10 train loss <loss>=2.96449513435\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:03 INFO 140645276194624] Epoch[80] Batch [10]#011Speed: 1942.70 samples/sec#011loss=2.964495\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:03 INFO 140645276194624] processed a total of 663 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 591.0358428955078, \"sum\": 591.0358428955078, \"min\": 591.0358428955078}}, \"EndTime\": 1589566083.030456, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566082.438921}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:03 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1121.55578733 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:03 INFO 140645276194624] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:03 INFO 140645276194624] #quality_metric: host=algo-1, epoch=80, train loss <loss>=3.10255336761\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:03 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:03 INFO 140645276194624] Epoch[81] Batch[0] avg_epoch_loss=2.751545\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:03 INFO 140645276194624] #quality_metric: host=algo-1, epoch=81, batch=0 train loss <loss>=2.75154519081\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:03 INFO 140645276194624] Epoch[81] Batch[5] avg_epoch_loss=2.793017\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:03 INFO 140645276194624] #quality_metric: host=algo-1, epoch=81, batch=5 train loss <loss>=2.79301699003\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:03 INFO 140645276194624] Epoch[81] Batch [5]#011Speed: 1973.44 samples/sec#011loss=2.793017\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:03 INFO 140645276194624] processed a total of 632 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 526.8399715423584, \"sum\": 526.8399715423584, \"min\": 526.8399715423584}}, \"EndTime\": 1589566083.557791, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566083.030528}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:03 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1199.36155673 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:03 INFO 140645276194624] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:03 INFO 140645276194624] #quality_metric: host=algo-1, epoch=81, train loss <loss>=2.77231934071\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:03 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:03 INFO 140645276194624] Epoch[82] Batch[0] avg_epoch_loss=2.646745\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:03 INFO 140645276194624] #quality_metric: host=algo-1, epoch=82, batch=0 train loss <loss>=2.64674544334\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:03 INFO 140645276194624] Epoch[82] Batch[5] avg_epoch_loss=2.699333\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:03 INFO 140645276194624] #quality_metric: host=algo-1, epoch=82, batch=5 train loss <loss>=2.69933267434\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:03 INFO 140645276194624] Epoch[82] Batch [5]#011Speed: 1963.24 samples/sec#011loss=2.699333\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:04 INFO 140645276194624] processed a total of 624 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 520.6718444824219, \"sum\": 520.6718444824219, \"min\": 520.6718444824219}}, \"EndTime\": 1589566084.079006, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566083.557862}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:04 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1198.19810852 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:04 INFO 140645276194624] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:04 INFO 140645276194624] #quality_metric: host=algo-1, epoch=82, train loss <loss>=2.68488852978\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:04 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:04 INFO 140645276194624] Epoch[83] Batch[0] avg_epoch_loss=2.741218\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:04 INFO 140645276194624] #quality_metric: host=algo-1, epoch=83, batch=0 train loss <loss>=2.74121809006\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:04 INFO 140645276194624] Epoch[83] Batch[5] avg_epoch_loss=2.662134\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:04 INFO 140645276194624] #quality_metric: host=algo-1, epoch=83, batch=5 train loss <loss>=2.66213385264\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:04 INFO 140645276194624] Epoch[83] Batch [5]#011Speed: 1836.96 samples/sec#011loss=2.662134\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:04 INFO 140645276194624] Epoch[83] Batch[10] avg_epoch_loss=2.643514\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:04 INFO 140645276194624] #quality_metric: host=algo-1, epoch=83, batch=10 train loss <loss>=2.62117109299\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:04 INFO 140645276194624] Epoch[83] Batch [10]#011Speed: 1889.88 samples/sec#011loss=2.621171\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:04 INFO 140645276194624] processed a total of 670 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 570.404052734375, \"sum\": 570.404052734375, \"min\": 570.404052734375}}, \"EndTime\": 1589566084.650003, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566084.079078}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:04 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1174.3649462 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:04 INFO 140645276194624] #progress_metric: host=algo-1, completed 21 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:04 INFO 140645276194624] #quality_metric: host=algo-1, epoch=83, train loss <loss>=2.64351441643\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:04 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:04 INFO 140645276194624] Epoch[84] Batch[0] avg_epoch_loss=2.811288\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:04 INFO 140645276194624] #quality_metric: host=algo-1, epoch=84, batch=0 train loss <loss>=2.81128764153\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:05 INFO 140645276194624] Epoch[84] Batch[5] avg_epoch_loss=2.727481\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:05 INFO 140645276194624] #quality_metric: host=algo-1, epoch=84, batch=5 train loss <loss>=2.72748128573\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:05 INFO 140645276194624] Epoch[84] Batch [5]#011Speed: 1963.92 samples/sec#011loss=2.727481\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:05 INFO 140645276194624] Epoch[84] Batch[10] avg_epoch_loss=2.681422\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:05 INFO 140645276194624] #quality_metric: host=algo-1, epoch=84, batch=10 train loss <loss>=2.62615103722\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:05 INFO 140645276194624] Epoch[84] Batch [10]#011Speed: 1919.08 samples/sec#011loss=2.626151\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:05 INFO 140645276194624] processed a total of 651 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 563.80295753479, \"sum\": 563.80295753479, \"min\": 563.80295753479}}, \"EndTime\": 1589566085.214337, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566084.65008}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:05 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1154.45172534 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:05 INFO 140645276194624] #progress_metric: host=algo-1, completed 21 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:05 INFO 140645276194624] #quality_metric: host=algo-1, epoch=84, train loss <loss>=2.68142208186\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:05 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:05 INFO 140645276194624] Epoch[85] Batch[0] avg_epoch_loss=2.670694\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:05 INFO 140645276194624] #quality_metric: host=algo-1, epoch=85, batch=0 train loss <loss>=2.67069387436\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:05 INFO 140645276194624] Epoch[85] Batch[5] avg_epoch_loss=2.716376\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:05 INFO 140645276194624] #quality_metric: host=algo-1, epoch=85, batch=5 train loss <loss>=2.71637554963\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:05 INFO 140645276194624] Epoch[85] Batch [5]#011Speed: 1868.54 samples/sec#011loss=2.716376\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:05 INFO 140645276194624] processed a total of 608 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 556.7190647125244, \"sum\": 556.7190647125244, \"min\": 556.7190647125244}}, \"EndTime\": 1589566085.771573, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566085.214398}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:05 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1091.90094121 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:05 INFO 140645276194624] #progress_metric: host=algo-1, completed 21 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:05 INFO 140645276194624] #quality_metric: host=algo-1, epoch=85, train loss <loss>=2.69921789169\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:05 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:05 INFO 140645276194624] Epoch[86] Batch[0] avg_epoch_loss=2.650352\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:05 INFO 140645276194624] #quality_metric: host=algo-1, epoch=86, batch=0 train loss <loss>=2.65035176277\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:06 INFO 140645276194624] Epoch[86] Batch[5] avg_epoch_loss=2.662852\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:06 INFO 140645276194624] #quality_metric: host=algo-1, epoch=86, batch=5 train loss <loss>=2.66285173098\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:06 INFO 140645276194624] Epoch[86] Batch [5]#011Speed: 1970.75 samples/sec#011loss=2.662852\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:06 INFO 140645276194624] processed a total of 599 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 513.7729644775391, \"sum\": 513.7729644775391, \"min\": 513.7729644775391}}, \"EndTime\": 1589566086.285881, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566085.771648}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:06 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1165.62823131 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:06 INFO 140645276194624] #progress_metric: host=algo-1, completed 21 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:06 INFO 140645276194624] #quality_metric: host=algo-1, epoch=86, train loss <loss>=2.6184180975\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:06 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:06 INFO 140645276194624] Epoch[87] Batch[0] avg_epoch_loss=2.591052\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:06 INFO 140645276194624] #quality_metric: host=algo-1, epoch=87, batch=0 train loss <loss>=2.59105205536\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:06 INFO 140645276194624] Epoch[87] Batch[5] avg_epoch_loss=2.596826\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:06 INFO 140645276194624] #quality_metric: host=algo-1, epoch=87, batch=5 train loss <loss>=2.59682607651\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:06 INFO 140645276194624] Epoch[87] Batch [5]#011Speed: 1610.68 samples/sec#011loss=2.596826\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:06 INFO 140645276194624] Epoch[87] Batch[10] avg_epoch_loss=2.546359\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:06 INFO 140645276194624] #quality_metric: host=algo-1, epoch=87, batch=10 train loss <loss>=2.48579821587\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:06 INFO 140645276194624] Epoch[87] Batch [10]#011Speed: 1961.11 samples/sec#011loss=2.485798\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:06 INFO 140645276194624] processed a total of 651 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 586.5781307220459, \"sum\": 586.5781307220459, \"min\": 586.5781307220459}}, \"EndTime\": 1589566086.872986, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566086.285963}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:06 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1109.61325119 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:06 INFO 140645276194624] #progress_metric: host=algo-1, completed 22 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:06 INFO 140645276194624] #quality_metric: host=algo-1, epoch=87, train loss <loss>=2.54635886713\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:06 INFO 140645276194624] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:06 INFO 140645276194624] Saved checkpoint to \"/opt/ml/model/state_a1ee0ec0-5498-4a09-b1c3-37737de7187b-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 20.05600929260254, \"sum\": 20.05600929260254, \"min\": 20.05600929260254}}, \"EndTime\": 1589566086.893591, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566086.873064}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:07 INFO 140645276194624] Epoch[88] Batch[0] avg_epoch_loss=2.677449\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:07 INFO 140645276194624] #quality_metric: host=algo-1, epoch=88, batch=0 train loss <loss>=2.67744922638\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:07 INFO 140645276194624] Epoch[88] Batch[5] avg_epoch_loss=2.651549\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:07 INFO 140645276194624] #quality_metric: host=algo-1, epoch=88, batch=5 train loss <loss>=2.65154854457\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:07 INFO 140645276194624] Epoch[88] Batch [5]#011Speed: 1951.54 samples/sec#011loss=2.651549\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:07 INFO 140645276194624] processed a total of 617 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 548.5391616821289, \"sum\": 548.5391616821289, \"min\": 548.5391616821289}}, \"EndTime\": 1589566087.442278, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566086.893673}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:07 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1124.56233036 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:07 INFO 140645276194624] #progress_metric: host=algo-1, completed 22 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:07 INFO 140645276194624] #quality_metric: host=algo-1, epoch=88, train loss <loss>=2.62238035202\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:07 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:07 INFO 140645276194624] Epoch[89] Batch[0] avg_epoch_loss=2.551654\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:07 INFO 140645276194624] #quality_metric: host=algo-1, epoch=89, batch=0 train loss <loss>=2.55165433884\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:07 INFO 140645276194624] Epoch[89] Batch[5] avg_epoch_loss=2.550075\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:07 INFO 140645276194624] #quality_metric: host=algo-1, epoch=89, batch=5 train loss <loss>=2.55007477601\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:07 INFO 140645276194624] Epoch[89] Batch [5]#011Speed: 1996.41 samples/sec#011loss=2.550075\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:07 INFO 140645276194624] processed a total of 624 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 529.7291278839111, \"sum\": 529.7291278839111, \"min\": 529.7291278839111}}, \"EndTime\": 1589566087.972544, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566087.44236}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:07 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1177.72941226 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:07 INFO 140645276194624] #progress_metric: host=algo-1, completed 22 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:07 INFO 140645276194624] #quality_metric: host=algo-1, epoch=89, train loss <loss>=2.57189030647\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:07 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:08 INFO 140645276194624] Epoch[90] Batch[0] avg_epoch_loss=2.600131\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:08 INFO 140645276194624] #quality_metric: host=algo-1, epoch=90, batch=0 train loss <loss>=2.60013103485\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:08 INFO 140645276194624] Epoch[90] Batch[5] avg_epoch_loss=2.607997\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:08 INFO 140645276194624] #quality_metric: host=algo-1, epoch=90, batch=5 train loss <loss>=2.60799690088\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:08 INFO 140645276194624] Epoch[90] Batch [5]#011Speed: 1866.55 samples/sec#011loss=2.607997\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:08 INFO 140645276194624] Epoch[90] Batch[10] avg_epoch_loss=2.578370\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:08 INFO 140645276194624] #quality_metric: host=algo-1, epoch=90, batch=10 train loss <loss>=2.54281845093\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:08 INFO 140645276194624] Epoch[90] Batch [10]#011Speed: 1946.89 samples/sec#011loss=2.542818\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:08 INFO 140645276194624] processed a total of 664 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 556.0860633850098, \"sum\": 556.0860633850098, \"min\": 556.0860633850098}}, \"EndTime\": 1589566088.529194, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566087.972612}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:08 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1193.825862 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:08 INFO 140645276194624] #progress_metric: host=algo-1, completed 22 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:08 INFO 140645276194624] #quality_metric: host=algo-1, epoch=90, train loss <loss>=2.57837033272\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:08 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:08 INFO 140645276194624] Epoch[91] Batch[0] avg_epoch_loss=2.801089\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:08 INFO 140645276194624] #quality_metric: host=algo-1, epoch=91, batch=0 train loss <loss>=2.8010892868\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:08 INFO 140645276194624] Epoch[91] Batch[5] avg_epoch_loss=2.735124\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:08 INFO 140645276194624] #quality_metric: host=algo-1, epoch=91, batch=5 train loss <loss>=2.73512387276\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:08 INFO 140645276194624] Epoch[91] Batch [5]#011Speed: 1868.67 samples/sec#011loss=2.735124\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:09 INFO 140645276194624] Epoch[91] Batch[10] avg_epoch_loss=2.684984\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:09 INFO 140645276194624] #quality_metric: host=algo-1, epoch=91, batch=10 train loss <loss>=2.62481541634\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:09 INFO 140645276194624] Epoch[91] Batch [10]#011Speed: 1963.61 samples/sec#011loss=2.624815\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:09 INFO 140645276194624] processed a total of 654 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 578.8519382476807, \"sum\": 578.8519382476807, \"min\": 578.8519382476807}}, \"EndTime\": 1589566089.108532, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566088.529268}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:09 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1129.59973645 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:09 INFO 140645276194624] #progress_metric: host=algo-1, completed 23 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:09 INFO 140645276194624] #quality_metric: host=algo-1, epoch=91, train loss <loss>=2.68498366529\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:09 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:09 INFO 140645276194624] Epoch[92] Batch[0] avg_epoch_loss=2.522007\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:09 INFO 140645276194624] #quality_metric: host=algo-1, epoch=92, batch=0 train loss <loss>=2.52200698853\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:09 INFO 140645276194624] Epoch[92] Batch[5] avg_epoch_loss=2.539103\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:09 INFO 140645276194624] #quality_metric: host=algo-1, epoch=92, batch=5 train loss <loss>=2.53910263379\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:09 INFO 140645276194624] Epoch[92] Batch [5]#011Speed: 1863.60 samples/sec#011loss=2.539103\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:09 INFO 140645276194624] Epoch[92] Batch[10] avg_epoch_loss=2.633781\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:09 INFO 140645276194624] #quality_metric: host=algo-1, epoch=92, batch=10 train loss <loss>=2.7473959446\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:09 INFO 140645276194624] Epoch[92] Batch [10]#011Speed: 1913.48 samples/sec#011loss=2.747396\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:09 INFO 140645276194624] processed a total of 666 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 604.6559810638428, \"sum\": 604.6559810638428, \"min\": 604.6559810638428}}, \"EndTime\": 1589566089.713701, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566089.10861}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:09 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1101.24520133 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:09 INFO 140645276194624] #progress_metric: host=algo-1, completed 23 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:09 INFO 140645276194624] #quality_metric: host=algo-1, epoch=92, train loss <loss>=2.63378141143\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:09 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:09 INFO 140645276194624] Epoch[93] Batch[0] avg_epoch_loss=2.966516\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:09 INFO 140645276194624] #quality_metric: host=algo-1, epoch=93, batch=0 train loss <loss>=2.96651554108\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:10 INFO 140645276194624] Epoch[93] Batch[5] avg_epoch_loss=2.728843\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:10 INFO 140645276194624] #quality_metric: host=algo-1, epoch=93, batch=5 train loss <loss>=2.72884269555\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:10 INFO 140645276194624] Epoch[93] Batch [5]#011Speed: 1841.67 samples/sec#011loss=2.728843\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:10 INFO 140645276194624] Epoch[93] Batch[10] avg_epoch_loss=2.670303\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:10 INFO 140645276194624] #quality_metric: host=algo-1, epoch=93, batch=10 train loss <loss>=2.60005531311\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:10 INFO 140645276194624] Epoch[93] Batch [10]#011Speed: 1903.79 samples/sec#011loss=2.600055\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:10 INFO 140645276194624] processed a total of 669 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 587.8891944885254, \"sum\": 587.8891944885254, \"min\": 587.8891944885254}}, \"EndTime\": 1589566090.302084, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566089.713778}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:10 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1137.75498763 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:10 INFO 140645276194624] #progress_metric: host=algo-1, completed 23 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:10 INFO 140645276194624] #quality_metric: host=algo-1, epoch=93, train loss <loss>=2.67030297626\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:10 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:10 INFO 140645276194624] Epoch[94] Batch[0] avg_epoch_loss=2.493815\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:10 INFO 140645276194624] #quality_metric: host=algo-1, epoch=94, batch=0 train loss <loss>=2.49381494522\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:10 INFO 140645276194624] Epoch[94] Batch[5] avg_epoch_loss=2.553960\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:10 INFO 140645276194624] #quality_metric: host=algo-1, epoch=94, batch=5 train loss <loss>=2.55396012465\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:10 INFO 140645276194624] Epoch[94] Batch [5]#011Speed: 1835.55 samples/sec#011loss=2.553960\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:10 INFO 140645276194624] processed a total of 616 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 555.8500289916992, \"sum\": 555.8500289916992, \"min\": 555.8500289916992}}, \"EndTime\": 1589566090.858457, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566090.30216}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:10 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1108.00347879 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:10 INFO 140645276194624] #progress_metric: host=algo-1, completed 23 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:10 INFO 140645276194624] #quality_metric: host=algo-1, epoch=94, train loss <loss>=2.58383600712\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:10 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:11 INFO 140645276194624] Epoch[95] Batch[0] avg_epoch_loss=2.509783\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:11 INFO 140645276194624] #quality_metric: host=algo-1, epoch=95, batch=0 train loss <loss>=2.50978255272\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:11 INFO 140645276194624] Epoch[95] Batch[5] avg_epoch_loss=2.554952\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:11 INFO 140645276194624] #quality_metric: host=algo-1, epoch=95, batch=5 train loss <loss>=2.55495162805\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:11 INFO 140645276194624] Epoch[95] Batch [5]#011Speed: 1988.85 samples/sec#011loss=2.554952\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:11 INFO 140645276194624] processed a total of 634 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 515.0578022003174, \"sum\": 515.0578022003174, \"min\": 515.0578022003174}}, \"EndTime\": 1589566091.374089, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566090.858524}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:11 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1230.64269606 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:11 INFO 140645276194624] #progress_metric: host=algo-1, completed 24 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:11 INFO 140645276194624] #quality_metric: host=algo-1, epoch=95, train loss <loss>=2.5692461729\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:11 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:11 INFO 140645276194624] Epoch[96] Batch[0] avg_epoch_loss=2.517485\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:11 INFO 140645276194624] #quality_metric: host=algo-1, epoch=96, batch=0 train loss <loss>=2.51748466492\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:11 INFO 140645276194624] Epoch[96] Batch[5] avg_epoch_loss=2.571450\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:11 INFO 140645276194624] #quality_metric: host=algo-1, epoch=96, batch=5 train loss <loss>=2.57145035267\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:11 INFO 140645276194624] Epoch[96] Batch [5]#011Speed: 1938.36 samples/sec#011loss=2.571450\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:11 INFO 140645276194624] processed a total of 630 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 534.276008605957, \"sum\": 534.276008605957, \"min\": 534.276008605957}}, \"EndTime\": 1589566091.908891, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566091.374169}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:11 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1178.90539486 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:11 INFO 140645276194624] #progress_metric: host=algo-1, completed 24 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:11 INFO 140645276194624] #quality_metric: host=algo-1, epoch=96, train loss <loss>=2.57689113617\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:11 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:12 INFO 140645276194624] Epoch[97] Batch[0] avg_epoch_loss=2.545833\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:12 INFO 140645276194624] #quality_metric: host=algo-1, epoch=97, batch=0 train loss <loss>=2.54583287239\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:12 INFO 140645276194624] Epoch[97] Batch[5] avg_epoch_loss=2.508050\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:12 INFO 140645276194624] #quality_metric: host=algo-1, epoch=97, batch=5 train loss <loss>=2.50805040201\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:12 INFO 140645276194624] Epoch[97] Batch [5]#011Speed: 1979.74 samples/sec#011loss=2.508050\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:12 INFO 140645276194624] Epoch[97] Batch[10] avg_epoch_loss=2.527984\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:12 INFO 140645276194624] #quality_metric: host=algo-1, epoch=97, batch=10 train loss <loss>=2.55190353394\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:12 INFO 140645276194624] Epoch[97] Batch [10]#011Speed: 1929.95 samples/sec#011loss=2.551904\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:12 INFO 140645276194624] processed a total of 660 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 557.3520660400391, \"sum\": 557.3520660400391, \"min\": 557.3520660400391}}, \"EndTime\": 1589566092.46678, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566091.908971}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:12 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1183.93117373 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:12 INFO 140645276194624] #progress_metric: host=algo-1, completed 24 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:12 INFO 140645276194624] #quality_metric: host=algo-1, epoch=97, train loss <loss>=2.52798364379\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:12 INFO 140645276194624] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:12 INFO 140645276194624] Saved checkpoint to \"/opt/ml/model/state_fb3ab44b-74fc-41a4-9d40-fc933c574401-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 19.923925399780273, \"sum\": 19.923925399780273, \"min\": 19.923925399780273}}, \"EndTime\": 1589566092.487291, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566092.466857}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:12 INFO 140645276194624] Epoch[98] Batch[0] avg_epoch_loss=2.521698\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:12 INFO 140645276194624] #quality_metric: host=algo-1, epoch=98, batch=0 train loss <loss>=2.52169752121\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:12 INFO 140645276194624] Epoch[98] Batch[5] avg_epoch_loss=2.607834\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:12 INFO 140645276194624] #quality_metric: host=algo-1, epoch=98, batch=5 train loss <loss>=2.60783437888\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:12 INFO 140645276194624] Epoch[98] Batch [5]#011Speed: 1988.33 samples/sec#011loss=2.607834\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:13 INFO 140645276194624] Epoch[98] Batch[10] avg_epoch_loss=2.607055\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:13 INFO 140645276194624] #quality_metric: host=algo-1, epoch=98, batch=10 train loss <loss>=2.6061205864\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:13 INFO 140645276194624] Epoch[98] Batch [10]#011Speed: 1832.09 samples/sec#011loss=2.606121\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:13 INFO 140645276194624] processed a total of 677 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 585.3137969970703, \"sum\": 585.3137969970703, \"min\": 585.3137969970703}}, \"EndTime\": 1589566093.072749, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566092.487369}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:13 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1156.43066858 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:13 INFO 140645276194624] #progress_metric: host=algo-1, completed 24 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:13 INFO 140645276194624] #quality_metric: host=algo-1, epoch=98, train loss <loss>=2.6070553823\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:13 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:13 INFO 140645276194624] Epoch[99] Batch[0] avg_epoch_loss=2.522843\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:13 INFO 140645276194624] #quality_metric: host=algo-1, epoch=99, batch=0 train loss <loss>=2.5228433609\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:13 INFO 140645276194624] Epoch[99] Batch[5] avg_epoch_loss=2.602035\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:13 INFO 140645276194624] #quality_metric: host=algo-1, epoch=99, batch=5 train loss <loss>=2.602034688\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:13 INFO 140645276194624] Epoch[99] Batch [5]#011Speed: 1996.99 samples/sec#011loss=2.602035\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:13 INFO 140645276194624] processed a total of 637 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 519.8628902435303, \"sum\": 519.8628902435303, \"min\": 519.8628902435303}}, \"EndTime\": 1589566093.593159, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566093.072818}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:13 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1225.04497932 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:13 INFO 140645276194624] #progress_metric: host=algo-1, completed 25 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:13 INFO 140645276194624] #quality_metric: host=algo-1, epoch=99, train loss <loss>=2.62264740467\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:13 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:13 INFO 140645276194624] Epoch[100] Batch[0] avg_epoch_loss=2.774079\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:13 INFO 140645276194624] #quality_metric: host=algo-1, epoch=100, batch=0 train loss <loss>=2.77407860756\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:14 INFO 140645276194624] Epoch[100] Batch[5] avg_epoch_loss=2.637501\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:14 INFO 140645276194624] #quality_metric: host=algo-1, epoch=100, batch=5 train loss <loss>=2.63750096162\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:14 INFO 140645276194624] Epoch[100] Batch [5]#011Speed: 1955.83 samples/sec#011loss=2.637501\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:14 INFO 140645276194624] processed a total of 639 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 576.8599510192871, \"sum\": 576.8599510192871, \"min\": 576.8599510192871}}, \"EndTime\": 1589566094.170549, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566093.593241}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:14 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1107.49462753 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:14 INFO 140645276194624] #progress_metric: host=algo-1, completed 25 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:14 INFO 140645276194624] #quality_metric: host=algo-1, epoch=100, train loss <loss>=2.60855178833\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:14 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:14 INFO 140645276194624] Epoch[101] Batch[0] avg_epoch_loss=2.507572\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:14 INFO 140645276194624] #quality_metric: host=algo-1, epoch=101, batch=0 train loss <loss>=2.50757169724\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:14 INFO 140645276194624] Epoch[101] Batch[5] avg_epoch_loss=2.567233\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:14 INFO 140645276194624] #quality_metric: host=algo-1, epoch=101, batch=5 train loss <loss>=2.56723312537\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:14 INFO 140645276194624] Epoch[101] Batch [5]#011Speed: 1712.86 samples/sec#011loss=2.567233\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:14 INFO 140645276194624] Epoch[101] Batch[10] avg_epoch_loss=2.539196\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:14 INFO 140645276194624] #quality_metric: host=algo-1, epoch=101, batch=10 train loss <loss>=2.50555100441\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:14 INFO 140645276194624] Epoch[101] Batch [10]#011Speed: 1899.49 samples/sec#011loss=2.505551\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:14 INFO 140645276194624] processed a total of 647 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 614.1149997711182, \"sum\": 614.1149997711182, \"min\": 614.1149997711182}}, \"EndTime\": 1589566094.785195, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566094.17063}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:14 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1053.36825574 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:14 INFO 140645276194624] #progress_metric: host=algo-1, completed 25 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:14 INFO 140645276194624] #quality_metric: host=algo-1, epoch=101, train loss <loss>=2.53919579766\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:14 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:15 INFO 140645276194624] Epoch[102] Batch[0] avg_epoch_loss=2.734757\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:15 INFO 140645276194624] #quality_metric: host=algo-1, epoch=102, batch=0 train loss <loss>=2.73475718498\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:15 INFO 140645276194624] Epoch[102] Batch[5] avg_epoch_loss=2.536725\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:15 INFO 140645276194624] #quality_metric: host=algo-1, epoch=102, batch=5 train loss <loss>=2.53672540188\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:15 INFO 140645276194624] Epoch[102] Batch [5]#011Speed: 1903.60 samples/sec#011loss=2.536725\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:15 INFO 140645276194624] processed a total of 633 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 529.6590328216553, \"sum\": 529.6590328216553, \"min\": 529.6590328216553}}, \"EndTime\": 1589566095.315395, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566094.78526}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:15 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1194.89870883 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:15 INFO 140645276194624] #progress_metric: host=algo-1, completed 25 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:15 INFO 140645276194624] #quality_metric: host=algo-1, epoch=102, train loss <loss>=2.56131019592\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:15 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:15 INFO 140645276194624] Epoch[103] Batch[0] avg_epoch_loss=2.527442\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:15 INFO 140645276194624] #quality_metric: host=algo-1, epoch=103, batch=0 train loss <loss>=2.52744150162\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:15 INFO 140645276194624] Epoch[103] Batch[5] avg_epoch_loss=2.536481\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:15 INFO 140645276194624] #quality_metric: host=algo-1, epoch=103, batch=5 train loss <loss>=2.53648050626\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:15 INFO 140645276194624] Epoch[103] Batch [5]#011Speed: 1952.12 samples/sec#011loss=2.536481\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:15 INFO 140645276194624] Epoch[103] Batch[10] avg_epoch_loss=2.534523\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:15 INFO 140645276194624] #quality_metric: host=algo-1, epoch=103, batch=10 train loss <loss>=2.53217487335\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:15 INFO 140645276194624] Epoch[103] Batch [10]#011Speed: 1853.97 samples/sec#011loss=2.532175\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:15 INFO 140645276194624] processed a total of 709 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 607.7349185943604, \"sum\": 607.7349185943604, \"min\": 607.7349185943604}}, \"EndTime\": 1589566095.923698, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566095.315455}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:15 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1166.40238226 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:15 INFO 140645276194624] #progress_metric: host=algo-1, completed 26 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:15 INFO 140645276194624] #quality_metric: host=algo-1, epoch=103, train loss <loss>=2.61567370097\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:15 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:16 INFO 140645276194624] Epoch[104] Batch[0] avg_epoch_loss=3.724057\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:16 INFO 140645276194624] #quality_metric: host=algo-1, epoch=104, batch=0 train loss <loss>=3.72405695915\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:16 INFO 140645276194624] Epoch[104] Batch[5] avg_epoch_loss=3.091087\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:16 INFO 140645276194624] #quality_metric: host=algo-1, epoch=104, batch=5 train loss <loss>=3.09108650684\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:16 INFO 140645276194624] Epoch[104] Batch [5]#011Speed: 1993.00 samples/sec#011loss=3.091087\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:16 INFO 140645276194624] processed a total of 629 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 533.7119102478027, \"sum\": 533.7119102478027, \"min\": 533.7119102478027}}, \"EndTime\": 1589566096.457945, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566095.923779}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:16 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1178.26894298 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:16 INFO 140645276194624] #progress_metric: host=algo-1, completed 26 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:16 INFO 140645276194624] #quality_metric: host=algo-1, epoch=104, train loss <loss>=3.0178347826\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:16 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:16 INFO 140645276194624] Epoch[105] Batch[0] avg_epoch_loss=2.680617\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:16 INFO 140645276194624] #quality_metric: host=algo-1, epoch=105, batch=0 train loss <loss>=2.68061685562\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:16 INFO 140645276194624] Epoch[105] Batch[5] avg_epoch_loss=2.825774\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:16 INFO 140645276194624] #quality_metric: host=algo-1, epoch=105, batch=5 train loss <loss>=2.82577447097\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:16 INFO 140645276194624] Epoch[105] Batch [5]#011Speed: 1966.29 samples/sec#011loss=2.825774\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:16 INFO 140645276194624] processed a total of 624 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 516.765832901001, \"sum\": 516.765832901001, \"min\": 516.765832901001}}, \"EndTime\": 1589566096.975236, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566096.45803}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:16 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1207.29015604 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:16 INFO 140645276194624] #progress_metric: host=algo-1, completed 26 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:16 INFO 140645276194624] #quality_metric: host=algo-1, epoch=105, train loss <loss>=2.78669669628\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:16 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:17 INFO 140645276194624] Epoch[106] Batch[0] avg_epoch_loss=2.627876\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:17 INFO 140645276194624] #quality_metric: host=algo-1, epoch=106, batch=0 train loss <loss>=2.62787604332\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:17 INFO 140645276194624] Epoch[106] Batch[5] avg_epoch_loss=2.714211\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:17 INFO 140645276194624] #quality_metric: host=algo-1, epoch=106, batch=5 train loss <loss>=2.71421142419\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:17 INFO 140645276194624] Epoch[106] Batch [5]#011Speed: 1954.59 samples/sec#011loss=2.714211\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:17 INFO 140645276194624] processed a total of 577 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 518.0850028991699, \"sum\": 518.0850028991699, \"min\": 518.0850028991699}}, \"EndTime\": 1589566097.493837, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566096.975299}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:17 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1113.5211053 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:17 INFO 140645276194624] #progress_metric: host=algo-1, completed 26 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:17 INFO 140645276194624] #quality_metric: host=algo-1, epoch=106, train loss <loss>=2.70488269329\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:17 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:17 INFO 140645276194624] Epoch[107] Batch[0] avg_epoch_loss=2.642536\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:17 INFO 140645276194624] #quality_metric: host=algo-1, epoch=107, batch=0 train loss <loss>=2.64253640175\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:17 INFO 140645276194624] Epoch[107] Batch[5] avg_epoch_loss=2.593640\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:17 INFO 140645276194624] #quality_metric: host=algo-1, epoch=107, batch=5 train loss <loss>=2.59364012877\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:17 INFO 140645276194624] Epoch[107] Batch [5]#011Speed: 1943.72 samples/sec#011loss=2.593640\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:18 INFO 140645276194624] processed a total of 622 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 511.95693016052246, \"sum\": 511.95693016052246, \"min\": 511.95693016052246}}, \"EndTime\": 1589566098.006337, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566097.493898}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:18 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1214.69422297 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:18 INFO 140645276194624] #progress_metric: host=algo-1, completed 27 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:18 INFO 140645276194624] #quality_metric: host=algo-1, epoch=107, train loss <loss>=2.56201767921\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:18 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:18 INFO 140645276194624] Epoch[108] Batch[0] avg_epoch_loss=2.603005\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:18 INFO 140645276194624] #quality_metric: host=algo-1, epoch=108, batch=0 train loss <loss>=2.60300469398\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:18 INFO 140645276194624] Epoch[108] Batch[5] avg_epoch_loss=2.574222\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:18 INFO 140645276194624] #quality_metric: host=algo-1, epoch=108, batch=5 train loss <loss>=2.57422240575\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:18 INFO 140645276194624] Epoch[108] Batch [5]#011Speed: 1761.13 samples/sec#011loss=2.574222\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:18 INFO 140645276194624] Epoch[108] Batch[10] avg_epoch_loss=2.508089\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:18 INFO 140645276194624] #quality_metric: host=algo-1, epoch=108, batch=10 train loss <loss>=2.42872962952\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:18 INFO 140645276194624] Epoch[108] Batch [10]#011Speed: 1928.40 samples/sec#011loss=2.428730\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:18 INFO 140645276194624] processed a total of 649 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 576.7369270324707, \"sum\": 576.7369270324707, \"min\": 576.7369270324707}}, \"EndTime\": 1589566098.583601, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566098.006412}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:18 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1125.07410493 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:18 INFO 140645276194624] #progress_metric: host=algo-1, completed 27 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:18 INFO 140645276194624] #quality_metric: host=algo-1, epoch=108, train loss <loss>=2.50808932564\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:18 INFO 140645276194624] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:18 INFO 140645276194624] Saved checkpoint to \"/opt/ml/model/state_b672cb72-60bf-4a7b-94d1-b4e5b514e5b6-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 13.761043548583984, \"sum\": 13.761043548583984, \"min\": 13.761043548583984}}, \"EndTime\": 1589566098.597945, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566098.583675}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:18 INFO 140645276194624] Epoch[109] Batch[0] avg_epoch_loss=2.548820\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:18 INFO 140645276194624] #quality_metric: host=algo-1, epoch=109, batch=0 train loss <loss>=2.54882049561\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:18 INFO 140645276194624] Epoch[109] Batch[5] avg_epoch_loss=2.513245\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:18 INFO 140645276194624] #quality_metric: host=algo-1, epoch=109, batch=5 train loss <loss>=2.5132445097\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:18 INFO 140645276194624] Epoch[109] Batch [5]#011Speed: 1997.84 samples/sec#011loss=2.513245\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:19 INFO 140645276194624] processed a total of 614 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 527.0891189575195, \"sum\": 527.0891189575195, \"min\": 527.0891189575195}}, \"EndTime\": 1589566099.125178, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566098.598025}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:19 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1164.64764889 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:19 INFO 140645276194624] #progress_metric: host=algo-1, completed 27 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:19 INFO 140645276194624] #quality_metric: host=algo-1, epoch=109, train loss <loss>=2.5071505785\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:19 INFO 140645276194624] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:19 INFO 140645276194624] Saved checkpoint to \"/opt/ml/model/state_cadf86c9-7cdc-4a70-a793-2f0952d27009-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 19.270896911621094, \"sum\": 19.270896911621094, \"min\": 19.270896911621094}}, \"EndTime\": 1589566099.145017, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566099.125252}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:19 INFO 140645276194624] Epoch[110] Batch[0] avg_epoch_loss=2.486054\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:19 INFO 140645276194624] #quality_metric: host=algo-1, epoch=110, batch=0 train loss <loss>=2.48605394363\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:19 INFO 140645276194624] Epoch[110] Batch[5] avg_epoch_loss=2.502352\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:19 INFO 140645276194624] #quality_metric: host=algo-1, epoch=110, batch=5 train loss <loss>=2.50235195955\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:19 INFO 140645276194624] Epoch[110] Batch [5]#011Speed: 1869.41 samples/sec#011loss=2.502352\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:19 INFO 140645276194624] processed a total of 621 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 577.2418975830078, \"sum\": 577.2418975830078, \"min\": 577.2418975830078}}, \"EndTime\": 1589566099.722402, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566099.145093}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:19 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1075.59624199 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:19 INFO 140645276194624] #progress_metric: host=algo-1, completed 27 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:19 INFO 140645276194624] #quality_metric: host=algo-1, epoch=110, train loss <loss>=2.51989235878\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:19 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:19 INFO 140645276194624] Epoch[111] Batch[0] avg_epoch_loss=2.646116\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:19 INFO 140645276194624] #quality_metric: host=algo-1, epoch=111, batch=0 train loss <loss>=2.64611554146\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:20 INFO 140645276194624] Epoch[111] Batch[5] avg_epoch_loss=2.584631\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:20 INFO 140645276194624] #quality_metric: host=algo-1, epoch=111, batch=5 train loss <loss>=2.58463084698\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:20 INFO 140645276194624] Epoch[111] Batch [5]#011Speed: 2020.18 samples/sec#011loss=2.584631\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:20 INFO 140645276194624] processed a total of 601 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 505.1600933074951, \"sum\": 505.1600933074951, \"min\": 505.1600933074951}}, \"EndTime\": 1589566100.22812, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566099.722472}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:20 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1189.50795215 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:20 INFO 140645276194624] #progress_metric: host=algo-1, completed 28 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:20 INFO 140645276194624] #quality_metric: host=algo-1, epoch=111, train loss <loss>=2.53934791088\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:20 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:20 INFO 140645276194624] Epoch[112] Batch[0] avg_epoch_loss=2.646356\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:20 INFO 140645276194624] #quality_metric: host=algo-1, epoch=112, batch=0 train loss <loss>=2.64635634422\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:20 INFO 140645276194624] Epoch[112] Batch[5] avg_epoch_loss=2.619969\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:20 INFO 140645276194624] #quality_metric: host=algo-1, epoch=112, batch=5 train loss <loss>=2.61996944745\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:20 INFO 140645276194624] Epoch[112] Batch [5]#011Speed: 1973.56 samples/sec#011loss=2.619969\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:20 INFO 140645276194624] processed a total of 593 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 504.27889823913574, \"sum\": 504.27889823913574, \"min\": 504.27889823913574}}, \"EndTime\": 1589566100.73291, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566100.22818}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:20 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1175.67310228 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:20 INFO 140645276194624] #progress_metric: host=algo-1, completed 28 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:20 INFO 140645276194624] #quality_metric: host=algo-1, epoch=112, train loss <loss>=2.61406850815\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:20 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:20 INFO 140645276194624] Epoch[113] Batch[0] avg_epoch_loss=3.457273\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:20 INFO 140645276194624] #quality_metric: host=algo-1, epoch=113, batch=0 train loss <loss>=3.45727348328\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:21 INFO 140645276194624] Epoch[113] Batch[5] avg_epoch_loss=2.965271\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:21 INFO 140645276194624] #quality_metric: host=algo-1, epoch=113, batch=5 train loss <loss>=2.9652706782\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:21 INFO 140645276194624] Epoch[113] Batch [5]#011Speed: 1531.78 samples/sec#011loss=2.965271\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:21 INFO 140645276194624] Epoch[113] Batch[10] avg_epoch_loss=2.983798\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:21 INFO 140645276194624] #quality_metric: host=algo-1, epoch=113, batch=10 train loss <loss>=3.0060300827\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:21 INFO 140645276194624] Epoch[113] Batch [10]#011Speed: 1977.60 samples/sec#011loss=3.006030\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:21 INFO 140645276194624] processed a total of 651 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 633.0158710479736, \"sum\": 633.0158710479736, \"min\": 633.0158710479736}}, \"EndTime\": 1589566101.366455, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566100.732985}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:21 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1028.22976532 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:21 INFO 140645276194624] #progress_metric: host=algo-1, completed 28 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:21 INFO 140645276194624] #quality_metric: host=algo-1, epoch=113, train loss <loss>=2.98379768025\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:21 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:21 INFO 140645276194624] Epoch[114] Batch[0] avg_epoch_loss=2.636763\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:21 INFO 140645276194624] #quality_metric: host=algo-1, epoch=114, batch=0 train loss <loss>=2.63676285744\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:21 INFO 140645276194624] Epoch[114] Batch[5] avg_epoch_loss=2.620782\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:21 INFO 140645276194624] #quality_metric: host=algo-1, epoch=114, batch=5 train loss <loss>=2.62078166008\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:21 INFO 140645276194624] Epoch[114] Batch [5]#011Speed: 2017.88 samples/sec#011loss=2.620782\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:21 INFO 140645276194624] processed a total of 619 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 505.0480365753174, \"sum\": 505.0480365753174, \"min\": 505.0480365753174}}, \"EndTime\": 1589566101.872018, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566101.366529}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:21 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1225.38361218 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:21 INFO 140645276194624] #progress_metric: host=algo-1, completed 28 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:21 INFO 140645276194624] #quality_metric: host=algo-1, epoch=114, train loss <loss>=2.61126127243\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:21 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:22 INFO 140645276194624] Epoch[115] Batch[0] avg_epoch_loss=2.582840\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:22 INFO 140645276194624] #quality_metric: host=algo-1, epoch=115, batch=0 train loss <loss>=2.58284020424\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:22 INFO 140645276194624] Epoch[115] Batch[5] avg_epoch_loss=2.588101\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:22 INFO 140645276194624] #quality_metric: host=algo-1, epoch=115, batch=5 train loss <loss>=2.5881010294\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:22 INFO 140645276194624] Epoch[115] Batch [5]#011Speed: 1998.60 samples/sec#011loss=2.588101\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:22 INFO 140645276194624] processed a total of 607 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 504.1160583496094, \"sum\": 504.1160583496094, \"min\": 504.1160583496094}}, \"EndTime\": 1589566102.376678, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566101.872088}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:22 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1203.83729578 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:22 INFO 140645276194624] #progress_metric: host=algo-1, completed 29 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:22 INFO 140645276194624] #quality_metric: host=algo-1, epoch=115, train loss <loss>=2.58000323772\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:22 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:22 INFO 140645276194624] Epoch[116] Batch[0] avg_epoch_loss=2.673192\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:22 INFO 140645276194624] #quality_metric: host=algo-1, epoch=116, batch=0 train loss <loss>=2.67319202423\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:22 INFO 140645276194624] Epoch[116] Batch[5] avg_epoch_loss=2.609156\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:22 INFO 140645276194624] #quality_metric: host=algo-1, epoch=116, batch=5 train loss <loss>=2.60915609201\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:22 INFO 140645276194624] Epoch[116] Batch [5]#011Speed: 2011.24 samples/sec#011loss=2.609156\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:22 INFO 140645276194624] Epoch[116] Batch[10] avg_epoch_loss=2.539199\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:22 INFO 140645276194624] #quality_metric: host=algo-1, epoch=116, batch=10 train loss <loss>=2.45524997711\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:22 INFO 140645276194624] Epoch[116] Batch [10]#011Speed: 1839.71 samples/sec#011loss=2.455250\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:22 INFO 140645276194624] processed a total of 657 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 551.3300895690918, \"sum\": 551.3300895690918, \"min\": 551.3300895690918}}, \"EndTime\": 1589566102.928549, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566102.376752}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:22 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1191.41732629 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:22 INFO 140645276194624] #progress_metric: host=algo-1, completed 29 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:22 INFO 140645276194624] #quality_metric: host=algo-1, epoch=116, train loss <loss>=2.53919876706\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:22 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:23 INFO 140645276194624] Epoch[117] Batch[0] avg_epoch_loss=2.438048\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:23 INFO 140645276194624] #quality_metric: host=algo-1, epoch=117, batch=0 train loss <loss>=2.43804836273\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:23 INFO 140645276194624] Epoch[117] Batch[5] avg_epoch_loss=2.522744\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:23 INFO 140645276194624] #quality_metric: host=algo-1, epoch=117, batch=5 train loss <loss>=2.52274394035\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:23 INFO 140645276194624] Epoch[117] Batch [5]#011Speed: 2001.34 samples/sec#011loss=2.522744\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:23 INFO 140645276194624] Epoch[117] Batch[10] avg_epoch_loss=2.507053\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:23 INFO 140645276194624] #quality_metric: host=algo-1, epoch=117, batch=10 train loss <loss>=2.48822445869\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:23 INFO 140645276194624] Epoch[117] Batch [10]#011Speed: 1953.83 samples/sec#011loss=2.488224\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:23 INFO 140645276194624] processed a total of 665 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 557.6961040496826, \"sum\": 557.6961040496826, \"min\": 557.6961040496826}}, \"EndTime\": 1589566103.486763, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566102.928627}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:23 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1192.17479911 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:23 INFO 140645276194624] #progress_metric: host=algo-1, completed 29 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:23 INFO 140645276194624] #quality_metric: host=algo-1, epoch=117, train loss <loss>=2.50705326687\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:23 INFO 140645276194624] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:23 INFO 140645276194624] Saved checkpoint to \"/opt/ml/model/state_7a0ecc64-bad7-406b-855e-d823c6b0603c-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 18.9208984375, \"sum\": 18.9208984375, \"min\": 18.9208984375}}, \"EndTime\": 1589566103.506247, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566103.486837}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:23 INFO 140645276194624] Epoch[118] Batch[0] avg_epoch_loss=2.474964\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:23 INFO 140645276194624] #quality_metric: host=algo-1, epoch=118, batch=0 train loss <loss>=2.47496366501\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:23 INFO 140645276194624] Epoch[118] Batch[5] avg_epoch_loss=2.490492\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:23 INFO 140645276194624] #quality_metric: host=algo-1, epoch=118, batch=5 train loss <loss>=2.49049206575\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:23 INFO 140645276194624] Epoch[118] Batch [5]#011Speed: 1680.90 samples/sec#011loss=2.490492\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:24 INFO 140645276194624] Epoch[118] Batch[10] avg_epoch_loss=2.514109\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:24 INFO 140645276194624] #quality_metric: host=algo-1, epoch=118, batch=10 train loss <loss>=2.5424498558\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:24 INFO 140645276194624] Epoch[118] Batch [10]#011Speed: 1656.09 samples/sec#011loss=2.542450\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:24 INFO 140645276194624] processed a total of 658 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 626.4200210571289, \"sum\": 626.4200210571289, \"min\": 626.4200210571289}}, \"EndTime\": 1589566104.1328, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566103.506317}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:24 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1050.23235049 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:24 INFO 140645276194624] #progress_metric: host=algo-1, completed 29 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:24 INFO 140645276194624] #quality_metric: host=algo-1, epoch=118, train loss <loss>=2.51410924305\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:24 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:24 INFO 140645276194624] Epoch[119] Batch[0] avg_epoch_loss=2.551167\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:24 INFO 140645276194624] #quality_metric: host=algo-1, epoch=119, batch=0 train loss <loss>=2.55116677284\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:24 INFO 140645276194624] Epoch[119] Batch[5] avg_epoch_loss=2.576759\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:24 INFO 140645276194624] #quality_metric: host=algo-1, epoch=119, batch=5 train loss <loss>=2.57675898075\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:24 INFO 140645276194624] Epoch[119] Batch [5]#011Speed: 1888.75 samples/sec#011loss=2.576759\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:24 INFO 140645276194624] processed a total of 630 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 550.1480102539062, \"sum\": 550.1480102539062, \"min\": 550.1480102539062}}, \"EndTime\": 1589566104.683484, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566104.13287}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:24 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1144.90523723 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:24 INFO 140645276194624] #progress_metric: host=algo-1, completed 30 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:24 INFO 140645276194624] #quality_metric: host=algo-1, epoch=119, train loss <loss>=2.56719455719\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:24 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:24 INFO 140645276194624] Epoch[120] Batch[0] avg_epoch_loss=2.558069\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:24 INFO 140645276194624] #quality_metric: host=algo-1, epoch=120, batch=0 train loss <loss>=2.55806946754\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:25 INFO 140645276194624] Epoch[120] Batch[5] avg_epoch_loss=2.522604\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:25 INFO 140645276194624] #quality_metric: host=algo-1, epoch=120, batch=5 train loss <loss>=2.52260375023\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:25 INFO 140645276194624] Epoch[120] Batch [5]#011Speed: 1974.21 samples/sec#011loss=2.522604\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:25 INFO 140645276194624] Epoch[120] Batch[10] avg_epoch_loss=2.527096\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:25 INFO 140645276194624] #quality_metric: host=algo-1, epoch=120, batch=10 train loss <loss>=2.53248653412\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:25 INFO 140645276194624] Epoch[120] Batch [10]#011Speed: 1814.51 samples/sec#011loss=2.532487\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:25 INFO 140645276194624] processed a total of 653 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 569.9808597564697, \"sum\": 569.9808597564697, \"min\": 569.9808597564697}}, \"EndTime\": 1589566105.254051, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566104.683562}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:25 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1145.45701798 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:25 INFO 140645276194624] #progress_metric: host=algo-1, completed 30 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:25 INFO 140645276194624] #quality_metric: host=algo-1, epoch=120, train loss <loss>=2.52709592472\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:25 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:25 INFO 140645276194624] Epoch[121] Batch[0] avg_epoch_loss=2.504142\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:25 INFO 140645276194624] #quality_metric: host=algo-1, epoch=121, batch=0 train loss <loss>=2.50414228439\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:25 INFO 140645276194624] Epoch[121] Batch[5] avg_epoch_loss=2.535842\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:25 INFO 140645276194624] #quality_metric: host=algo-1, epoch=121, batch=5 train loss <loss>=2.53584225972\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:25 INFO 140645276194624] Epoch[121] Batch [5]#011Speed: 1868.47 samples/sec#011loss=2.535842\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:25 INFO 140645276194624] processed a total of 625 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 530.0979614257812, \"sum\": 530.0979614257812, \"min\": 530.0979614257812}}, \"EndTime\": 1589566105.784547, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566105.254118}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:25 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1178.78931093 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:25 INFO 140645276194624] #progress_metric: host=algo-1, completed 30 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:25 INFO 140645276194624] #quality_metric: host=algo-1, epoch=121, train loss <loss>=2.53672862053\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:25 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:26 INFO 140645276194624] Epoch[122] Batch[0] avg_epoch_loss=2.531894\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:26 INFO 140645276194624] #quality_metric: host=algo-1, epoch=122, batch=0 train loss <loss>=2.53189396858\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:26 INFO 140645276194624] Epoch[122] Batch[5] avg_epoch_loss=2.550345\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:26 INFO 140645276194624] #quality_metric: host=algo-1, epoch=122, batch=5 train loss <loss>=2.55034466585\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:26 INFO 140645276194624] Epoch[122] Batch [5]#011Speed: 1925.98 samples/sec#011loss=2.550345\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:26 INFO 140645276194624] processed a total of 630 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 522.2477912902832, \"sum\": 522.2477912902832, \"min\": 522.2477912902832}}, \"EndTime\": 1589566106.307363, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566105.784617}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:26 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1206.06238142 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:26 INFO 140645276194624] #progress_metric: host=algo-1, completed 30 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:26 INFO 140645276194624] #quality_metric: host=algo-1, epoch=122, train loss <loss>=2.57424247265\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:26 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:26 INFO 140645276194624] Epoch[123] Batch[0] avg_epoch_loss=2.495728\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:26 INFO 140645276194624] #quality_metric: host=algo-1, epoch=123, batch=0 train loss <loss>=2.49572849274\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:26 INFO 140645276194624] Epoch[123] Batch[5] avg_epoch_loss=2.555024\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:26 INFO 140645276194624] #quality_metric: host=algo-1, epoch=123, batch=5 train loss <loss>=2.55502434572\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:26 INFO 140645276194624] Epoch[123] Batch [5]#011Speed: 1943.31 samples/sec#011loss=2.555024\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:26 INFO 140645276194624] Epoch[123] Batch[10] avg_epoch_loss=2.557330\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:26 INFO 140645276194624] #quality_metric: host=algo-1, epoch=123, batch=10 train loss <loss>=2.56009669304\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:26 INFO 140645276194624] Epoch[123] Batch [10]#011Speed: 1916.75 samples/sec#011loss=2.560097\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:26 INFO 140645276194624] processed a total of 665 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 576.3530731201172, \"sum\": 576.3530731201172, \"min\": 576.3530731201172}}, \"EndTime\": 1589566106.884227, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566106.307441}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:26 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1153.58425984 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:26 INFO 140645276194624] #progress_metric: host=algo-1, completed 31 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:26 INFO 140645276194624] #quality_metric: host=algo-1, epoch=123, train loss <loss>=2.55732995814\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:26 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:27 INFO 140645276194624] Epoch[124] Batch[0] avg_epoch_loss=2.657995\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:27 INFO 140645276194624] #quality_metric: host=algo-1, epoch=124, batch=0 train loss <loss>=2.65799474716\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:27 INFO 140645276194624] Epoch[124] Batch[5] avg_epoch_loss=2.685289\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:27 INFO 140645276194624] #quality_metric: host=algo-1, epoch=124, batch=5 train loss <loss>=2.68528926373\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:27 INFO 140645276194624] Epoch[124] Batch [5]#011Speed: 1969.62 samples/sec#011loss=2.685289\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:27 INFO 140645276194624] processed a total of 640 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 531.8279266357422, \"sum\": 531.8279266357422, \"min\": 531.8279266357422}}, \"EndTime\": 1589566107.416553, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566106.884303}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:27 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1203.13192499 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:27 INFO 140645276194624] #progress_metric: host=algo-1, completed 31 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:27 INFO 140645276194624] #quality_metric: host=algo-1, epoch=124, train loss <loss>=2.66615645885\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:27 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:27 INFO 140645276194624] Epoch[125] Batch[0] avg_epoch_loss=2.568155\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:27 INFO 140645276194624] #quality_metric: host=algo-1, epoch=125, batch=0 train loss <loss>=2.56815457344\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:27 INFO 140645276194624] Epoch[125] Batch[5] avg_epoch_loss=2.596394\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:27 INFO 140645276194624] #quality_metric: host=algo-1, epoch=125, batch=5 train loss <loss>=2.59639386336\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:27 INFO 140645276194624] Epoch[125] Batch [5]#011Speed: 1846.48 samples/sec#011loss=2.596394\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:27 INFO 140645276194624] Epoch[125] Batch[10] avg_epoch_loss=2.604021\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:27 INFO 140645276194624] #quality_metric: host=algo-1, epoch=125, batch=10 train loss <loss>=2.61317334175\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:27 INFO 140645276194624] Epoch[125] Batch [10]#011Speed: 1917.80 samples/sec#011loss=2.613173\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:27 INFO 140645276194624] processed a total of 666 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 580.5060863494873, \"sum\": 580.5060863494873, \"min\": 580.5060863494873}}, \"EndTime\": 1589566107.997576, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566107.416633}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:27 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1147.05572902 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:27 INFO 140645276194624] #progress_metric: host=algo-1, completed 31 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:27 INFO 140645276194624] #quality_metric: host=algo-1, epoch=125, train loss <loss>=2.60402089899\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:27 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:28 INFO 140645276194624] Epoch[126] Batch[0] avg_epoch_loss=2.601100\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:28 INFO 140645276194624] #quality_metric: host=algo-1, epoch=126, batch=0 train loss <loss>=2.60109972954\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:28 INFO 140645276194624] Epoch[126] Batch[5] avg_epoch_loss=2.570372\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:28 INFO 140645276194624] #quality_metric: host=algo-1, epoch=126, batch=5 train loss <loss>=2.5703723828\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:28 INFO 140645276194624] Epoch[126] Batch [5]#011Speed: 1975.36 samples/sec#011loss=2.570372\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:28 INFO 140645276194624] processed a total of 632 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 537.7898216247559, \"sum\": 537.7898216247559, \"min\": 537.7898216247559}}, \"EndTime\": 1589566108.535877, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566107.997652}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:28 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1174.92245769 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:28 INFO 140645276194624] #progress_metric: host=algo-1, completed 31 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:28 INFO 140645276194624] #quality_metric: host=algo-1, epoch=126, train loss <loss>=2.55015158653\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:28 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:28 INFO 140645276194624] Epoch[127] Batch[0] avg_epoch_loss=2.496140\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:28 INFO 140645276194624] #quality_metric: host=algo-1, epoch=127, batch=0 train loss <loss>=2.49613976479\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:28 INFO 140645276194624] Epoch[127] Batch[5] avg_epoch_loss=2.492141\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:28 INFO 140645276194624] #quality_metric: host=algo-1, epoch=127, batch=5 train loss <loss>=2.49214112759\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:28 INFO 140645276194624] Epoch[127] Batch [5]#011Speed: 1947.58 samples/sec#011loss=2.492141\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:29 INFO 140645276194624] processed a total of 628 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 556.1661720275879, \"sum\": 556.1661720275879, \"min\": 556.1661720275879}}, \"EndTime\": 1589566109.092565, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566108.535959}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:29 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1128.91550565 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:29 INFO 140645276194624] #progress_metric: host=algo-1, completed 32 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:29 INFO 140645276194624] #quality_metric: host=algo-1, epoch=127, train loss <loss>=2.48228962421\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:29 INFO 140645276194624] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:29 INFO 140645276194624] Saved checkpoint to \"/opt/ml/model/state_a41ecd9a-b424-4f73-ab7e-915f27ac73ec-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 12.44807243347168, \"sum\": 12.44807243347168, \"min\": 12.44807243347168}}, \"EndTime\": 1589566109.105648, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566109.092646}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:29 INFO 140645276194624] Epoch[128] Batch[0] avg_epoch_loss=2.577074\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:29 INFO 140645276194624] #quality_metric: host=algo-1, epoch=128, batch=0 train loss <loss>=2.57707357407\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:29 INFO 140645276194624] Epoch[128] Batch[5] avg_epoch_loss=2.486104\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:29 INFO 140645276194624] #quality_metric: host=algo-1, epoch=128, batch=5 train loss <loss>=2.48610417048\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:29 INFO 140645276194624] Epoch[128] Batch [5]#011Speed: 1983.92 samples/sec#011loss=2.486104\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:29 INFO 140645276194624] Epoch[128] Batch[10] avg_epoch_loss=2.486874\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:29 INFO 140645276194624] #quality_metric: host=algo-1, epoch=128, batch=10 train loss <loss>=2.48779816628\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:29 INFO 140645276194624] Epoch[128] Batch [10]#011Speed: 1683.15 samples/sec#011loss=2.487798\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:29 INFO 140645276194624] processed a total of 641 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 586.7748260498047, \"sum\": 586.7748260498047, \"min\": 586.7748260498047}}, \"EndTime\": 1589566109.692557, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566109.105712}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:29 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1092.17570527 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:29 INFO 140645276194624] #progress_metric: host=algo-1, completed 32 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:29 INFO 140645276194624] #quality_metric: host=algo-1, epoch=128, train loss <loss>=2.48687416857\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:29 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:29 INFO 140645276194624] Epoch[129] Batch[0] avg_epoch_loss=2.470780\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:29 INFO 140645276194624] #quality_metric: host=algo-1, epoch=129, batch=0 train loss <loss>=2.47077965736\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:30 INFO 140645276194624] Epoch[129] Batch[5] avg_epoch_loss=2.497420\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:30 INFO 140645276194624] #quality_metric: host=algo-1, epoch=129, batch=5 train loss <loss>=2.49742027124\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:30 INFO 140645276194624] Epoch[129] Batch [5]#011Speed: 1955.58 samples/sec#011loss=2.497420\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:30 INFO 140645276194624] processed a total of 631 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 522.4311351776123, \"sum\": 522.4311351776123, \"min\": 522.4311351776123}}, \"EndTime\": 1589566110.21552, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566109.692642}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:30 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1207.60471907 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:30 INFO 140645276194624] #progress_metric: host=algo-1, completed 32 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:30 INFO 140645276194624] #quality_metric: host=algo-1, epoch=129, train loss <loss>=2.47839109898\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:30 INFO 140645276194624] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:30 INFO 140645276194624] Saved checkpoint to \"/opt/ml/model/state_22da33b8-f036-450e-8a50-74f8c331ad79-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 13.849020004272461, \"sum\": 13.849020004272461, \"min\": 13.849020004272461}}, \"EndTime\": 1589566110.229975, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566110.215579}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:30 INFO 140645276194624] Epoch[130] Batch[0] avg_epoch_loss=2.445909\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:30 INFO 140645276194624] #quality_metric: host=algo-1, epoch=130, batch=0 train loss <loss>=2.44590902328\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:30 INFO 140645276194624] Epoch[130] Batch[5] avg_epoch_loss=2.510012\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:30 INFO 140645276194624] #quality_metric: host=algo-1, epoch=130, batch=5 train loss <loss>=2.51001171271\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:30 INFO 140645276194624] Epoch[130] Batch [5]#011Speed: 1762.71 samples/sec#011loss=2.510012\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:30 INFO 140645276194624] Epoch[130] Batch[10] avg_epoch_loss=2.495460\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:30 INFO 140645276194624] #quality_metric: host=algo-1, epoch=130, batch=10 train loss <loss>=2.47799720764\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:30 INFO 140645276194624] Epoch[130] Batch [10]#011Speed: 1552.05 samples/sec#011loss=2.477997\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:30 INFO 140645276194624] processed a total of 653 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 612.3960018157959, \"sum\": 612.3960018157959, \"min\": 612.3960018157959}}, \"EndTime\": 1589566110.842512, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566110.230049}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:30 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1066.08933354 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:30 INFO 140645276194624] #progress_metric: host=algo-1, completed 32 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:30 INFO 140645276194624] #quality_metric: host=algo-1, epoch=130, train loss <loss>=2.49545966495\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:30 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:31 INFO 140645276194624] Epoch[131] Batch[0] avg_epoch_loss=2.660640\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:31 INFO 140645276194624] #quality_metric: host=algo-1, epoch=131, batch=0 train loss <loss>=2.6606400013\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:31 INFO 140645276194624] Epoch[131] Batch[5] avg_epoch_loss=2.567049\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:31 INFO 140645276194624] #quality_metric: host=algo-1, epoch=131, batch=5 train loss <loss>=2.56704946359\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:31 INFO 140645276194624] Epoch[131] Batch [5]#011Speed: 1957.20 samples/sec#011loss=2.567049\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:31 INFO 140645276194624] Epoch[131] Batch[10] avg_epoch_loss=2.543815\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:31 INFO 140645276194624] #quality_metric: host=algo-1, epoch=131, batch=10 train loss <loss>=2.51593384743\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:31 INFO 140645276194624] Epoch[131] Batch [10]#011Speed: 1985.18 samples/sec#011loss=2.515934\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:31 INFO 140645276194624] processed a total of 715 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 607.8851222991943, \"sum\": 607.8851222991943, \"min\": 607.8851222991943}}, \"EndTime\": 1589566111.450876, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566110.842596}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:31 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1176.03149755 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:31 INFO 140645276194624] #progress_metric: host=algo-1, completed 33 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:31 INFO 140645276194624] #quality_metric: host=algo-1, epoch=131, train loss <loss>=2.52091530959\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:31 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:31 INFO 140645276194624] Epoch[132] Batch[0] avg_epoch_loss=2.527517\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:31 INFO 140645276194624] #quality_metric: host=algo-1, epoch=132, batch=0 train loss <loss>=2.52751731873\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:31 INFO 140645276194624] Epoch[132] Batch[5] avg_epoch_loss=2.525142\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:31 INFO 140645276194624] #quality_metric: host=algo-1, epoch=132, batch=5 train loss <loss>=2.52514231205\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:31 INFO 140645276194624] Epoch[132] Batch [5]#011Speed: 1977.85 samples/sec#011loss=2.525142\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:31 INFO 140645276194624] processed a total of 616 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 517.3931121826172, \"sum\": 517.3931121826172, \"min\": 517.3931121826172}}, \"EndTime\": 1589566111.968854, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566111.450939}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:31 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1190.34985633 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:31 INFO 140645276194624] #progress_metric: host=algo-1, completed 33 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:31 INFO 140645276194624] #quality_metric: host=algo-1, epoch=132, train loss <loss>=2.54221045971\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:31 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:32 INFO 140645276194624] Epoch[133] Batch[0] avg_epoch_loss=2.466416\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:32 INFO 140645276194624] #quality_metric: host=algo-1, epoch=133, batch=0 train loss <loss>=2.46641635895\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:32 INFO 140645276194624] Epoch[133] Batch[5] avg_epoch_loss=2.567899\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:32 INFO 140645276194624] #quality_metric: host=algo-1, epoch=133, batch=5 train loss <loss>=2.56789902846\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:32 INFO 140645276194624] Epoch[133] Batch [5]#011Speed: 1978.79 samples/sec#011loss=2.567899\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:32 INFO 140645276194624] processed a total of 636 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 521.9821929931641, \"sum\": 521.9821929931641, \"min\": 521.9821929931641}}, \"EndTime\": 1589566112.491353, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566111.968927}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:32 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1218.14805036 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:32 INFO 140645276194624] #progress_metric: host=algo-1, completed 33 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:32 INFO 140645276194624] #quality_metric: host=algo-1, epoch=133, train loss <loss>=2.5677036047\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:32 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:32 INFO 140645276194624] Epoch[134] Batch[0] avg_epoch_loss=2.660622\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:32 INFO 140645276194624] #quality_metric: host=algo-1, epoch=134, batch=0 train loss <loss>=2.66062235832\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:32 INFO 140645276194624] Epoch[134] Batch[5] avg_epoch_loss=2.529825\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:32 INFO 140645276194624] #quality_metric: host=algo-1, epoch=134, batch=5 train loss <loss>=2.52982457479\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:32 INFO 140645276194624] Epoch[134] Batch [5]#011Speed: 1698.59 samples/sec#011loss=2.529825\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:33 INFO 140645276194624] Epoch[134] Batch[10] avg_epoch_loss=2.544528\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:33 INFO 140645276194624] #quality_metric: host=algo-1, epoch=134, batch=10 train loss <loss>=2.56217226982\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:33 INFO 140645276194624] Epoch[134] Batch [10]#011Speed: 1736.53 samples/sec#011loss=2.562172\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:33 INFO 140645276194624] processed a total of 686 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 611.8412017822266, \"sum\": 611.8412017822266, \"min\": 611.8412017822266}}, \"EndTime\": 1589566113.103772, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566112.491436}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:33 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1121.00457979 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:33 INFO 140645276194624] #progress_metric: host=algo-1, completed 33 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:33 INFO 140645276194624] #quality_metric: host=algo-1, epoch=134, train loss <loss>=2.54452807253\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:33 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:33 INFO 140645276194624] Epoch[135] Batch[0] avg_epoch_loss=2.497801\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:33 INFO 140645276194624] #quality_metric: host=algo-1, epoch=135, batch=0 train loss <loss>=2.49780082703\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:33 INFO 140645276194624] Epoch[135] Batch[5] avg_epoch_loss=2.520356\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:33 INFO 140645276194624] #quality_metric: host=algo-1, epoch=135, batch=5 train loss <loss>=2.52035578092\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:33 INFO 140645276194624] Epoch[135] Batch [5]#011Speed: 1893.33 samples/sec#011loss=2.520356\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:33 INFO 140645276194624] Epoch[135] Batch[10] avg_epoch_loss=2.498108\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:33 INFO 140645276194624] #quality_metric: host=algo-1, epoch=135, batch=10 train loss <loss>=2.47141108513\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:33 INFO 140645276194624] Epoch[135] Batch [10]#011Speed: 1915.73 samples/sec#011loss=2.471411\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:33 INFO 140645276194624] processed a total of 672 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 591.6481018066406, \"sum\": 591.6481018066406, \"min\": 591.6481018066406}}, \"EndTime\": 1589566113.695907, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566113.103846}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:33 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1135.58971714 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:33 INFO 140645276194624] #progress_metric: host=algo-1, completed 34 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:33 INFO 140645276194624] #quality_metric: host=algo-1, epoch=135, train loss <loss>=2.49810819192\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:33 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:33 INFO 140645276194624] Epoch[136] Batch[0] avg_epoch_loss=2.577646\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:33 INFO 140645276194624] #quality_metric: host=algo-1, epoch=136, batch=0 train loss <loss>=2.57764625549\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:34 INFO 140645276194624] Epoch[136] Batch[5] avg_epoch_loss=2.485809\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:34 INFO 140645276194624] #quality_metric: host=algo-1, epoch=136, batch=5 train loss <loss>=2.48580888907\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:34 INFO 140645276194624] Epoch[136] Batch [5]#011Speed: 1914.23 samples/sec#011loss=2.485809\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:34 INFO 140645276194624] Epoch[136] Batch[10] avg_epoch_loss=2.488767\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:34 INFO 140645276194624] #quality_metric: host=algo-1, epoch=136, batch=10 train loss <loss>=2.49231615067\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:34 INFO 140645276194624] Epoch[136] Batch [10]#011Speed: 1817.89 samples/sec#011loss=2.492316\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:34 INFO 140645276194624] processed a total of 697 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 601.9399166107178, \"sum\": 601.9399166107178, \"min\": 601.9399166107178}}, \"EndTime\": 1589566114.29834, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566113.695985}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:34 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1157.71148512 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:34 INFO 140645276194624] #progress_metric: host=algo-1, completed 34 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:34 INFO 140645276194624] #quality_metric: host=algo-1, epoch=136, train loss <loss>=2.48876673525\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:34 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:34 INFO 140645276194624] Epoch[137] Batch[0] avg_epoch_loss=2.605540\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:34 INFO 140645276194624] #quality_metric: host=algo-1, epoch=137, batch=0 train loss <loss>=2.60554027557\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:34 INFO 140645276194624] Epoch[137] Batch[5] avg_epoch_loss=2.490945\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:34 INFO 140645276194624] #quality_metric: host=algo-1, epoch=137, batch=5 train loss <loss>=2.49094514052\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:34 INFO 140645276194624] Epoch[137] Batch [5]#011Speed: 1783.25 samples/sec#011loss=2.490945\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:34 INFO 140645276194624] Epoch[137] Batch[10] avg_epoch_loss=2.516050\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:34 INFO 140645276194624] #quality_metric: host=algo-1, epoch=137, batch=10 train loss <loss>=2.54617624283\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:34 INFO 140645276194624] Epoch[137] Batch [10]#011Speed: 1905.00 samples/sec#011loss=2.546176\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:34 INFO 140645276194624] processed a total of 664 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 597.1169471740723, \"sum\": 597.1169471740723, \"min\": 597.1169471740723}}, \"EndTime\": 1589566114.895933, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566114.298415}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:34 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1111.81242467 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:34 INFO 140645276194624] #progress_metric: host=algo-1, completed 34 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:34 INFO 140645276194624] #quality_metric: host=algo-1, epoch=137, train loss <loss>=2.51605018702\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:34 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:35 INFO 140645276194624] Epoch[138] Batch[0] avg_epoch_loss=2.451835\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:35 INFO 140645276194624] #quality_metric: host=algo-1, epoch=138, batch=0 train loss <loss>=2.45183539391\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:35 INFO 140645276194624] Epoch[138] Batch[5] avg_epoch_loss=2.519315\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:35 INFO 140645276194624] #quality_metric: host=algo-1, epoch=138, batch=5 train loss <loss>=2.51931480567\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:35 INFO 140645276194624] Epoch[138] Batch [5]#011Speed: 1804.31 samples/sec#011loss=2.519315\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:35 INFO 140645276194624] Epoch[138] Batch[10] avg_epoch_loss=2.479117\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:35 INFO 140645276194624] #quality_metric: host=algo-1, epoch=138, batch=10 train loss <loss>=2.4308795929\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:35 INFO 140645276194624] Epoch[138] Batch [10]#011Speed: 1748.47 samples/sec#011loss=2.430880\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:35 INFO 140645276194624] processed a total of 660 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 625.4889965057373, \"sum\": 625.4889965057373, \"min\": 625.4889965057373}}, \"EndTime\": 1589566115.521891, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566114.896006}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:35 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1054.98905468 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:35 INFO 140645276194624] #progress_metric: host=algo-1, completed 34 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:35 INFO 140645276194624] #quality_metric: host=algo-1, epoch=138, train loss <loss>=2.47911698168\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:35 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:35 INFO 140645276194624] Epoch[139] Batch[0] avg_epoch_loss=2.408223\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:35 INFO 140645276194624] #quality_metric: host=algo-1, epoch=139, batch=0 train loss <loss>=2.40822291374\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:35 INFO 140645276194624] Epoch[139] Batch[5] avg_epoch_loss=2.462883\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:35 INFO 140645276194624] #quality_metric: host=algo-1, epoch=139, batch=5 train loss <loss>=2.46288283666\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:35 INFO 140645276194624] Epoch[139] Batch [5]#011Speed: 1783.66 samples/sec#011loss=2.462883\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:36 INFO 140645276194624] Epoch[139] Batch[10] avg_epoch_loss=2.502097\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:36 INFO 140645276194624] #quality_metric: host=algo-1, epoch=139, batch=10 train loss <loss>=2.54915409088\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:36 INFO 140645276194624] Epoch[139] Batch [10]#011Speed: 1560.49 samples/sec#011loss=2.549154\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:36 INFO 140645276194624] processed a total of 674 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 653.9089679718018, \"sum\": 653.9089679718018, \"min\": 653.9089679718018}}, \"EndTime\": 1589566116.176288, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566115.521966}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:36 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1030.54490442 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:36 INFO 140645276194624] #progress_metric: host=algo-1, completed 35 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:36 INFO 140645276194624] #quality_metric: host=algo-1, epoch=139, train loss <loss>=2.50209704312\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:36 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:36 INFO 140645276194624] Epoch[140] Batch[0] avg_epoch_loss=2.601455\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:36 INFO 140645276194624] #quality_metric: host=algo-1, epoch=140, batch=0 train loss <loss>=2.60145497322\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:36 INFO 140645276194624] Epoch[140] Batch[5] avg_epoch_loss=2.570712\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:36 INFO 140645276194624] #quality_metric: host=algo-1, epoch=140, batch=5 train loss <loss>=2.57071220875\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:36 INFO 140645276194624] Epoch[140] Batch [5]#011Speed: 1953.81 samples/sec#011loss=2.570712\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:36 INFO 140645276194624] processed a total of 639 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 547.6598739624023, \"sum\": 547.6598739624023, \"min\": 547.6598739624023}}, \"EndTime\": 1589566116.724457, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566116.176367}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:36 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1166.53069098 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:36 INFO 140645276194624] #progress_metric: host=algo-1, completed 35 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:36 INFO 140645276194624] #quality_metric: host=algo-1, epoch=140, train loss <loss>=2.54244675636\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:36 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:36 INFO 140645276194624] Epoch[141] Batch[0] avg_epoch_loss=2.507312\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:36 INFO 140645276194624] #quality_metric: host=algo-1, epoch=141, batch=0 train loss <loss>=2.50731229782\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:37 INFO 140645276194624] Epoch[141] Batch[5] avg_epoch_loss=2.506180\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:37 INFO 140645276194624] #quality_metric: host=algo-1, epoch=141, batch=5 train loss <loss>=2.50618020693\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:37 INFO 140645276194624] Epoch[141] Batch [5]#011Speed: 1994.63 samples/sec#011loss=2.506180\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:37 INFO 140645276194624] Epoch[141] Batch[10] avg_epoch_loss=2.526180\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:37 INFO 140645276194624] #quality_metric: host=algo-1, epoch=141, batch=10 train loss <loss>=2.55017938614\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:37 INFO 140645276194624] Epoch[141] Batch [10]#011Speed: 1966.36 samples/sec#011loss=2.550179\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:37 INFO 140645276194624] processed a total of 663 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 561.743974685669, \"sum\": 561.743974685669, \"min\": 561.743974685669}}, \"EndTime\": 1589566117.286736, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566116.724538}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:37 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1180.02359857 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:37 INFO 140645276194624] #progress_metric: host=algo-1, completed 35 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:37 INFO 140645276194624] #quality_metric: host=algo-1, epoch=141, train loss <loss>=2.52617983385\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:37 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:37 INFO 140645276194624] Epoch[142] Batch[0] avg_epoch_loss=2.770057\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:37 INFO 140645276194624] #quality_metric: host=algo-1, epoch=142, batch=0 train loss <loss>=2.77005672455\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:37 INFO 140645276194624] Epoch[142] Batch[5] avg_epoch_loss=2.593669\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:37 INFO 140645276194624] #quality_metric: host=algo-1, epoch=142, batch=5 train loss <loss>=2.59366913637\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:37 INFO 140645276194624] Epoch[142] Batch [5]#011Speed: 1963.77 samples/sec#011loss=2.593669\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:37 INFO 140645276194624] processed a total of 601 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 532.7341556549072, \"sum\": 532.7341556549072, \"min\": 532.7341556549072}}, \"EndTime\": 1589566117.820068, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566117.286811}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:37 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1127.89306215 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:37 INFO 140645276194624] #progress_metric: host=algo-1, completed 35 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:37 INFO 140645276194624] #quality_metric: host=algo-1, epoch=142, train loss <loss>=2.59768681526\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:37 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:38 INFO 140645276194624] Epoch[143] Batch[0] avg_epoch_loss=2.392918\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:38 INFO 140645276194624] #quality_metric: host=algo-1, epoch=143, batch=0 train loss <loss>=2.39291787148\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:38 INFO 140645276194624] Epoch[143] Batch[5] avg_epoch_loss=2.514318\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:38 INFO 140645276194624] #quality_metric: host=algo-1, epoch=143, batch=5 train loss <loss>=2.5143182675\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:38 INFO 140645276194624] Epoch[143] Batch [5]#011Speed: 1987.94 samples/sec#011loss=2.514318\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:38 INFO 140645276194624] Epoch[143] Batch[10] avg_epoch_loss=2.524712\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:38 INFO 140645276194624] #quality_metric: host=algo-1, epoch=143, batch=10 train loss <loss>=2.53718547821\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:38 INFO 140645276194624] Epoch[143] Batch [10]#011Speed: 1814.32 samples/sec#011loss=2.537185\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:38 INFO 140645276194624] processed a total of 645 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 579.8709392547607, \"sum\": 579.8709392547607, \"min\": 579.8709392547607}}, \"EndTime\": 1589566118.400468, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566117.820148}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:38 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1112.09791202 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:38 INFO 140645276194624] #progress_metric: host=algo-1, completed 36 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:38 INFO 140645276194624] #quality_metric: host=algo-1, epoch=143, train loss <loss>=2.52471245419\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:38 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:38 INFO 140645276194624] Epoch[144] Batch[0] avg_epoch_loss=2.645855\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:38 INFO 140645276194624] #quality_metric: host=algo-1, epoch=144, batch=0 train loss <loss>=2.64585494995\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:38 INFO 140645276194624] Epoch[144] Batch[5] avg_epoch_loss=2.587455\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:38 INFO 140645276194624] #quality_metric: host=algo-1, epoch=144, batch=5 train loss <loss>=2.58745511373\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:38 INFO 140645276194624] Epoch[144] Batch [5]#011Speed: 1989.89 samples/sec#011loss=2.587455\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:38 INFO 140645276194624] Epoch[144] Batch[10] avg_epoch_loss=2.542075\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:38 INFO 140645276194624] #quality_metric: host=algo-1, epoch=144, batch=10 train loss <loss>=2.48761944771\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:38 INFO 140645276194624] Epoch[144] Batch [10]#011Speed: 1807.04 samples/sec#011loss=2.487619\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:38 INFO 140645276194624] processed a total of 647 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 576.0989189147949, \"sum\": 576.0989189147949, \"min\": 576.0989189147949}}, \"EndTime\": 1589566118.977101, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566118.400544}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:38 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1122.85447203 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:38 INFO 140645276194624] #progress_metric: host=algo-1, completed 36 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:38 INFO 140645276194624] #quality_metric: host=algo-1, epoch=144, train loss <loss>=2.54207526554\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:38 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:39 INFO 140645276194624] Epoch[145] Batch[0] avg_epoch_loss=2.683914\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:39 INFO 140645276194624] #quality_metric: host=algo-1, epoch=145, batch=0 train loss <loss>=2.68391394615\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:39 INFO 140645276194624] Epoch[145] Batch[5] avg_epoch_loss=2.645931\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:39 INFO 140645276194624] #quality_metric: host=algo-1, epoch=145, batch=5 train loss <loss>=2.64593140284\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:39 INFO 140645276194624] Epoch[145] Batch [5]#011Speed: 2006.65 samples/sec#011loss=2.645931\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:39 INFO 140645276194624] Epoch[145] Batch[10] avg_epoch_loss=2.644286\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:39 INFO 140645276194624] #quality_metric: host=algo-1, epoch=145, batch=10 train loss <loss>=2.64231243134\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:39 INFO 140645276194624] Epoch[145] Batch [10]#011Speed: 1805.47 samples/sec#011loss=2.642312\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:39 INFO 140645276194624] processed a total of 669 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 626.4729499816895, \"sum\": 626.4729499816895, \"min\": 626.4729499816895}}, \"EndTime\": 1589566119.604036, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566118.977177}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:39 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1067.69069576 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:39 INFO 140645276194624] #progress_metric: host=algo-1, completed 36 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:39 INFO 140645276194624] #quality_metric: host=algo-1, epoch=145, train loss <loss>=2.64428641579\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:39 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:39 INFO 140645276194624] Epoch[146] Batch[0] avg_epoch_loss=2.486986\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:39 INFO 140645276194624] #quality_metric: host=algo-1, epoch=146, batch=0 train loss <loss>=2.48698592186\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:40 INFO 140645276194624] Epoch[146] Batch[5] avg_epoch_loss=2.531963\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:40 INFO 140645276194624] #quality_metric: host=algo-1, epoch=146, batch=5 train loss <loss>=2.53196267287\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:40 INFO 140645276194624] Epoch[146] Batch [5]#011Speed: 1909.56 samples/sec#011loss=2.531963\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:40 INFO 140645276194624] processed a total of 632 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 597.3520278930664, \"sum\": 597.3520278930664, \"min\": 597.3520278930664}}, \"EndTime\": 1589566120.201877, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566119.604113}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:40 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1057.79572748 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:40 INFO 140645276194624] #progress_metric: host=algo-1, completed 36 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:40 INFO 140645276194624] #quality_metric: host=algo-1, epoch=146, train loss <loss>=2.55980830193\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:40 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:40 INFO 140645276194624] Epoch[147] Batch[0] avg_epoch_loss=2.568210\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:40 INFO 140645276194624] #quality_metric: host=algo-1, epoch=147, batch=0 train loss <loss>=2.56821012497\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:40 INFO 140645276194624] Epoch[147] Batch[5] avg_epoch_loss=2.539791\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:40 INFO 140645276194624] #quality_metric: host=algo-1, epoch=147, batch=5 train loss <loss>=2.53979098797\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:40 INFO 140645276194624] Epoch[147] Batch [5]#011Speed: 1981.82 samples/sec#011loss=2.539791\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:40 INFO 140645276194624] Epoch[147] Batch[10] avg_epoch_loss=2.548767\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:40 INFO 140645276194624] #quality_metric: host=algo-1, epoch=147, batch=10 train loss <loss>=2.55953812599\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:40 INFO 140645276194624] Epoch[147] Batch [10]#011Speed: 1838.38 samples/sec#011loss=2.559538\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:40 INFO 140645276194624] processed a total of 646 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 614.5920753479004, \"sum\": 614.5920753479004, \"min\": 614.5920753479004}}, \"EndTime\": 1589566120.816985, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566120.201958}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:40 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1050.91738211 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:40 INFO 140645276194624] #progress_metric: host=algo-1, completed 37 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:40 INFO 140645276194624] #quality_metric: host=algo-1, epoch=147, train loss <loss>=2.5487669598\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:40 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:41 INFO 140645276194624] Epoch[148] Batch[0] avg_epoch_loss=2.622542\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:41 INFO 140645276194624] #quality_metric: host=algo-1, epoch=148, batch=0 train loss <loss>=2.62254190445\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:41 INFO 140645276194624] Epoch[148] Batch[5] avg_epoch_loss=2.576839\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:41 INFO 140645276194624] #quality_metric: host=algo-1, epoch=148, batch=5 train loss <loss>=2.57683932781\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:41 INFO 140645276194624] Epoch[148] Batch [5]#011Speed: 1932.27 samples/sec#011loss=2.576839\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:41 INFO 140645276194624] Epoch[148] Batch[10] avg_epoch_loss=2.541873\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:41 INFO 140645276194624] #quality_metric: host=algo-1, epoch=148, batch=10 train loss <loss>=2.49991235733\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:41 INFO 140645276194624] Epoch[148] Batch [10]#011Speed: 1942.43 samples/sec#011loss=2.499912\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:41 INFO 140645276194624] processed a total of 655 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 593.095064163208, \"sum\": 593.095064163208, \"min\": 593.095064163208}}, \"EndTime\": 1589566121.410586, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566120.81706}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:41 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1104.1732293 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:41 INFO 140645276194624] #progress_metric: host=algo-1, completed 37 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:41 INFO 140645276194624] #quality_metric: host=algo-1, epoch=148, train loss <loss>=2.54187252305\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:41 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:41 INFO 140645276194624] Epoch[149] Batch[0] avg_epoch_loss=2.491693\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:41 INFO 140645276194624] #quality_metric: host=algo-1, epoch=149, batch=0 train loss <loss>=2.49169278145\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:41 INFO 140645276194624] Epoch[149] Batch[5] avg_epoch_loss=2.521181\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:41 INFO 140645276194624] #quality_metric: host=algo-1, epoch=149, batch=5 train loss <loss>=2.52118062973\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:41 INFO 140645276194624] Epoch[149] Batch [5]#011Speed: 1767.51 samples/sec#011loss=2.521181\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:42 INFO 140645276194624] Epoch[149] Batch[10] avg_epoch_loss=2.483150\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:42 INFO 140645276194624] #quality_metric: host=algo-1, epoch=149, batch=10 train loss <loss>=2.43751330376\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:42 INFO 140645276194624] Epoch[149] Batch [10]#011Speed: 1923.25 samples/sec#011loss=2.437513\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:42 INFO 140645276194624] processed a total of 653 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 592.1080112457275, \"sum\": 592.1080112457275, \"min\": 592.1080112457275}}, \"EndTime\": 1589566122.003188, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566121.41066}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:42 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1102.56362742 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:42 INFO 140645276194624] #progress_metric: host=algo-1, completed 37 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:42 INFO 140645276194624] #quality_metric: host=algo-1, epoch=149, train loss <loss>=2.48315002701\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:42 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:42 INFO 140645276194624] Epoch[150] Batch[0] avg_epoch_loss=2.599094\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:42 INFO 140645276194624] #quality_metric: host=algo-1, epoch=150, batch=0 train loss <loss>=2.59909415245\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:42 INFO 140645276194624] Epoch[150] Batch[5] avg_epoch_loss=2.570614\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:42 INFO 140645276194624] #quality_metric: host=algo-1, epoch=150, batch=5 train loss <loss>=2.57061441739\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:42 INFO 140645276194624] Epoch[150] Batch [5]#011Speed: 1968.84 samples/sec#011loss=2.570614\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:42 INFO 140645276194624] Epoch[150] Batch[10] avg_epoch_loss=2.498200\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:42 INFO 140645276194624] #quality_metric: host=algo-1, epoch=150, batch=10 train loss <loss>=2.41130180359\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:42 INFO 140645276194624] Epoch[150] Batch [10]#011Speed: 1816.60 samples/sec#011loss=2.411302\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:42 INFO 140645276194624] processed a total of 645 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 613.3930683135986, \"sum\": 613.3930683135986, \"min\": 613.3930683135986}}, \"EndTime\": 1589566122.617072, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566122.003265}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:42 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1051.33800348 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:42 INFO 140645276194624] #progress_metric: host=algo-1, completed 37 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:42 INFO 140645276194624] #quality_metric: host=algo-1, epoch=150, train loss <loss>=2.49819959294\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:42 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:42 INFO 140645276194624] Epoch[151] Batch[0] avg_epoch_loss=2.678133\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:42 INFO 140645276194624] #quality_metric: host=algo-1, epoch=151, batch=0 train loss <loss>=2.6781334877\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:43 INFO 140645276194624] Epoch[151] Batch[5] avg_epoch_loss=2.630955\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:43 INFO 140645276194624] #quality_metric: host=algo-1, epoch=151, batch=5 train loss <loss>=2.63095494111\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:43 INFO 140645276194624] Epoch[151] Batch [5]#011Speed: 1951.29 samples/sec#011loss=2.630955\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:43 INFO 140645276194624] Epoch[151] Batch[10] avg_epoch_loss=2.573351\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:43 INFO 140645276194624] #quality_metric: host=algo-1, epoch=151, batch=10 train loss <loss>=2.50422616005\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:43 INFO 140645276194624] Epoch[151] Batch [10]#011Speed: 1822.80 samples/sec#011loss=2.504226\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:43 INFO 140645276194624] processed a total of 644 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 578.7410736083984, \"sum\": 578.7410736083984, \"min\": 578.7410736083984}}, \"EndTime\": 1589566123.196307, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566122.617148}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:43 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1112.54702187 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:43 INFO 140645276194624] #progress_metric: host=algo-1, completed 38 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:43 INFO 140645276194624] #quality_metric: host=algo-1, epoch=151, train loss <loss>=2.57335094972\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:43 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:43 INFO 140645276194624] Epoch[152] Batch[0] avg_epoch_loss=2.604629\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:43 INFO 140645276194624] #quality_metric: host=algo-1, epoch=152, batch=0 train loss <loss>=2.60462880135\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:43 INFO 140645276194624] Epoch[152] Batch[5] avg_epoch_loss=2.493701\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:43 INFO 140645276194624] #quality_metric: host=algo-1, epoch=152, batch=5 train loss <loss>=2.49370121956\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:43 INFO 140645276194624] Epoch[152] Batch [5]#011Speed: 1995.29 samples/sec#011loss=2.493701\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:43 INFO 140645276194624] processed a total of 619 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 541.7160987854004, \"sum\": 541.7160987854004, \"min\": 541.7160987854004}}, \"EndTime\": 1589566123.738546, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566123.196383}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:43 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1142.42260244 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:43 INFO 140645276194624] #progress_metric: host=algo-1, completed 38 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:43 INFO 140645276194624] #quality_metric: host=algo-1, epoch=152, train loss <loss>=2.50518913269\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:43 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:43 INFO 140645276194624] Epoch[153] Batch[0] avg_epoch_loss=2.470563\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:43 INFO 140645276194624] #quality_metric: host=algo-1, epoch=153, batch=0 train loss <loss>=2.47056341171\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:44 INFO 140645276194624] Epoch[153] Batch[5] avg_epoch_loss=2.505011\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:44 INFO 140645276194624] #quality_metric: host=algo-1, epoch=153, batch=5 train loss <loss>=2.50501104196\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:44 INFO 140645276194624] Epoch[153] Batch [5]#011Speed: 1886.16 samples/sec#011loss=2.505011\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:44 INFO 140645276194624] Epoch[153] Batch[10] avg_epoch_loss=2.521906\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:44 INFO 140645276194624] #quality_metric: host=algo-1, epoch=153, batch=10 train loss <loss>=2.54217905998\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:44 INFO 140645276194624] Epoch[153] Batch [10]#011Speed: 1948.99 samples/sec#011loss=2.542179\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:44 INFO 140645276194624] processed a total of 666 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 579.0860652923584, \"sum\": 579.0860652923584, \"min\": 579.0860652923584}}, \"EndTime\": 1589566124.318153, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566123.738625}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:44 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1149.86986668 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:44 INFO 140645276194624] #progress_metric: host=algo-1, completed 38 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:44 INFO 140645276194624] #quality_metric: host=algo-1, epoch=153, train loss <loss>=2.52190559561\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:44 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:44 INFO 140645276194624] Epoch[154] Batch[0] avg_epoch_loss=2.482965\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:44 INFO 140645276194624] #quality_metric: host=algo-1, epoch=154, batch=0 train loss <loss>=2.48296499252\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:44 INFO 140645276194624] Epoch[154] Batch[5] avg_epoch_loss=2.495681\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:44 INFO 140645276194624] #quality_metric: host=algo-1, epoch=154, batch=5 train loss <loss>=2.49568148454\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:44 INFO 140645276194624] Epoch[154] Batch [5]#011Speed: 1875.36 samples/sec#011loss=2.495681\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:44 INFO 140645276194624] processed a total of 602 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 591.2151336669922, \"sum\": 591.2151336669922, \"min\": 591.2151336669922}}, \"EndTime\": 1589566124.909856, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566124.318228}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:44 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1018.03864559 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:44 INFO 140645276194624] #progress_metric: host=algo-1, completed 38 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:44 INFO 140645276194624] #quality_metric: host=algo-1, epoch=154, train loss <loss>=2.44648578167\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:44 INFO 140645276194624] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:44 INFO 140645276194624] Saved checkpoint to \"/opt/ml/model/state_47d3f254-de5a-4342-ba01-ea2a6c28417e-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 19.627809524536133, \"sum\": 19.627809524536133, \"min\": 19.627809524536133}}, \"EndTime\": 1589566124.930062, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566124.909937}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:45 INFO 140645276194624] Epoch[155] Batch[0] avg_epoch_loss=2.501419\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:45 INFO 140645276194624] #quality_metric: host=algo-1, epoch=155, batch=0 train loss <loss>=2.50141859055\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:45 INFO 140645276194624] Epoch[155] Batch[5] avg_epoch_loss=2.433648\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:45 INFO 140645276194624] #quality_metric: host=algo-1, epoch=155, batch=5 train loss <loss>=2.43364818891\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:45 INFO 140645276194624] Epoch[155] Batch [5]#011Speed: 1977.76 samples/sec#011loss=2.433648\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:45 INFO 140645276194624] processed a total of 608 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 558.7878227233887, \"sum\": 558.7878227233887, \"min\": 558.7878227233887}}, \"EndTime\": 1589566125.488994, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566124.93014}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:45 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1087.83559292 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:45 INFO 140645276194624] #progress_metric: host=algo-1, completed 39 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:45 INFO 140645276194624] #quality_metric: host=algo-1, epoch=155, train loss <loss>=2.46789569855\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:45 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:45 INFO 140645276194624] Epoch[156] Batch[0] avg_epoch_loss=2.412231\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:45 INFO 140645276194624] #quality_metric: host=algo-1, epoch=156, batch=0 train loss <loss>=2.41223096848\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:45 INFO 140645276194624] Epoch[156] Batch[5] avg_epoch_loss=2.497510\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:45 INFO 140645276194624] #quality_metric: host=algo-1, epoch=156, batch=5 train loss <loss>=2.497509559\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:45 INFO 140645276194624] Epoch[156] Batch [5]#011Speed: 1523.61 samples/sec#011loss=2.497510\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:46 INFO 140645276194624] Epoch[156] Batch[10] avg_epoch_loss=2.505929\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:46 INFO 140645276194624] #quality_metric: host=algo-1, epoch=156, batch=10 train loss <loss>=2.51603136063\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:46 INFO 140645276194624] Epoch[156] Batch [10]#011Speed: 1463.82 samples/sec#011loss=2.516031\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:46 INFO 140645276194624] processed a total of 661 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 673.306941986084, \"sum\": 673.306941986084, \"min\": 673.306941986084}}, \"EndTime\": 1589566126.162827, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566125.489075}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:46 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=981.587480704 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:46 INFO 140645276194624] #progress_metric: host=algo-1, completed 39 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:46 INFO 140645276194624] #quality_metric: host=algo-1, epoch=156, train loss <loss>=2.50592855974\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:46 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:46 INFO 140645276194624] Epoch[157] Batch[0] avg_epoch_loss=2.273276\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:46 INFO 140645276194624] #quality_metric: host=algo-1, epoch=157, batch=0 train loss <loss>=2.27327632904\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:46 INFO 140645276194624] Epoch[157] Batch[5] avg_epoch_loss=2.469733\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:46 INFO 140645276194624] #quality_metric: host=algo-1, epoch=157, batch=5 train loss <loss>=2.4697334369\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:46 INFO 140645276194624] Epoch[157] Batch [5]#011Speed: 1893.46 samples/sec#011loss=2.469733\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:46 INFO 140645276194624] processed a total of 639 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 548.051118850708, \"sum\": 548.051118850708, \"min\": 548.051118850708}}, \"EndTime\": 1589566126.711436, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566126.162887}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:46 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1165.68593514 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:46 INFO 140645276194624] #progress_metric: host=algo-1, completed 39 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:46 INFO 140645276194624] #quality_metric: host=algo-1, epoch=157, train loss <loss>=2.47677230835\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:46 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:46 INFO 140645276194624] Epoch[158] Batch[0] avg_epoch_loss=2.532049\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:46 INFO 140645276194624] #quality_metric: host=algo-1, epoch=158, batch=0 train loss <loss>=2.53204894066\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:47 INFO 140645276194624] Epoch[158] Batch[5] avg_epoch_loss=2.437143\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:47 INFO 140645276194624] #quality_metric: host=algo-1, epoch=158, batch=5 train loss <loss>=2.43714336554\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:47 INFO 140645276194624] Epoch[158] Batch [5]#011Speed: 1929.39 samples/sec#011loss=2.437143\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:47 INFO 140645276194624] Epoch[158] Batch[10] avg_epoch_loss=2.452835\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:47 INFO 140645276194624] #quality_metric: host=algo-1, epoch=158, batch=10 train loss <loss>=2.47166466713\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:47 INFO 140645276194624] Epoch[158] Batch [10]#011Speed: 1545.98 samples/sec#011loss=2.471665\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:47 INFO 140645276194624] processed a total of 647 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 597.4109172821045, \"sum\": 597.4109172821045, \"min\": 597.4109172821045}}, \"EndTime\": 1589566127.309384, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566126.71152}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:47 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1082.78929674 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:47 INFO 140645276194624] #progress_metric: host=algo-1, completed 39 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:47 INFO 140645276194624] #quality_metric: host=algo-1, epoch=158, train loss <loss>=2.45283486626\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:47 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:47 INFO 140645276194624] Epoch[159] Batch[0] avg_epoch_loss=2.525808\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:47 INFO 140645276194624] #quality_metric: host=algo-1, epoch=159, batch=0 train loss <loss>=2.52580809593\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:47 INFO 140645276194624] Epoch[159] Batch[5] avg_epoch_loss=2.558290\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:47 INFO 140645276194624] #quality_metric: host=algo-1, epoch=159, batch=5 train loss <loss>=2.55828980605\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:47 INFO 140645276194624] Epoch[159] Batch [5]#011Speed: 1968.14 samples/sec#011loss=2.558290\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:47 INFO 140645276194624] processed a total of 602 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 543.4579849243164, \"sum\": 543.4579849243164, \"min\": 543.4579849243164}}, \"EndTime\": 1589566127.853378, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566127.309464}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:47 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1107.4890842 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:47 INFO 140645276194624] #progress_metric: host=algo-1, completed 40 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:47 INFO 140645276194624] #quality_metric: host=algo-1, epoch=159, train loss <loss>=2.60927498341\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:47 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:48 INFO 140645276194624] Epoch[160] Batch[0] avg_epoch_loss=2.538990\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:48 INFO 140645276194624] #quality_metric: host=algo-1, epoch=160, batch=0 train loss <loss>=2.53899025917\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:48 INFO 140645276194624] Epoch[160] Batch[5] avg_epoch_loss=2.531126\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:48 INFO 140645276194624] #quality_metric: host=algo-1, epoch=160, batch=5 train loss <loss>=2.53112637997\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:48 INFO 140645276194624] Epoch[160] Batch [5]#011Speed: 1827.20 samples/sec#011loss=2.531126\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:48 INFO 140645276194624] Epoch[160] Batch[10] avg_epoch_loss=2.514061\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:48 INFO 140645276194624] #quality_metric: host=algo-1, epoch=160, batch=10 train loss <loss>=2.49358329773\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:48 INFO 140645276194624] Epoch[160] Batch [10]#011Speed: 1593.92 samples/sec#011loss=2.493583\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:48 INFO 140645276194624] processed a total of 644 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 637.5510692596436, \"sum\": 637.5510692596436, \"min\": 637.5510692596436}}, \"EndTime\": 1589566128.49143, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566127.853456}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:48 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1009.9361412 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:48 INFO 140645276194624] #progress_metric: host=algo-1, completed 40 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:48 INFO 140645276194624] #quality_metric: host=algo-1, epoch=160, train loss <loss>=2.51406134259\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:48 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:48 INFO 140645276194624] Epoch[161] Batch[0] avg_epoch_loss=2.409046\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:48 INFO 140645276194624] #quality_metric: host=algo-1, epoch=161, batch=0 train loss <loss>=2.40904593468\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:48 INFO 140645276194624] Epoch[161] Batch[5] avg_epoch_loss=2.471070\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:48 INFO 140645276194624] #quality_metric: host=algo-1, epoch=161, batch=5 train loss <loss>=2.47107036908\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:48 INFO 140645276194624] Epoch[161] Batch [5]#011Speed: 1874.41 samples/sec#011loss=2.471070\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:49 INFO 140645276194624] processed a total of 634 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 568.809986114502, \"sum\": 568.809986114502, \"min\": 568.809986114502}}, \"EndTime\": 1589566129.060736, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566128.491508}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:49 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1114.40219059 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:49 INFO 140645276194624] #progress_metric: host=algo-1, completed 40 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:49 INFO 140645276194624] #quality_metric: host=algo-1, epoch=161, train loss <loss>=2.4647705555\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:49 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:49 INFO 140645276194624] Epoch[162] Batch[0] avg_epoch_loss=2.388189\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:49 INFO 140645276194624] #quality_metric: host=algo-1, epoch=162, batch=0 train loss <loss>=2.38818860054\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:49 INFO 140645276194624] Epoch[162] Batch[5] avg_epoch_loss=2.473585\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:49 INFO 140645276194624] #quality_metric: host=algo-1, epoch=162, batch=5 train loss <loss>=2.47358465195\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:49 INFO 140645276194624] Epoch[162] Batch [5]#011Speed: 1988.73 samples/sec#011loss=2.473585\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:49 INFO 140645276194624] Epoch[162] Batch[10] avg_epoch_loss=2.463915\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:49 INFO 140645276194624] #quality_metric: host=algo-1, epoch=162, batch=10 train loss <loss>=2.45231070518\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:49 INFO 140645276194624] Epoch[162] Batch [10]#011Speed: 1825.52 samples/sec#011loss=2.452311\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:49 INFO 140645276194624] processed a total of 689 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 575.9940147399902, \"sum\": 575.9940147399902, \"min\": 575.9940147399902}}, \"EndTime\": 1589566129.637279, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566129.060808}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:49 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1195.96229701 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:49 INFO 140645276194624] #progress_metric: host=algo-1, completed 40 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:49 INFO 140645276194624] #quality_metric: host=algo-1, epoch=162, train loss <loss>=2.46391467615\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:49 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:49 INFO 140645276194624] Epoch[163] Batch[0] avg_epoch_loss=2.496511\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:49 INFO 140645276194624] #quality_metric: host=algo-1, epoch=163, batch=0 train loss <loss>=2.49651145935\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:50 INFO 140645276194624] Epoch[163] Batch[5] avg_epoch_loss=2.452046\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:50 INFO 140645276194624] #quality_metric: host=algo-1, epoch=163, batch=5 train loss <loss>=2.45204571883\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:50 INFO 140645276194624] Epoch[163] Batch [5]#011Speed: 1974.25 samples/sec#011loss=2.452046\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:50 INFO 140645276194624] Epoch[163] Batch[10] avg_epoch_loss=2.455008\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:50 INFO 140645276194624] #quality_metric: host=algo-1, epoch=163, batch=10 train loss <loss>=2.45856275558\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:50 INFO 140645276194624] Epoch[163] Batch [10]#011Speed: 1849.24 samples/sec#011loss=2.458563\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:50 INFO 140645276194624] processed a total of 727 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 649.5299339294434, \"sum\": 649.5299339294434, \"min\": 649.5299339294434}}, \"EndTime\": 1589566130.287288, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566129.637355}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:50 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1119.06928355 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:50 INFO 140645276194624] #progress_metric: host=algo-1, completed 41 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:50 INFO 140645276194624] #quality_metric: host=algo-1, epoch=163, train loss <loss>=2.42122960091\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:50 INFO 140645276194624] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:50 INFO 140645276194624] Saved checkpoint to \"/opt/ml/model/state_9790ebec-4297-4ea0-982d-c5241fa60b06-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 18.7380313873291, \"sum\": 18.7380313873291, \"min\": 18.7380313873291}}, \"EndTime\": 1589566130.306605, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566130.287369}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:50 INFO 140645276194624] Epoch[164] Batch[0] avg_epoch_loss=2.511219\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:50 INFO 140645276194624] #quality_metric: host=algo-1, epoch=164, batch=0 train loss <loss>=2.51121902466\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:50 INFO 140645276194624] Epoch[164] Batch[5] avg_epoch_loss=2.487482\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:50 INFO 140645276194624] #quality_metric: host=algo-1, epoch=164, batch=5 train loss <loss>=2.48748175303\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:50 INFO 140645276194624] Epoch[164] Batch [5]#011Speed: 1970.98 samples/sec#011loss=2.487482\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:50 INFO 140645276194624] processed a total of 571 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 486.9718551635742, \"sum\": 486.9718551635742, \"min\": 486.9718551635742}}, \"EndTime\": 1589566130.793726, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566130.306685}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:50 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1172.26080657 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:50 INFO 140645276194624] #progress_metric: host=algo-1, completed 41 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:50 INFO 140645276194624] #quality_metric: host=algo-1, epoch=164, train loss <loss>=2.46633124352\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:50 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:51 INFO 140645276194624] Epoch[165] Batch[0] avg_epoch_loss=2.406446\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:51 INFO 140645276194624] #quality_metric: host=algo-1, epoch=165, batch=0 train loss <loss>=2.40644574165\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:51 INFO 140645276194624] Epoch[165] Batch[5] avg_epoch_loss=2.528720\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:51 INFO 140645276194624] #quality_metric: host=algo-1, epoch=165, batch=5 train loss <loss>=2.52872021993\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:51 INFO 140645276194624] Epoch[165] Batch [5]#011Speed: 1885.91 samples/sec#011loss=2.528720\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:51 INFO 140645276194624] processed a total of 623 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 541.4941310882568, \"sum\": 541.4941310882568, \"min\": 541.4941310882568}}, \"EndTime\": 1589566131.335745, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566130.793808}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:51 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1150.32481488 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:51 INFO 140645276194624] #progress_metric: host=algo-1, completed 41 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:51 INFO 140645276194624] #quality_metric: host=algo-1, epoch=165, train loss <loss>=2.53102087975\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:51 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:51 INFO 140645276194624] Epoch[166] Batch[0] avg_epoch_loss=2.585180\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:51 INFO 140645276194624] #quality_metric: host=algo-1, epoch=166, batch=0 train loss <loss>=2.58518028259\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:51 INFO 140645276194624] Epoch[166] Batch[5] avg_epoch_loss=2.538679\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:51 INFO 140645276194624] #quality_metric: host=algo-1, epoch=166, batch=5 train loss <loss>=2.53867944082\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:51 INFO 140645276194624] Epoch[166] Batch [5]#011Speed: 1971.12 samples/sec#011loss=2.538679\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:51 INFO 140645276194624] Epoch[166] Batch[10] avg_epoch_loss=2.489826\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:51 INFO 140645276194624] #quality_metric: host=algo-1, epoch=166, batch=10 train loss <loss>=2.43120193481\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:51 INFO 140645276194624] Epoch[166] Batch [10]#011Speed: 1970.19 samples/sec#011loss=2.431202\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:51 INFO 140645276194624] processed a total of 644 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 567.7180290222168, \"sum\": 567.7180290222168, \"min\": 567.7180290222168}}, \"EndTime\": 1589566131.904019, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566131.335807}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:51 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1134.14256581 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:51 INFO 140645276194624] #progress_metric: host=algo-1, completed 41 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:51 INFO 140645276194624] #quality_metric: host=algo-1, epoch=166, train loss <loss>=2.489826029\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:51 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:52 INFO 140645276194624] Epoch[167] Batch[0] avg_epoch_loss=2.677862\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:52 INFO 140645276194624] #quality_metric: host=algo-1, epoch=167, batch=0 train loss <loss>=2.67786240578\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:52 INFO 140645276194624] Epoch[167] Batch[5] avg_epoch_loss=2.482835\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:52 INFO 140645276194624] #quality_metric: host=algo-1, epoch=167, batch=5 train loss <loss>=2.48283465703\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:52 INFO 140645276194624] Epoch[167] Batch [5]#011Speed: 1976.61 samples/sec#011loss=2.482835\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:52 INFO 140645276194624] Epoch[167] Batch[10] avg_epoch_loss=2.441522\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:52 INFO 140645276194624] #quality_metric: host=algo-1, epoch=167, batch=10 train loss <loss>=2.39194631577\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:52 INFO 140645276194624] Epoch[167] Batch [10]#011Speed: 1944.39 samples/sec#011loss=2.391946\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:52 INFO 140645276194624] processed a total of 663 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 572.4678039550781, \"sum\": 572.4678039550781, \"min\": 572.4678039550781}}, \"EndTime\": 1589566132.476979, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566131.904095}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:52 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1157.93491918 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:52 INFO 140645276194624] #progress_metric: host=algo-1, completed 42 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:52 INFO 140645276194624] #quality_metric: host=algo-1, epoch=167, train loss <loss>=2.44152177464\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:52 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:52 INFO 140645276194624] Epoch[168] Batch[0] avg_epoch_loss=2.384313\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:52 INFO 140645276194624] #quality_metric: host=algo-1, epoch=168, batch=0 train loss <loss>=2.3843126297\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:52 INFO 140645276194624] Epoch[168] Batch[5] avg_epoch_loss=2.446641\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:52 INFO 140645276194624] #quality_metric: host=algo-1, epoch=168, batch=5 train loss <loss>=2.446641167\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:52 INFO 140645276194624] Epoch[168] Batch [5]#011Speed: 1995.84 samples/sec#011loss=2.446641\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:53 INFO 140645276194624] Epoch[168] Batch[10] avg_epoch_loss=2.408229\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:53 INFO 140645276194624] #quality_metric: host=algo-1, epoch=168, batch=10 train loss <loss>=2.362134552\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:53 INFO 140645276194624] Epoch[168] Batch [10]#011Speed: 1897.45 samples/sec#011loss=2.362135\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:53 INFO 140645276194624] processed a total of 649 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 572.4689960479736, \"sum\": 572.4689960479736, \"min\": 572.4689960479736}}, \"EndTime\": 1589566133.049936, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566132.477048}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:53 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1133.47011742 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:53 INFO 140645276194624] #progress_metric: host=algo-1, completed 42 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:53 INFO 140645276194624] #quality_metric: host=algo-1, epoch=168, train loss <loss>=2.40822906928\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:53 INFO 140645276194624] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:53 INFO 140645276194624] Saved checkpoint to \"/opt/ml/model/state_7de2a411-b34d-4e1d-94a7-e25a70525a95-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 13.917922973632812, \"sum\": 13.917922973632812, \"min\": 13.917922973632812}}, \"EndTime\": 1589566133.064417, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566133.050007}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:53 INFO 140645276194624] Epoch[169] Batch[0] avg_epoch_loss=2.921708\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:53 INFO 140645276194624] #quality_metric: host=algo-1, epoch=169, batch=0 train loss <loss>=2.92170810699\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:53 INFO 140645276194624] Epoch[169] Batch[5] avg_epoch_loss=2.646500\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:53 INFO 140645276194624] #quality_metric: host=algo-1, epoch=169, batch=5 train loss <loss>=2.64650046825\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:53 INFO 140645276194624] Epoch[169] Batch [5]#011Speed: 1861.42 samples/sec#011loss=2.646500\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:53 INFO 140645276194624] Epoch[169] Batch[10] avg_epoch_loss=2.600587\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:53 INFO 140645276194624] #quality_metric: host=algo-1, epoch=169, batch=10 train loss <loss>=2.54549183846\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:53 INFO 140645276194624] Epoch[169] Batch [10]#011Speed: 1735.11 samples/sec#011loss=2.545492\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:53 INFO 140645276194624] processed a total of 675 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 585.4959487915039, \"sum\": 585.4959487915039, \"min\": 585.4959487915039}}, \"EndTime\": 1589566133.650062, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566133.064475}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:53 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1152.6406686 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:53 INFO 140645276194624] #progress_metric: host=algo-1, completed 42 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:53 INFO 140645276194624] #quality_metric: host=algo-1, epoch=169, train loss <loss>=2.60058745471\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:53 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:53 INFO 140645276194624] Epoch[170] Batch[0] avg_epoch_loss=2.528596\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:53 INFO 140645276194624] #quality_metric: host=algo-1, epoch=170, batch=0 train loss <loss>=2.52859640121\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:54 INFO 140645276194624] Epoch[170] Batch[5] avg_epoch_loss=2.469858\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:54 INFO 140645276194624] #quality_metric: host=algo-1, epoch=170, batch=5 train loss <loss>=2.46985805035\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:54 INFO 140645276194624] Epoch[170] Batch [5]#011Speed: 1854.13 samples/sec#011loss=2.469858\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:54 INFO 140645276194624] processed a total of 628 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 586.7660045623779, \"sum\": 586.7660045623779, \"min\": 586.7660045623779}}, \"EndTime\": 1589566134.237368, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566133.650137}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:54 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1070.06766149 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:54 INFO 140645276194624] #progress_metric: host=algo-1, completed 42 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:54 INFO 140645276194624] #quality_metric: host=algo-1, epoch=170, train loss <loss>=2.46972358227\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:54 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:54 INFO 140645276194624] Epoch[171] Batch[0] avg_epoch_loss=2.496889\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:54 INFO 140645276194624] #quality_metric: host=algo-1, epoch=171, batch=0 train loss <loss>=2.4968893528\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:54 INFO 140645276194624] Epoch[171] Batch[5] avg_epoch_loss=2.470497\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:54 INFO 140645276194624] #quality_metric: host=algo-1, epoch=171, batch=5 train loss <loss>=2.47049748898\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:54 INFO 140645276194624] Epoch[171] Batch [5]#011Speed: 1966.53 samples/sec#011loss=2.470497\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:54 INFO 140645276194624] processed a total of 590 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 551.3789653778076, \"sum\": 551.3789653778076, \"min\": 551.3789653778076}}, \"EndTime\": 1589566134.789347, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566134.237444}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:54 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1069.81176351 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:54 INFO 140645276194624] #progress_metric: host=algo-1, completed 43 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:54 INFO 140645276194624] #quality_metric: host=algo-1, epoch=171, train loss <loss>=2.44872763157\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:54 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:55 INFO 140645276194624] Epoch[172] Batch[0] avg_epoch_loss=2.465021\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:55 INFO 140645276194624] #quality_metric: host=algo-1, epoch=172, batch=0 train loss <loss>=2.46502137184\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:55 INFO 140645276194624] Epoch[172] Batch[5] avg_epoch_loss=2.506291\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:55 INFO 140645276194624] #quality_metric: host=algo-1, epoch=172, batch=5 train loss <loss>=2.50629119078\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:55 INFO 140645276194624] Epoch[172] Batch [5]#011Speed: 1828.86 samples/sec#011loss=2.506291\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:55 INFO 140645276194624] Epoch[172] Batch[10] avg_epoch_loss=2.473292\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:55 INFO 140645276194624] #quality_metric: host=algo-1, epoch=172, batch=10 train loss <loss>=2.43369245529\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:55 INFO 140645276194624] Epoch[172] Batch [10]#011Speed: 1946.61 samples/sec#011loss=2.433692\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:55 INFO 140645276194624] processed a total of 656 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 632.1589946746826, \"sum\": 632.1589946746826, \"min\": 632.1589946746826}}, \"EndTime\": 1589566135.422026, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566134.789429}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:55 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1037.53166522 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:55 INFO 140645276194624] #progress_metric: host=algo-1, completed 43 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:55 INFO 140645276194624] #quality_metric: host=algo-1, epoch=172, train loss <loss>=2.47329176556\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:55 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:55 INFO 140645276194624] Epoch[173] Batch[0] avg_epoch_loss=2.660000\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:55 INFO 140645276194624] #quality_metric: host=algo-1, epoch=173, batch=0 train loss <loss>=2.66000032425\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:55 INFO 140645276194624] Epoch[173] Batch[5] avg_epoch_loss=2.596361\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:55 INFO 140645276194624] #quality_metric: host=algo-1, epoch=173, batch=5 train loss <loss>=2.59636080265\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:55 INFO 140645276194624] Epoch[173] Batch [5]#011Speed: 1947.54 samples/sec#011loss=2.596361\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:55 INFO 140645276194624] processed a total of 609 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 573.4741687774658, \"sum\": 573.4741687774658, \"min\": 573.4741687774658}}, \"EndTime\": 1589566135.995991, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566135.422102}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:55 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1061.72685567 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:55 INFO 140645276194624] #progress_metric: host=algo-1, completed 43 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:55 INFO 140645276194624] #quality_metric: host=algo-1, epoch=173, train loss <loss>=2.55862421989\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:55 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:56 INFO 140645276194624] Epoch[174] Batch[0] avg_epoch_loss=2.505349\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:56 INFO 140645276194624] #quality_metric: host=algo-1, epoch=174, batch=0 train loss <loss>=2.50534939766\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:56 INFO 140645276194624] Epoch[174] Batch[5] avg_epoch_loss=2.554705\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:56 INFO 140645276194624] #quality_metric: host=algo-1, epoch=174, batch=5 train loss <loss>=2.55470486482\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:56 INFO 140645276194624] Epoch[174] Batch [5]#011Speed: 1991.69 samples/sec#011loss=2.554705\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:56 INFO 140645276194624] Epoch[174] Batch[10] avg_epoch_loss=2.524080\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:56 INFO 140645276194624] #quality_metric: host=algo-1, epoch=174, batch=10 train loss <loss>=2.48733010292\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:56 INFO 140645276194624] Epoch[174] Batch [10]#011Speed: 1950.20 samples/sec#011loss=2.487330\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:56 INFO 140645276194624] processed a total of 650 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 556.1850070953369, \"sum\": 556.1850070953369, \"min\": 556.1850070953369}}, \"EndTime\": 1589566136.552781, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566135.996073}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:56 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1168.44296898 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:56 INFO 140645276194624] #progress_metric: host=algo-1, completed 43 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:56 INFO 140645276194624] #quality_metric: host=algo-1, epoch=174, train loss <loss>=2.52407997305\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:56 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:56 INFO 140645276194624] Epoch[175] Batch[0] avg_epoch_loss=2.543642\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:56 INFO 140645276194624] #quality_metric: host=algo-1, epoch=175, batch=0 train loss <loss>=2.54364204407\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:56 INFO 140645276194624] Epoch[175] Batch[5] avg_epoch_loss=2.523041\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:56 INFO 140645276194624] #quality_metric: host=algo-1, epoch=175, batch=5 train loss <loss>=2.52304073175\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:56 INFO 140645276194624] Epoch[175] Batch [5]#011Speed: 1981.23 samples/sec#011loss=2.523041\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:57 INFO 140645276194624] processed a total of 631 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 531.7950248718262, \"sum\": 531.7950248718262, \"min\": 531.7950248718262}}, \"EndTime\": 1589566137.085076, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566136.55285}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:57 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1186.32454193 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:57 INFO 140645276194624] #progress_metric: host=algo-1, completed 44 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:57 INFO 140645276194624] #quality_metric: host=algo-1, epoch=175, train loss <loss>=2.49577140808\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:57 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:57 INFO 140645276194624] Epoch[176] Batch[0] avg_epoch_loss=2.451709\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:57 INFO 140645276194624] #quality_metric: host=algo-1, epoch=176, batch=0 train loss <loss>=2.45170903206\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:57 INFO 140645276194624] Epoch[176] Batch[5] avg_epoch_loss=2.434400\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:57 INFO 140645276194624] #quality_metric: host=algo-1, epoch=176, batch=5 train loss <loss>=2.4344000419\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:57 INFO 140645276194624] Epoch[176] Batch [5]#011Speed: 1998.51 samples/sec#011loss=2.434400\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:57 INFO 140645276194624] processed a total of 619 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 515.1779651641846, \"sum\": 515.1779651641846, \"min\": 515.1779651641846}}, \"EndTime\": 1589566137.600822, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566137.085145}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:57 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1201.29082373 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:57 INFO 140645276194624] #progress_metric: host=algo-1, completed 44 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:57 INFO 140645276194624] #quality_metric: host=algo-1, epoch=176, train loss <loss>=2.42974207401\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:57 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:57 INFO 140645276194624] Epoch[177] Batch[0] avg_epoch_loss=2.413949\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:57 INFO 140645276194624] #quality_metric: host=algo-1, epoch=177, batch=0 train loss <loss>=2.41394901276\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:57 INFO 140645276194624] Epoch[177] Batch[5] avg_epoch_loss=2.465328\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:57 INFO 140645276194624] #quality_metric: host=algo-1, epoch=177, batch=5 train loss <loss>=2.46532762051\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:57 INFO 140645276194624] Epoch[177] Batch [5]#011Speed: 1982.71 samples/sec#011loss=2.465328\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:58 INFO 140645276194624] processed a total of 604 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 515.204906463623, \"sum\": 515.204906463623, \"min\": 515.204906463623}}, \"EndTime\": 1589566138.116574, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566137.600891}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:58 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1172.09849227 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:58 INFO 140645276194624] #progress_metric: host=algo-1, completed 44 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:58 INFO 140645276194624] #quality_metric: host=algo-1, epoch=177, train loss <loss>=2.45299134254\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:58 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:58 INFO 140645276194624] Epoch[178] Batch[0] avg_epoch_loss=2.553306\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:58 INFO 140645276194624] #quality_metric: host=algo-1, epoch=178, batch=0 train loss <loss>=2.55330634117\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:58 INFO 140645276194624] Epoch[178] Batch[5] avg_epoch_loss=2.471332\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:58 INFO 140645276194624] #quality_metric: host=algo-1, epoch=178, batch=5 train loss <loss>=2.47133155664\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:58 INFO 140645276194624] Epoch[178] Batch [5]#011Speed: 1983.42 samples/sec#011loss=2.471332\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:58 INFO 140645276194624] Epoch[178] Batch[10] avg_epoch_loss=2.426730\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:58 INFO 140645276194624] #quality_metric: host=algo-1, epoch=178, batch=10 train loss <loss>=2.3732073307\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:58 INFO 140645276194624] Epoch[178] Batch [10]#011Speed: 1939.11 samples/sec#011loss=2.373207\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:58 INFO 140645276194624] processed a total of 660 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 553.0710220336914, \"sum\": 553.0710220336914, \"min\": 553.0710220336914}}, \"EndTime\": 1589566138.67022, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566138.116646}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:58 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1193.09043469 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:58 INFO 140645276194624] #progress_metric: host=algo-1, completed 44 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:58 INFO 140645276194624] #quality_metric: host=algo-1, epoch=178, train loss <loss>=2.42672963576\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:58 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:58 INFO 140645276194624] Epoch[179] Batch[0] avg_epoch_loss=2.331384\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:58 INFO 140645276194624] #quality_metric: host=algo-1, epoch=179, batch=0 train loss <loss>=2.33138394356\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:59 INFO 140645276194624] Epoch[179] Batch[5] avg_epoch_loss=2.433855\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:59 INFO 140645276194624] #quality_metric: host=algo-1, epoch=179, batch=5 train loss <loss>=2.43385481834\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:59 INFO 140645276194624] Epoch[179] Batch [5]#011Speed: 1991.20 samples/sec#011loss=2.433855\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:59 INFO 140645276194624] processed a total of 627 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 548.2289791107178, \"sum\": 548.2289791107178, \"min\": 548.2289791107178}}, \"EndTime\": 1589566139.219001, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566138.670296}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:59 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1143.44102873 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:59 INFO 140645276194624] #progress_metric: host=algo-1, completed 45 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:59 INFO 140645276194624] #quality_metric: host=algo-1, epoch=179, train loss <loss>=2.4814915657\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:59 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:59 INFO 140645276194624] Epoch[180] Batch[0] avg_epoch_loss=2.445677\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:59 INFO 140645276194624] #quality_metric: host=algo-1, epoch=180, batch=0 train loss <loss>=2.44567728043\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:59 INFO 140645276194624] Epoch[180] Batch[5] avg_epoch_loss=2.412078\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:59 INFO 140645276194624] #quality_metric: host=algo-1, epoch=180, batch=5 train loss <loss>=2.41207846006\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:59 INFO 140645276194624] Epoch[180] Batch [5]#011Speed: 1970.98 samples/sec#011loss=2.412078\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:59 INFO 140645276194624] Epoch[180] Batch[10] avg_epoch_loss=2.416659\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:59 INFO 140645276194624] #quality_metric: host=algo-1, epoch=180, batch=10 train loss <loss>=2.42215461731\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:59 INFO 140645276194624] Epoch[180] Batch [10]#011Speed: 1706.49 samples/sec#011loss=2.422155\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:59 INFO 140645276194624] processed a total of 641 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 593.7938690185547, \"sum\": 593.7938690185547, \"min\": 593.7938690185547}}, \"EndTime\": 1589566139.813354, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566139.219081}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:59 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1079.29377855 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:59 INFO 140645276194624] #progress_metric: host=algo-1, completed 45 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:59 INFO 140645276194624] #quality_metric: host=algo-1, epoch=180, train loss <loss>=2.41665853154\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:08:59 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:00 INFO 140645276194624] Epoch[181] Batch[0] avg_epoch_loss=2.534665\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:00 INFO 140645276194624] #quality_metric: host=algo-1, epoch=181, batch=0 train loss <loss>=2.53466463089\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:00 INFO 140645276194624] Epoch[181] Batch[5] avg_epoch_loss=2.533609\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:00 INFO 140645276194624] #quality_metric: host=algo-1, epoch=181, batch=5 train loss <loss>=2.53360903263\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:00 INFO 140645276194624] Epoch[181] Batch [5]#011Speed: 1645.42 samples/sec#011loss=2.533609\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:00 INFO 140645276194624] processed a total of 613 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 570.0030326843262, \"sum\": 570.0030326843262, \"min\": 570.0030326843262}}, \"EndTime\": 1589566140.383855, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566139.813432}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:00 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1075.2143028 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:00 INFO 140645276194624] #progress_metric: host=algo-1, completed 45 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:00 INFO 140645276194624] #quality_metric: host=algo-1, epoch=181, train loss <loss>=2.57630975246\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:00 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:00 INFO 140645276194624] Epoch[182] Batch[0] avg_epoch_loss=2.688658\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:00 INFO 140645276194624] #quality_metric: host=algo-1, epoch=182, batch=0 train loss <loss>=2.68865847588\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:00 INFO 140645276194624] Epoch[182] Batch[5] avg_epoch_loss=2.584421\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:00 INFO 140645276194624] #quality_metric: host=algo-1, epoch=182, batch=5 train loss <loss>=2.58442103863\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:00 INFO 140645276194624] Epoch[182] Batch [5]#011Speed: 1631.54 samples/sec#011loss=2.584421\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:00 INFO 140645276194624] processed a total of 597 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 579.5450210571289, \"sum\": 579.5450210571289, \"min\": 579.5450210571289}}, \"EndTime\": 1589566140.963923, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566140.383935}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:00 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1029.91758519 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:00 INFO 140645276194624] #progress_metric: host=algo-1, completed 45 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:00 INFO 140645276194624] #quality_metric: host=algo-1, epoch=182, train loss <loss>=2.5525454998\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:00 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:01 INFO 140645276194624] Epoch[183] Batch[0] avg_epoch_loss=2.463486\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:01 INFO 140645276194624] #quality_metric: host=algo-1, epoch=183, batch=0 train loss <loss>=2.46348571777\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:01 INFO 140645276194624] Epoch[183] Batch[5] avg_epoch_loss=2.471367\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:01 INFO 140645276194624] #quality_metric: host=algo-1, epoch=183, batch=5 train loss <loss>=2.47136676311\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:01 INFO 140645276194624] Epoch[183] Batch [5]#011Speed: 1808.13 samples/sec#011loss=2.471367\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:01 INFO 140645276194624] processed a total of 630 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 571.6609954833984, \"sum\": 571.6609954833984, \"min\": 571.6609954833984}}, \"EndTime\": 1589566141.536083, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566140.963998}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:01 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1101.8279573 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:01 INFO 140645276194624] #progress_metric: host=algo-1, completed 46 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:01 INFO 140645276194624] #quality_metric: host=algo-1, epoch=183, train loss <loss>=2.45191316605\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:01 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:01 INFO 140645276194624] Epoch[184] Batch[0] avg_epoch_loss=2.461382\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:01 INFO 140645276194624] #quality_metric: host=algo-1, epoch=184, batch=0 train loss <loss>=2.46138191223\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:01 INFO 140645276194624] Epoch[184] Batch[5] avg_epoch_loss=2.444268\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:01 INFO 140645276194624] #quality_metric: host=algo-1, epoch=184, batch=5 train loss <loss>=2.44426846504\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:01 INFO 140645276194624] Epoch[184] Batch [5]#011Speed: 1864.91 samples/sec#011loss=2.444268\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:02 INFO 140645276194624] Epoch[184] Batch[10] avg_epoch_loss=2.591880\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:02 INFO 140645276194624] #quality_metric: host=algo-1, epoch=184, batch=10 train loss <loss>=2.76901397705\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:02 INFO 140645276194624] Epoch[184] Batch [10]#011Speed: 1917.76 samples/sec#011loss=2.769014\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:02 INFO 140645276194624] processed a total of 657 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 591.7820930480957, \"sum\": 591.7820930480957, \"min\": 591.7820930480957}}, \"EndTime\": 1589566142.128392, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566141.536163}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:02 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1110.0015782 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:02 INFO 140645276194624] #progress_metric: host=algo-1, completed 46 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:02 INFO 140645276194624] #quality_metric: host=algo-1, epoch=184, train loss <loss>=2.59188006141\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:02 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:02 INFO 140645276194624] Epoch[185] Batch[0] avg_epoch_loss=2.475260\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:02 INFO 140645276194624] #quality_metric: host=algo-1, epoch=185, batch=0 train loss <loss>=2.47526049614\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:02 INFO 140645276194624] Epoch[185] Batch[5] avg_epoch_loss=2.429660\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:02 INFO 140645276194624] #quality_metric: host=algo-1, epoch=185, batch=5 train loss <loss>=2.42966043949\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:02 INFO 140645276194624] Epoch[185] Batch [5]#011Speed: 1848.04 samples/sec#011loss=2.429660\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:02 INFO 140645276194624] processed a total of 614 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 584.0861797332764, \"sum\": 584.0861797332764, \"min\": 584.0861797332764}}, \"EndTime\": 1589566142.712986, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566142.128466}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:02 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1051.00795366 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:02 INFO 140645276194624] #progress_metric: host=algo-1, completed 46 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:02 INFO 140645276194624] #quality_metric: host=algo-1, epoch=185, train loss <loss>=2.44464480877\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:02 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:02 INFO 140645276194624] Epoch[186] Batch[0] avg_epoch_loss=2.497055\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:02 INFO 140645276194624] #quality_metric: host=algo-1, epoch=186, batch=0 train loss <loss>=2.49705481529\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:03 INFO 140645276194624] Epoch[186] Batch[5] avg_epoch_loss=2.390183\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:03 INFO 140645276194624] #quality_metric: host=algo-1, epoch=186, batch=5 train loss <loss>=2.3901826938\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:03 INFO 140645276194624] Epoch[186] Batch [5]#011Speed: 1701.31 samples/sec#011loss=2.390183\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:03 INFO 140645276194624] Epoch[186] Batch[10] avg_epoch_loss=2.342627\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:03 INFO 140645276194624] #quality_metric: host=algo-1, epoch=186, batch=10 train loss <loss>=2.28556098938\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:03 INFO 140645276194624] Epoch[186] Batch [10]#011Speed: 1958.96 samples/sec#011loss=2.285561\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:03 INFO 140645276194624] processed a total of 655 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 629.1909217834473, \"sum\": 629.1909217834473, \"min\": 629.1909217834473}}, \"EndTime\": 1589566143.342711, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566142.713067}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:03 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1040.83410116 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:03 INFO 140645276194624] #progress_metric: host=algo-1, completed 46 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:03 INFO 140645276194624] #quality_metric: host=algo-1, epoch=186, train loss <loss>=2.34262737361\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:03 INFO 140645276194624] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:03 INFO 140645276194624] Saved checkpoint to \"/opt/ml/model/state_5e854c31-f927-4e40-8255-f5984c40eb06-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 17.132043838500977, \"sum\": 17.132043838500977, \"min\": 17.132043838500977}}, \"EndTime\": 1589566143.360406, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566143.342785}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:03 INFO 140645276194624] Epoch[187] Batch[0] avg_epoch_loss=2.358793\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:03 INFO 140645276194624] #quality_metric: host=algo-1, epoch=187, batch=0 train loss <loss>=2.35879325867\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:03 INFO 140645276194624] Epoch[187] Batch[5] avg_epoch_loss=2.435303\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:03 INFO 140645276194624] #quality_metric: host=algo-1, epoch=187, batch=5 train loss <loss>=2.43530273438\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:03 INFO 140645276194624] Epoch[187] Batch [5]#011Speed: 1784.47 samples/sec#011loss=2.435303\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:03 INFO 140645276194624] Epoch[187] Batch[10] avg_epoch_loss=2.412231\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:03 INFO 140645276194624] #quality_metric: host=algo-1, epoch=187, batch=10 train loss <loss>=2.38454551697\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:03 INFO 140645276194624] Epoch[187] Batch [10]#011Speed: 1699.04 samples/sec#011loss=2.384546\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:03 INFO 140645276194624] processed a total of 662 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 612.5459671020508, \"sum\": 612.5459671020508, \"min\": 612.5459671020508}}, \"EndTime\": 1589566143.973082, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566143.360477}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:03 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1080.53586792 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:03 INFO 140645276194624] #progress_metric: host=algo-1, completed 47 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:03 INFO 140645276194624] #quality_metric: host=algo-1, epoch=187, train loss <loss>=2.41223127192\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:03 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:04 INFO 140645276194624] Epoch[188] Batch[0] avg_epoch_loss=2.545387\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:04 INFO 140645276194624] #quality_metric: host=algo-1, epoch=188, batch=0 train loss <loss>=2.54538702965\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:04 INFO 140645276194624] Epoch[188] Batch[5] avg_epoch_loss=2.498705\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:04 INFO 140645276194624] #quality_metric: host=algo-1, epoch=188, batch=5 train loss <loss>=2.49870546659\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:04 INFO 140645276194624] Epoch[188] Batch [5]#011Speed: 1964.24 samples/sec#011loss=2.498705\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:04 INFO 140645276194624] Epoch[188] Batch[10] avg_epoch_loss=2.464157\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:04 INFO 140645276194624] #quality_metric: host=algo-1, epoch=188, batch=10 train loss <loss>=2.42269787788\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:04 INFO 140645276194624] Epoch[188] Batch [10]#011Speed: 1826.79 samples/sec#011loss=2.422698\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:04 INFO 140645276194624] processed a total of 643 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 593.7700271606445, \"sum\": 593.7700271606445, \"min\": 593.7700271606445}}, \"EndTime\": 1589566144.567348, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566143.973158}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:04 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1082.70825134 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:04 INFO 140645276194624] #progress_metric: host=algo-1, completed 47 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:04 INFO 140645276194624] #quality_metric: host=algo-1, epoch=188, train loss <loss>=2.46415656263\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:04 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:04 INFO 140645276194624] Epoch[189] Batch[0] avg_epoch_loss=3.229566\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:04 INFO 140645276194624] #quality_metric: host=algo-1, epoch=189, batch=0 train loss <loss>=3.22956633568\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:04 INFO 140645276194624] Epoch[189] Batch[5] avg_epoch_loss=2.843156\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:04 INFO 140645276194624] #quality_metric: host=algo-1, epoch=189, batch=5 train loss <loss>=2.84315621853\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:04 INFO 140645276194624] Epoch[189] Batch [5]#011Speed: 2019.57 samples/sec#011loss=2.843156\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:05 INFO 140645276194624] processed a total of 629 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 558.0289363861084, \"sum\": 558.0289363861084, \"min\": 558.0289363861084}}, \"EndTime\": 1589566145.125871, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566144.567423}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:05 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1126.94527974 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:05 INFO 140645276194624] #progress_metric: host=algo-1, completed 47 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:05 INFO 140645276194624] #quality_metric: host=algo-1, epoch=189, train loss <loss>=2.79062023163\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:05 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:05 INFO 140645276194624] Epoch[190] Batch[0] avg_epoch_loss=2.810884\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:05 INFO 140645276194624] #quality_metric: host=algo-1, epoch=190, batch=0 train loss <loss>=2.81088399887\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:05 INFO 140645276194624] Epoch[190] Batch[5] avg_epoch_loss=2.614311\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:05 INFO 140645276194624] #quality_metric: host=algo-1, epoch=190, batch=5 train loss <loss>=2.61431101958\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:05 INFO 140645276194624] Epoch[190] Batch [5]#011Speed: 1668.66 samples/sec#011loss=2.614311\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:05 INFO 140645276194624] processed a total of 567 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 542.5019264221191, \"sum\": 542.5019264221191, \"min\": 542.5019264221191}}, \"EndTime\": 1589566145.668887, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566145.12595}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:05 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1044.92613016 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:05 INFO 140645276194624] #progress_metric: host=algo-1, completed 47 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:05 INFO 140645276194624] #quality_metric: host=algo-1, epoch=190, train loss <loss>=2.60009998745\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:05 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:05 INFO 140645276194624] Epoch[191] Batch[0] avg_epoch_loss=2.571783\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:05 INFO 140645276194624] #quality_metric: host=algo-1, epoch=191, batch=0 train loss <loss>=2.57178258896\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:06 INFO 140645276194624] Epoch[191] Batch[5] avg_epoch_loss=2.543048\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:06 INFO 140645276194624] #quality_metric: host=algo-1, epoch=191, batch=5 train loss <loss>=2.54304786523\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:06 INFO 140645276194624] Epoch[191] Batch [5]#011Speed: 1925.70 samples/sec#011loss=2.543048\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:06 INFO 140645276194624] processed a total of 633 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 552.3390769958496, \"sum\": 552.3390769958496, \"min\": 552.3390769958496}}, \"EndTime\": 1589566146.221779, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566145.668969}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:06 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1145.79280915 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:06 INFO 140645276194624] #progress_metric: host=algo-1, completed 48 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:06 INFO 140645276194624] #quality_metric: host=algo-1, epoch=191, train loss <loss>=2.52135267258\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:06 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:06 INFO 140645276194624] Epoch[192] Batch[0] avg_epoch_loss=2.526078\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:06 INFO 140645276194624] #quality_metric: host=algo-1, epoch=192, batch=0 train loss <loss>=2.5260784626\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:06 INFO 140645276194624] Epoch[192] Batch[5] avg_epoch_loss=2.497122\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:06 INFO 140645276194624] #quality_metric: host=algo-1, epoch=192, batch=5 train loss <loss>=2.49712153276\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:06 INFO 140645276194624] Epoch[192] Batch [5]#011Speed: 1957.34 samples/sec#011loss=2.497122\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:06 INFO 140645276194624] Epoch[192] Batch[10] avg_epoch_loss=2.446625\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:06 INFO 140645276194624] #quality_metric: host=algo-1, epoch=192, batch=10 train loss <loss>=2.38602809906\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:06 INFO 140645276194624] Epoch[192] Batch [10]#011Speed: 1894.44 samples/sec#011loss=2.386028\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:06 INFO 140645276194624] processed a total of 659 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 563.7779235839844, \"sum\": 563.7779235839844, \"min\": 563.7779235839844}}, \"EndTime\": 1589566146.786081, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566146.22186}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:06 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1168.68251268 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:06 INFO 140645276194624] #progress_metric: host=algo-1, completed 48 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:06 INFO 140645276194624] #quality_metric: host=algo-1, epoch=192, train loss <loss>=2.44662451744\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:06 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:07 INFO 140645276194624] Epoch[193] Batch[0] avg_epoch_loss=2.375596\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:07 INFO 140645276194624] #quality_metric: host=algo-1, epoch=193, batch=0 train loss <loss>=2.37559628487\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:07 INFO 140645276194624] Epoch[193] Batch[5] avg_epoch_loss=2.409869\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:07 INFO 140645276194624] #quality_metric: host=algo-1, epoch=193, batch=5 train loss <loss>=2.40986947219\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:07 INFO 140645276194624] Epoch[193] Batch [5]#011Speed: 1999.20 samples/sec#011loss=2.409869\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:07 INFO 140645276194624] Epoch[193] Batch[10] avg_epoch_loss=2.503767\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:07 INFO 140645276194624] #quality_metric: host=algo-1, epoch=193, batch=10 train loss <loss>=2.6164431572\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:07 INFO 140645276194624] Epoch[193] Batch [10]#011Speed: 1834.18 samples/sec#011loss=2.616443\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:07 INFO 140645276194624] processed a total of 659 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 572.829008102417, \"sum\": 572.829008102417, \"min\": 572.829008102417}}, \"EndTime\": 1589566147.359397, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566146.786152}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:07 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1150.2136998 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:07 INFO 140645276194624] #progress_metric: host=algo-1, completed 48 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:07 INFO 140645276194624] #quality_metric: host=algo-1, epoch=193, train loss <loss>=2.50376660174\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:07 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:07 INFO 140645276194624] Epoch[194] Batch[0] avg_epoch_loss=2.670445\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:07 INFO 140645276194624] #quality_metric: host=algo-1, epoch=194, batch=0 train loss <loss>=2.67044472694\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:07 INFO 140645276194624] Epoch[194] Batch[5] avg_epoch_loss=2.546929\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:07 INFO 140645276194624] #quality_metric: host=algo-1, epoch=194, batch=5 train loss <loss>=2.54692924023\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:07 INFO 140645276194624] Epoch[194] Batch [5]#011Speed: 1917.59 samples/sec#011loss=2.546929\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:07 INFO 140645276194624] processed a total of 622 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 543.032169342041, \"sum\": 543.032169342041, \"min\": 543.032169342041}}, \"EndTime\": 1589566147.902896, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566147.35947}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:07 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1145.22608502 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:07 INFO 140645276194624] #progress_metric: host=algo-1, completed 48 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:07 INFO 140645276194624] #quality_metric: host=algo-1, epoch=194, train loss <loss>=2.52376596928\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:07 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:08 INFO 140645276194624] Epoch[195] Batch[0] avg_epoch_loss=2.464146\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:08 INFO 140645276194624] #quality_metric: host=algo-1, epoch=195, batch=0 train loss <loss>=2.46414613724\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:08 INFO 140645276194624] Epoch[195] Batch[5] avg_epoch_loss=2.427985\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:08 INFO 140645276194624] #quality_metric: host=algo-1, epoch=195, batch=5 train loss <loss>=2.42798511187\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:08 INFO 140645276194624] Epoch[195] Batch [5]#011Speed: 1604.90 samples/sec#011loss=2.427985\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:08 INFO 140645276194624] processed a total of 635 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 548.2618808746338, \"sum\": 548.2618808746338, \"min\": 548.2618808746338}}, \"EndTime\": 1589566148.45174, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566147.902957}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:08 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1157.96040458 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:08 INFO 140645276194624] #progress_metric: host=algo-1, completed 49 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:08 INFO 140645276194624] #quality_metric: host=algo-1, epoch=195, train loss <loss>=2.4091594696\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:08 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:08 INFO 140645276194624] Epoch[196] Batch[0] avg_epoch_loss=2.400794\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:08 INFO 140645276194624] #quality_metric: host=algo-1, epoch=196, batch=0 train loss <loss>=2.40079402924\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:08 INFO 140645276194624] Epoch[196] Batch[5] avg_epoch_loss=2.464603\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:08 INFO 140645276194624] #quality_metric: host=algo-1, epoch=196, batch=5 train loss <loss>=2.46460282803\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:08 INFO 140645276194624] Epoch[196] Batch [5]#011Speed: 1991.07 samples/sec#011loss=2.464603\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:09 INFO 140645276194624] Epoch[196] Batch[10] avg_epoch_loss=2.457892\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:09 INFO 140645276194624] #quality_metric: host=algo-1, epoch=196, batch=10 train loss <loss>=2.44983997345\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:09 INFO 140645276194624] Epoch[196] Batch [10]#011Speed: 1830.68 samples/sec#011loss=2.449840\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:09 INFO 140645276194624] processed a total of 665 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 578.1459808349609, \"sum\": 578.1459808349609, \"min\": 578.1459808349609}}, \"EndTime\": 1589566149.030413, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566148.451821}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:09 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1150.01132195 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:09 INFO 140645276194624] #progress_metric: host=algo-1, completed 49 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:09 INFO 140645276194624] #quality_metric: host=algo-1, epoch=196, train loss <loss>=2.45789243958\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:09 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:09 INFO 140645276194624] Epoch[197] Batch[0] avg_epoch_loss=2.580497\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:09 INFO 140645276194624] #quality_metric: host=algo-1, epoch=197, batch=0 train loss <loss>=2.58049678802\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:09 INFO 140645276194624] Epoch[197] Batch[5] avg_epoch_loss=2.506819\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:09 INFO 140645276194624] #quality_metric: host=algo-1, epoch=197, batch=5 train loss <loss>=2.50681861242\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:09 INFO 140645276194624] Epoch[197] Batch [5]#011Speed: 2023.59 samples/sec#011loss=2.506819\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:09 INFO 140645276194624] processed a total of 639 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 525.0229835510254, \"sum\": 525.0229835510254, \"min\": 525.0229835510254}}, \"EndTime\": 1589566149.555958, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566149.030488}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:09 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1216.82986467 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:09 INFO 140645276194624] #progress_metric: host=algo-1, completed 49 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:09 INFO 140645276194624] #quality_metric: host=algo-1, epoch=197, train loss <loss>=2.47936866283\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:09 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:09 INFO 140645276194624] Epoch[198] Batch[0] avg_epoch_loss=2.431181\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:09 INFO 140645276194624] #quality_metric: host=algo-1, epoch=198, batch=0 train loss <loss>=2.4311811924\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:09 INFO 140645276194624] Epoch[198] Batch[5] avg_epoch_loss=2.432466\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:09 INFO 140645276194624] #quality_metric: host=algo-1, epoch=198, batch=5 train loss <loss>=2.43246606986\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:09 INFO 140645276194624] Epoch[198] Batch [5]#011Speed: 1827.74 samples/sec#011loss=2.432466\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:10 INFO 140645276194624] Epoch[198] Batch[10] avg_epoch_loss=2.395969\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:10 INFO 140645276194624] #quality_metric: host=algo-1, epoch=198, batch=10 train loss <loss>=2.35217308998\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:10 INFO 140645276194624] Epoch[198] Batch [10]#011Speed: 1951.90 samples/sec#011loss=2.352173\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:10 INFO 140645276194624] processed a total of 649 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 579.0019035339355, \"sum\": 579.0019035339355, \"min\": 579.0019035339355}}, \"EndTime\": 1589566150.135461, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566149.556036}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:10 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1120.68121658 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:10 INFO 140645276194624] #progress_metric: host=algo-1, completed 49 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:10 INFO 140645276194624] #quality_metric: host=algo-1, epoch=198, train loss <loss>=2.39596926082\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:10 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:10 INFO 140645276194624] Epoch[199] Batch[0] avg_epoch_loss=2.339807\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:10 INFO 140645276194624] #quality_metric: host=algo-1, epoch=199, batch=0 train loss <loss>=2.33980679512\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:10 INFO 140645276194624] Epoch[199] Batch[5] avg_epoch_loss=2.345326\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:10 INFO 140645276194624] #quality_metric: host=algo-1, epoch=199, batch=5 train loss <loss>=2.34532550971\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:10 INFO 140645276194624] Epoch[199] Batch [5]#011Speed: 1986.01 samples/sec#011loss=2.345326\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:10 INFO 140645276194624] Epoch[199] Batch[10] avg_epoch_loss=2.342049\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:10 INFO 140645276194624] #quality_metric: host=algo-1, epoch=199, batch=10 train loss <loss>=2.33811793327\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:10 INFO 140645276194624] Epoch[199] Batch [10]#011Speed: 1885.29 samples/sec#011loss=2.338118\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:10 INFO 140645276194624] processed a total of 658 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 587.3048305511475, \"sum\": 587.3048305511475, \"min\": 587.3048305511475}}, \"EndTime\": 1589566150.723261, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566150.135537}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:10 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1120.15801244 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:10 INFO 140645276194624] #progress_metric: host=algo-1, completed 50 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:10 INFO 140645276194624] #quality_metric: host=algo-1, epoch=199, train loss <loss>=2.3420493386\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:10 INFO 140645276194624] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:10 INFO 140645276194624] Saved checkpoint to \"/opt/ml/model/state_0cef735f-995a-4421-a9fa-8021d5caec36-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 14.140129089355469, \"sum\": 14.140129089355469, \"min\": 14.140129089355469}}, \"EndTime\": 1589566150.738001, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566150.72334}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:10 INFO 140645276194624] Epoch[200] Batch[0] avg_epoch_loss=2.420782\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:10 INFO 140645276194624] #quality_metric: host=algo-1, epoch=200, batch=0 train loss <loss>=2.4207816124\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:11 INFO 140645276194624] Epoch[200] Batch[5] avg_epoch_loss=2.412744\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:11 INFO 140645276194624] #quality_metric: host=algo-1, epoch=200, batch=5 train loss <loss>=2.41274424394\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:11 INFO 140645276194624] Epoch[200] Batch [5]#011Speed: 1867.33 samples/sec#011loss=2.412744\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:11 INFO 140645276194624] Epoch[200] Batch[10] avg_epoch_loss=2.377925\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:11 INFO 140645276194624] #quality_metric: host=algo-1, epoch=200, batch=10 train loss <loss>=2.33614177704\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:11 INFO 140645276194624] Epoch[200] Batch [10]#011Speed: 1909.22 samples/sec#011loss=2.336142\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:11 INFO 140645276194624] processed a total of 671 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 578.2811641693115, \"sum\": 578.2811641693115, \"min\": 578.2811641693115}}, \"EndTime\": 1589566151.316423, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566150.738079}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:11 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1160.10276454 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:11 INFO 140645276194624] #progress_metric: host=algo-1, completed 50 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:11 INFO 140645276194624] #quality_metric: host=algo-1, epoch=200, train loss <loss>=2.3779249408\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:11 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:11 INFO 140645276194624] Epoch[201] Batch[0] avg_epoch_loss=2.528650\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:11 INFO 140645276194624] #quality_metric: host=algo-1, epoch=201, batch=0 train loss <loss>=2.52865004539\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:11 INFO 140645276194624] Epoch[201] Batch[5] avg_epoch_loss=2.470604\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:11 INFO 140645276194624] #quality_metric: host=algo-1, epoch=201, batch=5 train loss <loss>=2.47060362498\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:11 INFO 140645276194624] Epoch[201] Batch [5]#011Speed: 1957.76 samples/sec#011loss=2.470604\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:11 INFO 140645276194624] Epoch[201] Batch[10] avg_epoch_loss=2.453511\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:11 INFO 140645276194624] #quality_metric: host=algo-1, epoch=201, batch=10 train loss <loss>=2.43299994469\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:11 INFO 140645276194624] Epoch[201] Batch [10]#011Speed: 1914.94 samples/sec#011loss=2.433000\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:11 INFO 140645276194624] processed a total of 648 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 563.3718967437744, \"sum\": 563.3718967437744, \"min\": 563.3718967437744}}, \"EndTime\": 1589566151.880353, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566151.316503}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:11 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1150.01660429 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:11 INFO 140645276194624] #progress_metric: host=algo-1, completed 50 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:11 INFO 140645276194624] #quality_metric: host=algo-1, epoch=201, train loss <loss>=2.45351104303\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:11 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:12 INFO 140645276194624] Epoch[202] Batch[0] avg_epoch_loss=2.376238\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:12 INFO 140645276194624] #quality_metric: host=algo-1, epoch=202, batch=0 train loss <loss>=2.3762383461\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:12 INFO 140645276194624] Epoch[202] Batch[5] avg_epoch_loss=2.475121\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:12 INFO 140645276194624] #quality_metric: host=algo-1, epoch=202, batch=5 train loss <loss>=2.47512121995\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:12 INFO 140645276194624] Epoch[202] Batch [5]#011Speed: 1978.15 samples/sec#011loss=2.475121\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:12 INFO 140645276194624] processed a total of 588 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 537.6851558685303, \"sum\": 537.6851558685303, \"min\": 537.6851558685303}}, \"EndTime\": 1589566152.418533, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566151.880419}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:12 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1093.35134062 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:12 INFO 140645276194624] #progress_metric: host=algo-1, completed 50 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:12 INFO 140645276194624] #quality_metric: host=algo-1, epoch=202, train loss <loss>=2.58162515163\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:12 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:12 INFO 140645276194624] Epoch[203] Batch[0] avg_epoch_loss=2.944119\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:12 INFO 140645276194624] #quality_metric: host=algo-1, epoch=203, batch=0 train loss <loss>=2.94411921501\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:12 INFO 140645276194624] Epoch[203] Batch[5] avg_epoch_loss=2.747016\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:12 INFO 140645276194624] #quality_metric: host=algo-1, epoch=203, batch=5 train loss <loss>=2.74701627096\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:12 INFO 140645276194624] Epoch[203] Batch [5]#011Speed: 1958.11 samples/sec#011loss=2.747016\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:12 INFO 140645276194624] processed a total of 638 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 554.3570518493652, \"sum\": 554.3570518493652, \"min\": 554.3570518493652}}, \"EndTime\": 1589566152.973473, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566152.418607}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:12 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1150.59233126 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:12 INFO 140645276194624] #progress_metric: host=algo-1, completed 51 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:12 INFO 140645276194624] #quality_metric: host=algo-1, epoch=203, train loss <loss>=2.69637393951\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:12 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:13 INFO 140645276194624] Epoch[204] Batch[0] avg_epoch_loss=2.504598\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:13 INFO 140645276194624] #quality_metric: host=algo-1, epoch=204, batch=0 train loss <loss>=2.50459837914\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:13 INFO 140645276194624] Epoch[204] Batch[5] avg_epoch_loss=2.529656\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:13 INFO 140645276194624] #quality_metric: host=algo-1, epoch=204, batch=5 train loss <loss>=2.52965637048\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:13 INFO 140645276194624] Epoch[204] Batch [5]#011Speed: 2009.70 samples/sec#011loss=2.529656\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:13 INFO 140645276194624] Epoch[204] Batch[10] avg_epoch_loss=2.545076\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:13 INFO 140645276194624] #quality_metric: host=algo-1, epoch=204, batch=10 train loss <loss>=2.56357855797\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:13 INFO 140645276194624] Epoch[204] Batch [10]#011Speed: 1950.74 samples/sec#011loss=2.563579\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:13 INFO 140645276194624] processed a total of 658 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 563.3950233459473, \"sum\": 563.3950233459473, \"min\": 563.3950233459473}}, \"EndTime\": 1589566153.537405, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566152.973554}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:13 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1167.68719198 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:13 INFO 140645276194624] #progress_metric: host=algo-1, completed 51 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:13 INFO 140645276194624] #quality_metric: host=algo-1, epoch=204, train loss <loss>=2.54507554661\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:13 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:13 INFO 140645276194624] Epoch[205] Batch[0] avg_epoch_loss=2.536197\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:13 INFO 140645276194624] #quality_metric: host=algo-1, epoch=205, batch=0 train loss <loss>=2.53619670868\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:13 INFO 140645276194624] Epoch[205] Batch[5] avg_epoch_loss=2.516643\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:13 INFO 140645276194624] #quality_metric: host=algo-1, epoch=205, batch=5 train loss <loss>=2.51664276918\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:13 INFO 140645276194624] Epoch[205] Batch [5]#011Speed: 2018.49 samples/sec#011loss=2.516643\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:14 INFO 140645276194624] processed a total of 609 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 556.6799640655518, \"sum\": 556.6799640655518, \"min\": 556.6799640655518}}, \"EndTime\": 1589566154.094576, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566153.537481}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:14 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1093.75396552 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:14 INFO 140645276194624] #progress_metric: host=algo-1, completed 51 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:14 INFO 140645276194624] #quality_metric: host=algo-1, epoch=205, train loss <loss>=2.51026878357\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:14 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:14 INFO 140645276194624] Epoch[206] Batch[0] avg_epoch_loss=2.414029\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:14 INFO 140645276194624] #quality_metric: host=algo-1, epoch=206, batch=0 train loss <loss>=2.41402864456\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:14 INFO 140645276194624] Epoch[206] Batch[5] avg_epoch_loss=2.452985\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:14 INFO 140645276194624] #quality_metric: host=algo-1, epoch=206, batch=5 train loss <loss>=2.45298496882\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:14 INFO 140645276194624] Epoch[206] Batch [5]#011Speed: 1869.83 samples/sec#011loss=2.452985\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:14 INFO 140645276194624] processed a total of 635 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 520.5140113830566, \"sum\": 520.5140113830566, \"min\": 520.5140113830566}}, \"EndTime\": 1589566154.615643, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566154.094656}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:14 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1219.72503118 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:14 INFO 140645276194624] #progress_metric: host=algo-1, completed 51 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:14 INFO 140645276194624] #quality_metric: host=algo-1, epoch=206, train loss <loss>=2.45549843311\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:14 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:14 INFO 140645276194624] Epoch[207] Batch[0] avg_epoch_loss=2.425943\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:14 INFO 140645276194624] #quality_metric: host=algo-1, epoch=207, batch=0 train loss <loss>=2.42594337463\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:15 INFO 140645276194624] Epoch[207] Batch[5] avg_epoch_loss=2.464142\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:15 INFO 140645276194624] #quality_metric: host=algo-1, epoch=207, batch=5 train loss <loss>=2.46414240201\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:15 INFO 140645276194624] Epoch[207] Batch [5]#011Speed: 1766.79 samples/sec#011loss=2.464142\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:15 INFO 140645276194624] processed a total of 630 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 527.8770923614502, \"sum\": 527.8770923614502, \"min\": 527.8770923614502}}, \"EndTime\": 1589566155.144086, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566154.615704}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:15 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1193.19340857 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:15 INFO 140645276194624] #progress_metric: host=algo-1, completed 52 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:15 INFO 140645276194624] #quality_metric: host=algo-1, epoch=207, train loss <loss>=2.43221149445\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:15 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:15 INFO 140645276194624] Epoch[208] Batch[0] avg_epoch_loss=2.377777\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:15 INFO 140645276194624] #quality_metric: host=algo-1, epoch=208, batch=0 train loss <loss>=2.37777709961\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:15 INFO 140645276194624] Epoch[208] Batch[5] avg_epoch_loss=2.380328\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:15 INFO 140645276194624] #quality_metric: host=algo-1, epoch=208, batch=5 train loss <loss>=2.38032825788\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:15 INFO 140645276194624] Epoch[208] Batch [5]#011Speed: 2000.69 samples/sec#011loss=2.380328\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:15 INFO 140645276194624] Epoch[208] Batch[10] avg_epoch_loss=2.383861\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:15 INFO 140645276194624] #quality_metric: host=algo-1, epoch=208, batch=10 train loss <loss>=2.38810138702\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:15 INFO 140645276194624] Epoch[208] Batch [10]#011Speed: 1888.92 samples/sec#011loss=2.388101\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:15 INFO 140645276194624] processed a total of 654 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 588.9058113098145, \"sum\": 588.9058113098145, \"min\": 588.9058113098145}}, \"EndTime\": 1589566155.733531, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566155.144167}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:15 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1110.32240406 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:15 INFO 140645276194624] #progress_metric: host=algo-1, completed 52 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:15 INFO 140645276194624] #quality_metric: host=algo-1, epoch=208, train loss <loss>=2.3838614984\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:15 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:15 INFO 140645276194624] Epoch[209] Batch[0] avg_epoch_loss=2.427221\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:15 INFO 140645276194624] #quality_metric: host=algo-1, epoch=209, batch=0 train loss <loss>=2.4272210598\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:16 INFO 140645276194624] Epoch[209] Batch[5] avg_epoch_loss=2.377669\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:16 INFO 140645276194624] #quality_metric: host=algo-1, epoch=209, batch=5 train loss <loss>=2.37766905626\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:16 INFO 140645276194624] Epoch[209] Batch [5]#011Speed: 1989.47 samples/sec#011loss=2.377669\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:16 INFO 140645276194624] processed a total of 634 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 583.698034286499, \"sum\": 583.698034286499, \"min\": 583.698034286499}}, \"EndTime\": 1589566156.317738, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566155.733608}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:16 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1085.95893741 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:16 INFO 140645276194624] #progress_metric: host=algo-1, completed 52 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:16 INFO 140645276194624] #quality_metric: host=algo-1, epoch=209, train loss <loss>=2.36594762802\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:16 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:16 INFO 140645276194624] Epoch[210] Batch[0] avg_epoch_loss=2.505875\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:16 INFO 140645276194624] #quality_metric: host=algo-1, epoch=210, batch=0 train loss <loss>=2.50587511063\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:16 INFO 140645276194624] Epoch[210] Batch[5] avg_epoch_loss=2.439468\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:16 INFO 140645276194624] #quality_metric: host=algo-1, epoch=210, batch=5 train loss <loss>=2.43946774801\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:16 INFO 140645276194624] Epoch[210] Batch [5]#011Speed: 1976.39 samples/sec#011loss=2.439468\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:16 INFO 140645276194624] processed a total of 620 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 554.3220043182373, \"sum\": 554.3220043182373, \"min\": 554.3220043182373}}, \"EndTime\": 1589566156.872609, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566156.317818}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:16 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1118.2473169 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:16 INFO 140645276194624] #progress_metric: host=algo-1, completed 52 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:16 INFO 140645276194624] #quality_metric: host=algo-1, epoch=210, train loss <loss>=2.49794664383\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:16 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:17 INFO 140645276194624] Epoch[211] Batch[0] avg_epoch_loss=2.768946\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:17 INFO 140645276194624] #quality_metric: host=algo-1, epoch=211, batch=0 train loss <loss>=2.76894569397\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:17 INFO 140645276194624] Epoch[211] Batch[5] avg_epoch_loss=2.520501\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:17 INFO 140645276194624] #quality_metric: host=algo-1, epoch=211, batch=5 train loss <loss>=2.52050109704\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:17 INFO 140645276194624] Epoch[211] Batch [5]#011Speed: 1917.89 samples/sec#011loss=2.520501\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:17 INFO 140645276194624] Epoch[211] Batch[10] avg_epoch_loss=2.452218\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:17 INFO 140645276194624] #quality_metric: host=algo-1, epoch=211, batch=10 train loss <loss>=2.37027740479\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:17 INFO 140645276194624] Epoch[211] Batch [10]#011Speed: 1923.20 samples/sec#011loss=2.370277\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:17 INFO 140645276194624] processed a total of 673 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 596.7810153961182, \"sum\": 596.7810153961182, \"min\": 596.7810153961182}}, \"EndTime\": 1589566157.469927, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566156.872689}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:17 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1127.50918179 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:17 INFO 140645276194624] #progress_metric: host=algo-1, completed 53 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:17 INFO 140645276194624] #quality_metric: host=algo-1, epoch=211, train loss <loss>=2.45221760056\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:17 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:17 INFO 140645276194624] Epoch[212] Batch[0] avg_epoch_loss=2.455030\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:17 INFO 140645276194624] #quality_metric: host=algo-1, epoch=212, batch=0 train loss <loss>=2.45503044128\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:17 INFO 140645276194624] Epoch[212] Batch[5] avg_epoch_loss=2.415371\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:17 INFO 140645276194624] #quality_metric: host=algo-1, epoch=212, batch=5 train loss <loss>=2.41537110011\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:17 INFO 140645276194624] Epoch[212] Batch [5]#011Speed: 1862.65 samples/sec#011loss=2.415371\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:18 INFO 140645276194624] Epoch[212] Batch[10] avg_epoch_loss=2.440952\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:18 INFO 140645276194624] #quality_metric: host=algo-1, epoch=212, batch=10 train loss <loss>=2.47164974213\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:18 INFO 140645276194624] Epoch[212] Batch [10]#011Speed: 1952.60 samples/sec#011loss=2.471650\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:18 INFO 140645276194624] processed a total of 668 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 597.0277786254883, \"sum\": 597.0277786254883, \"min\": 597.0277786254883}}, \"EndTime\": 1589566158.06747, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566157.470002}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:18 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1118.67309438 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:18 INFO 140645276194624] #progress_metric: host=algo-1, completed 53 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:18 INFO 140645276194624] #quality_metric: host=algo-1, epoch=212, train loss <loss>=2.44095230103\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:18 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:18 INFO 140645276194624] Epoch[213] Batch[0] avg_epoch_loss=2.589619\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:18 INFO 140645276194624] #quality_metric: host=algo-1, epoch=213, batch=0 train loss <loss>=2.58961892128\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:18 INFO 140645276194624] Epoch[213] Batch[5] avg_epoch_loss=2.522957\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:18 INFO 140645276194624] #quality_metric: host=algo-1, epoch=213, batch=5 train loss <loss>=2.52295732498\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:18 INFO 140645276194624] Epoch[213] Batch [5]#011Speed: 2002.04 samples/sec#011loss=2.522957\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:18 INFO 140645276194624] Epoch[213] Batch[10] avg_epoch_loss=2.524623\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:18 INFO 140645276194624] #quality_metric: host=algo-1, epoch=213, batch=10 train loss <loss>=2.52662210464\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:18 INFO 140645276194624] Epoch[213] Batch [10]#011Speed: 1934.54 samples/sec#011loss=2.526622\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:18 INFO 140645276194624] processed a total of 677 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 559.3938827514648, \"sum\": 559.3938827514648, \"min\": 559.3938827514648}}, \"EndTime\": 1589566158.627373, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566158.067539}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:18 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1210.00434137 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:18 INFO 140645276194624] #progress_metric: host=algo-1, completed 53 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:18 INFO 140645276194624] #quality_metric: host=algo-1, epoch=213, train loss <loss>=2.52462313392\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:18 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:18 INFO 140645276194624] Epoch[214] Batch[0] avg_epoch_loss=2.488520\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:18 INFO 140645276194624] #quality_metric: host=algo-1, epoch=214, batch=0 train loss <loss>=2.48851966858\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:19 INFO 140645276194624] Epoch[214] Batch[5] avg_epoch_loss=2.477301\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:19 INFO 140645276194624] #quality_metric: host=algo-1, epoch=214, batch=5 train loss <loss>=2.47730072339\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:19 INFO 140645276194624] Epoch[214] Batch [5]#011Speed: 2001.56 samples/sec#011loss=2.477301\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:19 INFO 140645276194624] Epoch[214] Batch[10] avg_epoch_loss=2.488701\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:19 INFO 140645276194624] #quality_metric: host=algo-1, epoch=214, batch=10 train loss <loss>=2.50238108635\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:19 INFO 140645276194624] Epoch[214] Batch [10]#011Speed: 1959.28 samples/sec#011loss=2.502381\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:19 INFO 140645276194624] processed a total of 647 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 552.4759292602539, \"sum\": 552.4759292602539, \"min\": 552.4759292602539}}, \"EndTime\": 1589566159.180376, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566158.627442}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:19 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1170.89468002 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:19 INFO 140645276194624] #progress_metric: host=algo-1, completed 53 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:19 INFO 140645276194624] #quality_metric: host=algo-1, epoch=214, train loss <loss>=2.48870088837\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:19 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:19 INFO 140645276194624] Epoch[215] Batch[0] avg_epoch_loss=2.743289\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:19 INFO 140645276194624] #quality_metric: host=algo-1, epoch=215, batch=0 train loss <loss>=2.743288517\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:19 INFO 140645276194624] Epoch[215] Batch[5] avg_epoch_loss=2.706187\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:19 INFO 140645276194624] #quality_metric: host=algo-1, epoch=215, batch=5 train loss <loss>=2.70618728797\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:19 INFO 140645276194624] Epoch[215] Batch [5]#011Speed: 1995.45 samples/sec#011loss=2.706187\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:19 INFO 140645276194624] processed a total of 631 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 529.2720794677734, \"sum\": 529.2720794677734, \"min\": 529.2720794677734}}, \"EndTime\": 1589566159.710143, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566159.18044}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:19 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1191.93123149 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:19 INFO 140645276194624] #progress_metric: host=algo-1, completed 54 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:19 INFO 140645276194624] #quality_metric: host=algo-1, epoch=215, train loss <loss>=2.71809790134\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:19 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:19 INFO 140645276194624] Epoch[216] Batch[0] avg_epoch_loss=2.679052\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:19 INFO 140645276194624] #quality_metric: host=algo-1, epoch=216, batch=0 train loss <loss>=2.67905187607\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:20 INFO 140645276194624] Epoch[216] Batch[5] avg_epoch_loss=2.566033\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:20 INFO 140645276194624] #quality_metric: host=algo-1, epoch=216, batch=5 train loss <loss>=2.56603336334\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:20 INFO 140645276194624] Epoch[216] Batch [5]#011Speed: 2013.07 samples/sec#011loss=2.566033\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:20 INFO 140645276194624] processed a total of 633 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 552.5469779968262, \"sum\": 552.5469779968262, \"min\": 552.5469779968262}}, \"EndTime\": 1589566160.263231, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566159.710225}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:20 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1145.35931442 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:20 INFO 140645276194624] #progress_metric: host=algo-1, completed 54 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:20 INFO 140645276194624] #quality_metric: host=algo-1, epoch=216, train loss <loss>=2.55400049686\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:20 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:20 INFO 140645276194624] Epoch[217] Batch[0] avg_epoch_loss=2.591400\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:20 INFO 140645276194624] #quality_metric: host=algo-1, epoch=217, batch=0 train loss <loss>=2.59139990807\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:20 INFO 140645276194624] Epoch[217] Batch[5] avg_epoch_loss=2.486589\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:20 INFO 140645276194624] #quality_metric: host=algo-1, epoch=217, batch=5 train loss <loss>=2.48658911387\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:20 INFO 140645276194624] Epoch[217] Batch [5]#011Speed: 1897.89 samples/sec#011loss=2.486589\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:20 INFO 140645276194624] Epoch[217] Batch[10] avg_epoch_loss=2.557837\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:20 INFO 140645276194624] #quality_metric: host=algo-1, epoch=217, batch=10 train loss <loss>=2.64333434105\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:20 INFO 140645276194624] Epoch[217] Batch [10]#011Speed: 1922.05 samples/sec#011loss=2.643334\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:20 INFO 140645276194624] processed a total of 645 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 556.6442012786865, \"sum\": 556.6442012786865, \"min\": 556.6442012786865}}, \"EndTime\": 1589566160.820429, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566160.263313}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:20 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1158.5423226 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:20 INFO 140645276194624] #progress_metric: host=algo-1, completed 54 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:20 INFO 140645276194624] #quality_metric: host=algo-1, epoch=217, train loss <loss>=2.55783694441\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:20 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:21 INFO 140645276194624] Epoch[218] Batch[0] avg_epoch_loss=3.026164\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:21 INFO 140645276194624] #quality_metric: host=algo-1, epoch=218, batch=0 train loss <loss>=3.02616429329\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:21 INFO 140645276194624] Epoch[218] Batch[5] avg_epoch_loss=2.759880\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:21 INFO 140645276194624] #quality_metric: host=algo-1, epoch=218, batch=5 train loss <loss>=2.75988022486\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:21 INFO 140645276194624] Epoch[218] Batch [5]#011Speed: 2019.21 samples/sec#011loss=2.759880\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:21 INFO 140645276194624] processed a total of 603 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 507.8539848327637, \"sum\": 507.8539848327637, \"min\": 507.8539848327637}}, \"EndTime\": 1589566161.328762, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566160.820482}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:21 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1187.07831295 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:21 INFO 140645276194624] #progress_metric: host=algo-1, completed 54 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:21 INFO 140645276194624] #quality_metric: host=algo-1, epoch=218, train loss <loss>=2.70014965534\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:21 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:21 INFO 140645276194624] Epoch[219] Batch[0] avg_epoch_loss=2.511265\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:21 INFO 140645276194624] #quality_metric: host=algo-1, epoch=219, batch=0 train loss <loss>=2.51126527786\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:21 INFO 140645276194624] Epoch[219] Batch[5] avg_epoch_loss=2.542900\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:21 INFO 140645276194624] #quality_metric: host=algo-1, epoch=219, batch=5 train loss <loss>=2.54289984703\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:21 INFO 140645276194624] Epoch[219] Batch [5]#011Speed: 2009.48 samples/sec#011loss=2.542900\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:21 INFO 140645276194624] processed a total of 617 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 510.8330249786377, \"sum\": 510.8330249786377, \"min\": 510.8330249786377}}, \"EndTime\": 1589566161.840111, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566161.328842}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:21 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1207.6276012 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:21 INFO 140645276194624] #progress_metric: host=algo-1, completed 55 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:21 INFO 140645276194624] #quality_metric: host=algo-1, epoch=219, train loss <loss>=2.49375090599\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:21 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:22 INFO 140645276194624] Epoch[220] Batch[0] avg_epoch_loss=2.311120\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:22 INFO 140645276194624] #quality_metric: host=algo-1, epoch=220, batch=0 train loss <loss>=2.31111979485\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:22 INFO 140645276194624] Epoch[220] Batch[5] avg_epoch_loss=2.387520\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:22 INFO 140645276194624] #quality_metric: host=algo-1, epoch=220, batch=5 train loss <loss>=2.38752003511\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:22 INFO 140645276194624] Epoch[220] Batch [5]#011Speed: 1980.97 samples/sec#011loss=2.387520\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:22 INFO 140645276194624] processed a total of 625 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 523.3838558197021, \"sum\": 523.3838558197021, \"min\": 523.3838558197021}}, \"EndTime\": 1589566162.363895, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566161.840163}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:22 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1193.88302548 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:22 INFO 140645276194624] #progress_metric: host=algo-1, completed 55 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:22 INFO 140645276194624] #quality_metric: host=algo-1, epoch=220, train loss <loss>=2.41090157032\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:22 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:22 INFO 140645276194624] Epoch[221] Batch[0] avg_epoch_loss=2.571138\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:22 INFO 140645276194624] #quality_metric: host=algo-1, epoch=221, batch=0 train loss <loss>=2.57113790512\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:22 INFO 140645276194624] Epoch[221] Batch[5] avg_epoch_loss=2.459419\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:22 INFO 140645276194624] #quality_metric: host=algo-1, epoch=221, batch=5 train loss <loss>=2.45941940943\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:22 INFO 140645276194624] Epoch[221] Batch [5]#011Speed: 1987.81 samples/sec#011loss=2.459419\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:22 INFO 140645276194624] processed a total of 625 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 548.1560230255127, \"sum\": 548.1560230255127, \"min\": 548.1560230255127}}, \"EndTime\": 1589566162.912582, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566162.363976}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:22 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1139.94089479 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:22 INFO 140645276194624] #progress_metric: host=algo-1, completed 55 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:22 INFO 140645276194624] #quality_metric: host=algo-1, epoch=221, train loss <loss>=2.49874649048\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:22 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:23 INFO 140645276194624] Epoch[222] Batch[0] avg_epoch_loss=2.359133\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:23 INFO 140645276194624] #quality_metric: host=algo-1, epoch=222, batch=0 train loss <loss>=2.35913276672\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:23 INFO 140645276194624] Epoch[222] Batch[5] avg_epoch_loss=2.408891\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:23 INFO 140645276194624] #quality_metric: host=algo-1, epoch=222, batch=5 train loss <loss>=2.40889088313\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:23 INFO 140645276194624] Epoch[222] Batch [5]#011Speed: 1959.01 samples/sec#011loss=2.408891\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:23 INFO 140645276194624] Epoch[222] Batch[10] avg_epoch_loss=2.340379\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:23 INFO 140645276194624] #quality_metric: host=algo-1, epoch=222, batch=10 train loss <loss>=2.25816452503\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:23 INFO 140645276194624] Epoch[222] Batch [10]#011Speed: 1941.03 samples/sec#011loss=2.258165\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:23 INFO 140645276194624] processed a total of 644 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 547.3189353942871, \"sum\": 547.3189353942871, \"min\": 547.3189353942871}}, \"EndTime\": 1589566163.46048, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566162.912663}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:23 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1176.41474327 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:23 INFO 140645276194624] #progress_metric: host=algo-1, completed 55 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:23 INFO 140645276194624] #quality_metric: host=algo-1, epoch=222, train loss <loss>=2.34037890218\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:23 INFO 140645276194624] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:23 INFO 140645276194624] Saved checkpoint to \"/opt/ml/model/state_3bc41509-785c-476a-890b-a3657dc676cf-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 13.631820678710938, \"sum\": 13.631820678710938, \"min\": 13.631820678710938}}, \"EndTime\": 1589566163.474658, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566163.460548}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:23 INFO 140645276194624] Epoch[223] Batch[0] avg_epoch_loss=2.500060\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:23 INFO 140645276194624] #quality_metric: host=algo-1, epoch=223, batch=0 train loss <loss>=2.5000603199\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:23 INFO 140645276194624] Epoch[223] Batch[5] avg_epoch_loss=2.381988\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:23 INFO 140645276194624] #quality_metric: host=algo-1, epoch=223, batch=5 train loss <loss>=2.38198840618\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:23 INFO 140645276194624] Epoch[223] Batch [5]#011Speed: 2005.31 samples/sec#011loss=2.381988\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:23 INFO 140645276194624] processed a total of 637 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 508.9221000671387, \"sum\": 508.9221000671387, \"min\": 508.9221000671387}}, \"EndTime\": 1589566163.983728, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566163.474732}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:23 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1251.36488554 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:23 INFO 140645276194624] #progress_metric: host=algo-1, completed 56 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:23 INFO 140645276194624] #quality_metric: host=algo-1, epoch=223, train loss <loss>=2.39172742367\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:23 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:24 INFO 140645276194624] Epoch[224] Batch[0] avg_epoch_loss=2.418936\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:24 INFO 140645276194624] #quality_metric: host=algo-1, epoch=224, batch=0 train loss <loss>=2.41893649101\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:24 INFO 140645276194624] Epoch[224] Batch[5] avg_epoch_loss=2.399121\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:24 INFO 140645276194624] #quality_metric: host=algo-1, epoch=224, batch=5 train loss <loss>=2.39912112554\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:24 INFO 140645276194624] Epoch[224] Batch [5]#011Speed: 1887.47 samples/sec#011loss=2.399121\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:24 INFO 140645276194624] Epoch[224] Batch[10] avg_epoch_loss=2.413879\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:24 INFO 140645276194624] #quality_metric: host=algo-1, epoch=224, batch=10 train loss <loss>=2.43158912659\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:24 INFO 140645276194624] Epoch[224] Batch [10]#011Speed: 1922.89 samples/sec#011loss=2.431589\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:24 INFO 140645276194624] processed a total of 647 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 553.2829761505127, \"sum\": 553.2829761505127, \"min\": 553.2829761505127}}, \"EndTime\": 1589566164.537578, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566163.983796}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:24 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1169.149261 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:24 INFO 140645276194624] #progress_metric: host=algo-1, completed 56 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:24 INFO 140645276194624] #quality_metric: host=algo-1, epoch=224, train loss <loss>=2.41387930783\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:24 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:24 INFO 140645276194624] Epoch[225] Batch[0] avg_epoch_loss=2.420109\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:24 INFO 140645276194624] #quality_metric: host=algo-1, epoch=225, batch=0 train loss <loss>=2.420109272\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:24 INFO 140645276194624] Epoch[225] Batch[5] avg_epoch_loss=2.437800\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:24 INFO 140645276194624] #quality_metric: host=algo-1, epoch=225, batch=5 train loss <loss>=2.43779973189\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:24 INFO 140645276194624] Epoch[225] Batch [5]#011Speed: 1826.48 samples/sec#011loss=2.437800\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:25 INFO 140645276194624] Epoch[225] Batch[10] avg_epoch_loss=2.540657\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:25 INFO 140645276194624] #quality_metric: host=algo-1, epoch=225, batch=10 train loss <loss>=2.66408638954\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:25 INFO 140645276194624] Epoch[225] Batch [10]#011Speed: 1962.85 samples/sec#011loss=2.664086\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:25 INFO 140645276194624] processed a total of 667 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 588.7560844421387, \"sum\": 588.7560844421387, \"min\": 588.7560844421387}}, \"EndTime\": 1589566165.12682, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566164.537654}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:25 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1132.68370901 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:25 INFO 140645276194624] #progress_metric: host=algo-1, completed 56 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:25 INFO 140645276194624] #quality_metric: host=algo-1, epoch=225, train loss <loss>=2.54065730355\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:25 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:25 INFO 140645276194624] Epoch[226] Batch[0] avg_epoch_loss=2.464771\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:25 INFO 140645276194624] #quality_metric: host=algo-1, epoch=226, batch=0 train loss <loss>=2.46477079391\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:25 INFO 140645276194624] Epoch[226] Batch[5] avg_epoch_loss=2.431949\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:25 INFO 140645276194624] #quality_metric: host=algo-1, epoch=226, batch=5 train loss <loss>=2.4319486618\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:25 INFO 140645276194624] Epoch[226] Batch [5]#011Speed: 1969.80 samples/sec#011loss=2.431949\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:25 INFO 140645276194624] Epoch[226] Batch[10] avg_epoch_loss=2.435249\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:25 INFO 140645276194624] #quality_metric: host=algo-1, epoch=226, batch=10 train loss <loss>=2.43920865059\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:25 INFO 140645276194624] Epoch[226] Batch [10]#011Speed: 1947.25 samples/sec#011loss=2.439209\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:25 INFO 140645276194624] processed a total of 652 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 574.7270584106445, \"sum\": 574.7270584106445, \"min\": 574.7270584106445}}, \"EndTime\": 1589566165.702097, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566165.126895}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:25 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1134.23087129 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:25 INFO 140645276194624] #progress_metric: host=algo-1, completed 56 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:25 INFO 140645276194624] #quality_metric: host=algo-1, epoch=226, train loss <loss>=2.43524865671\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:25 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:25 INFO 140645276194624] Epoch[227] Batch[0] avg_epoch_loss=2.362175\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:25 INFO 140645276194624] #quality_metric: host=algo-1, epoch=227, batch=0 train loss <loss>=2.36217522621\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:26 INFO 140645276194624] Epoch[227] Batch[5] avg_epoch_loss=2.412140\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:26 INFO 140645276194624] #quality_metric: host=algo-1, epoch=227, batch=5 train loss <loss>=2.41213965416\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:26 INFO 140645276194624] Epoch[227] Batch [5]#011Speed: 1801.59 samples/sec#011loss=2.412140\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:26 INFO 140645276194624] processed a total of 635 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 574.3429660797119, \"sum\": 574.3429660797119, \"min\": 574.3429660797119}}, \"EndTime\": 1589566166.276935, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566165.702174}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:26 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1105.38587069 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:26 INFO 140645276194624] #progress_metric: host=algo-1, completed 57 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:26 INFO 140645276194624] #quality_metric: host=algo-1, epoch=227, train loss <loss>=2.44487164021\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:26 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:26 INFO 140645276194624] Epoch[228] Batch[0] avg_epoch_loss=2.404592\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:26 INFO 140645276194624] #quality_metric: host=algo-1, epoch=228, batch=0 train loss <loss>=2.40459179878\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:26 INFO 140645276194624] Epoch[228] Batch[5] avg_epoch_loss=2.420645\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:26 INFO 140645276194624] #quality_metric: host=algo-1, epoch=228, batch=5 train loss <loss>=2.42064495881\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:26 INFO 140645276194624] Epoch[228] Batch [5]#011Speed: 1880.23 samples/sec#011loss=2.420645\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:26 INFO 140645276194624] processed a total of 623 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 566.864013671875, \"sum\": 566.864013671875, \"min\": 566.864013671875}}, \"EndTime\": 1589566166.844335, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566166.277015}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:26 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1098.80256508 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:26 INFO 140645276194624] #progress_metric: host=algo-1, completed 57 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:26 INFO 140645276194624] #quality_metric: host=algo-1, epoch=228, train loss <loss>=2.403637743\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:26 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:27 INFO 140645276194624] Epoch[229] Batch[0] avg_epoch_loss=2.440272\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:27 INFO 140645276194624] #quality_metric: host=algo-1, epoch=229, batch=0 train loss <loss>=2.4402718544\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:27 INFO 140645276194624] Epoch[229] Batch[5] avg_epoch_loss=2.433920\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:27 INFO 140645276194624] #quality_metric: host=algo-1, epoch=229, batch=5 train loss <loss>=2.43392038345\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:27 INFO 140645276194624] Epoch[229] Batch [5]#011Speed: 1990.83 samples/sec#011loss=2.433920\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:27 INFO 140645276194624] processed a total of 633 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 534.1939926147461, \"sum\": 534.1939926147461, \"min\": 534.1939926147461}}, \"EndTime\": 1589566167.37906, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566166.844415}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:27 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1184.65453393 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:27 INFO 140645276194624] #progress_metric: host=algo-1, completed 57 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:27 INFO 140645276194624] #quality_metric: host=algo-1, epoch=229, train loss <loss>=2.43728055954\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:27 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:27 INFO 140645276194624] Epoch[230] Batch[0] avg_epoch_loss=2.472577\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:27 INFO 140645276194624] #quality_metric: host=algo-1, epoch=230, batch=0 train loss <loss>=2.47257709503\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:27 INFO 140645276194624] Epoch[230] Batch[5] avg_epoch_loss=2.465206\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:27 INFO 140645276194624] #quality_metric: host=algo-1, epoch=230, batch=5 train loss <loss>=2.46520606677\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:27 INFO 140645276194624] Epoch[230] Batch [5]#011Speed: 1963.52 samples/sec#011loss=2.465206\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:27 INFO 140645276194624] Epoch[230] Batch[10] avg_epoch_loss=2.467621\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:27 INFO 140645276194624] #quality_metric: host=algo-1, epoch=230, batch=10 train loss <loss>=2.47051787376\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:27 INFO 140645276194624] Epoch[230] Batch [10]#011Speed: 1974.26 samples/sec#011loss=2.470518\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:27 INFO 140645276194624] processed a total of 648 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 609.483003616333, \"sum\": 609.483003616333, \"min\": 609.483003616333}}, \"EndTime\": 1589566167.989098, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566167.37916}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:27 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1063.0040656 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:27 INFO 140645276194624] #progress_metric: host=algo-1, completed 57 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:27 INFO 140645276194624] #quality_metric: host=algo-1, epoch=230, train loss <loss>=2.46762052449\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:27 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:28 INFO 140645276194624] Epoch[231] Batch[0] avg_epoch_loss=2.430603\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:28 INFO 140645276194624] #quality_metric: host=algo-1, epoch=231, batch=0 train loss <loss>=2.43060326576\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:28 INFO 140645276194624] Epoch[231] Batch[5] avg_epoch_loss=2.449888\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:28 INFO 140645276194624] #quality_metric: host=algo-1, epoch=231, batch=5 train loss <loss>=2.44988838832\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:28 INFO 140645276194624] Epoch[231] Batch [5]#011Speed: 1754.18 samples/sec#011loss=2.449888\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:28 INFO 140645276194624] processed a total of 638 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 532.9649448394775, \"sum\": 532.9649448394775, \"min\": 532.9649448394775}}, \"EndTime\": 1589566168.52261, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566167.989176}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:28 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1196.81397982 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:28 INFO 140645276194624] #progress_metric: host=algo-1, completed 58 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:28 INFO 140645276194624] #quality_metric: host=algo-1, epoch=231, train loss <loss>=2.43953917027\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:28 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:28 INFO 140645276194624] Epoch[232] Batch[0] avg_epoch_loss=2.406282\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:28 INFO 140645276194624] #quality_metric: host=algo-1, epoch=232, batch=0 train loss <loss>=2.40628194809\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:28 INFO 140645276194624] Epoch[232] Batch[5] avg_epoch_loss=2.417674\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:28 INFO 140645276194624] #quality_metric: host=algo-1, epoch=232, batch=5 train loss <loss>=2.41767410437\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:28 INFO 140645276194624] Epoch[232] Batch [5]#011Speed: 1974.35 samples/sec#011loss=2.417674\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:29 INFO 140645276194624] Epoch[232] Batch[10] avg_epoch_loss=2.416756\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:29 INFO 140645276194624] #quality_metric: host=algo-1, epoch=232, batch=10 train loss <loss>=2.41565327644\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:29 INFO 140645276194624] Epoch[232] Batch [10]#011Speed: 1873.15 samples/sec#011loss=2.415653\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:29 INFO 140645276194624] processed a total of 642 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 570.551872253418, \"sum\": 570.551872253418, \"min\": 570.551872253418}}, \"EndTime\": 1589566169.093727, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566168.52269}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:29 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1124.9753167 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:29 INFO 140645276194624] #progress_metric: host=algo-1, completed 58 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:29 INFO 140645276194624] #quality_metric: host=algo-1, epoch=232, train loss <loss>=2.41675554622\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:29 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:29 INFO 140645276194624] Epoch[233] Batch[0] avg_epoch_loss=2.444592\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:29 INFO 140645276194624] #quality_metric: host=algo-1, epoch=233, batch=0 train loss <loss>=2.44459176064\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:29 INFO 140645276194624] Epoch[233] Batch[5] avg_epoch_loss=2.391287\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:29 INFO 140645276194624] #quality_metric: host=algo-1, epoch=233, batch=5 train loss <loss>=2.39128684998\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:29 INFO 140645276194624] Epoch[233] Batch [5]#011Speed: 1872.11 samples/sec#011loss=2.391287\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:29 INFO 140645276194624] Epoch[233] Batch[10] avg_epoch_loss=2.501778\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:29 INFO 140645276194624] #quality_metric: host=algo-1, epoch=233, batch=10 train loss <loss>=2.63436703682\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:29 INFO 140645276194624] Epoch[233] Batch [10]#011Speed: 1720.14 samples/sec#011loss=2.634367\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:29 INFO 140645276194624] processed a total of 655 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 610.2488040924072, \"sum\": 610.2488040924072, \"min\": 610.2488040924072}}, \"EndTime\": 1589566169.704449, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566169.0938}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:29 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1073.14235849 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:29 INFO 140645276194624] #progress_metric: host=algo-1, completed 58 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:29 INFO 140645276194624] #quality_metric: host=algo-1, epoch=233, train loss <loss>=2.501777844\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:29 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:29 INFO 140645276194624] Epoch[234] Batch[0] avg_epoch_loss=2.973456\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:29 INFO 140645276194624] #quality_metric: host=algo-1, epoch=234, batch=0 train loss <loss>=2.97345614433\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:30 INFO 140645276194624] Epoch[234] Batch[5] avg_epoch_loss=2.699147\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:30 INFO 140645276194624] #quality_metric: host=algo-1, epoch=234, batch=5 train loss <loss>=2.69914666812\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:30 INFO 140645276194624] Epoch[234] Batch [5]#011Speed: 1875.42 samples/sec#011loss=2.699147\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:30 INFO 140645276194624] processed a total of 596 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 515.1100158691406, \"sum\": 515.1100158691406, \"min\": 515.1100158691406}}, \"EndTime\": 1589566170.220107, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566169.70452}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:30 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1156.79879758 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:30 INFO 140645276194624] #progress_metric: host=algo-1, completed 58 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:30 INFO 140645276194624] #quality_metric: host=algo-1, epoch=234, train loss <loss>=2.61256508827\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:30 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:30 INFO 140645276194624] Epoch[235] Batch[0] avg_epoch_loss=2.447967\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:30 INFO 140645276194624] #quality_metric: host=algo-1, epoch=235, batch=0 train loss <loss>=2.44796705246\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:30 INFO 140645276194624] Epoch[235] Batch[5] avg_epoch_loss=2.441280\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:30 INFO 140645276194624] #quality_metric: host=algo-1, epoch=235, batch=5 train loss <loss>=2.44128040473\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:30 INFO 140645276194624] Epoch[235] Batch [5]#011Speed: 1886.74 samples/sec#011loss=2.441280\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:30 INFO 140645276194624] Epoch[235] Batch[10] avg_epoch_loss=2.404705\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:30 INFO 140645276194624] #quality_metric: host=algo-1, epoch=235, batch=10 train loss <loss>=2.36081442833\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:30 INFO 140645276194624] Epoch[235] Batch [10]#011Speed: 1873.06 samples/sec#011loss=2.360814\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:30 INFO 140645276194624] processed a total of 645 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 560.1880550384521, \"sum\": 560.1880550384521, \"min\": 560.1880550384521}}, \"EndTime\": 1589566170.78085, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566170.220179}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:30 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1151.16241901 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:30 INFO 140645276194624] #progress_metric: host=algo-1, completed 59 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:30 INFO 140645276194624] #quality_metric: host=algo-1, epoch=235, train loss <loss>=2.40470496091\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:30 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:31 INFO 140645276194624] Epoch[236] Batch[0] avg_epoch_loss=2.502585\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:31 INFO 140645276194624] #quality_metric: host=algo-1, epoch=236, batch=0 train loss <loss>=2.50258493423\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:31 INFO 140645276194624] Epoch[236] Batch[5] avg_epoch_loss=2.466128\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:31 INFO 140645276194624] #quality_metric: host=algo-1, epoch=236, batch=5 train loss <loss>=2.4661279122\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:31 INFO 140645276194624] Epoch[236] Batch [5]#011Speed: 1950.04 samples/sec#011loss=2.466128\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:31 INFO 140645276194624] Epoch[236] Batch[10] avg_epoch_loss=2.411584\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:31 INFO 140645276194624] #quality_metric: host=algo-1, epoch=236, batch=10 train loss <loss>=2.34613175392\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:31 INFO 140645276194624] Epoch[236] Batch [10]#011Speed: 1716.10 samples/sec#011loss=2.346132\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:31 INFO 140645276194624] processed a total of 661 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 601.999044418335, \"sum\": 601.999044418335, \"min\": 601.999044418335}}, \"EndTime\": 1589566171.38334, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566170.780929}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:31 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1097.80447574 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:31 INFO 140645276194624] #progress_metric: host=algo-1, completed 59 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:31 INFO 140645276194624] #quality_metric: host=algo-1, epoch=236, train loss <loss>=2.41158420389\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:31 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:31 INFO 140645276194624] Epoch[237] Batch[0] avg_epoch_loss=2.568098\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:31 INFO 140645276194624] #quality_metric: host=algo-1, epoch=237, batch=0 train loss <loss>=2.5680975914\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:31 INFO 140645276194624] Epoch[237] Batch[5] avg_epoch_loss=2.469777\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:31 INFO 140645276194624] #quality_metric: host=algo-1, epoch=237, batch=5 train loss <loss>=2.46977710724\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:31 INFO 140645276194624] Epoch[237] Batch [5]#011Speed: 1948.95 samples/sec#011loss=2.469777\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:31 INFO 140645276194624] Epoch[237] Batch[10] avg_epoch_loss=2.410849\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:31 INFO 140645276194624] #quality_metric: host=algo-1, epoch=237, batch=10 train loss <loss>=2.34013504982\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:31 INFO 140645276194624] Epoch[237] Batch [10]#011Speed: 1960.08 samples/sec#011loss=2.340135\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:31 INFO 140645276194624] processed a total of 646 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 568.9449310302734, \"sum\": 568.9449310302734, \"min\": 568.9449310302734}}, \"EndTime\": 1589566171.952791, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566171.383416}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:31 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1135.21143557 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:31 INFO 140645276194624] #progress_metric: host=algo-1, completed 59 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:31 INFO 140645276194624] #quality_metric: host=algo-1, epoch=237, train loss <loss>=2.41084889932\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:31 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:32 INFO 140645276194624] Epoch[238] Batch[0] avg_epoch_loss=2.385519\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:32 INFO 140645276194624] #quality_metric: host=algo-1, epoch=238, batch=0 train loss <loss>=2.38551926613\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:32 INFO 140645276194624] Epoch[238] Batch[5] avg_epoch_loss=2.402498\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:32 INFO 140645276194624] #quality_metric: host=algo-1, epoch=238, batch=5 train loss <loss>=2.40249808629\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:32 INFO 140645276194624] Epoch[238] Batch [5]#011Speed: 1971.20 samples/sec#011loss=2.402498\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:32 INFO 140645276194624] processed a total of 622 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 587.6951217651367, \"sum\": 587.6951217651367, \"min\": 587.6951217651367}}, \"EndTime\": 1589566172.541, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566171.952866}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:32 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1058.16154863 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:32 INFO 140645276194624] #progress_metric: host=algo-1, completed 59 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:32 INFO 140645276194624] #quality_metric: host=algo-1, epoch=238, train loss <loss>=2.40498373508\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:32 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:32 INFO 140645276194624] Epoch[239] Batch[0] avg_epoch_loss=2.462871\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:32 INFO 140645276194624] #quality_metric: host=algo-1, epoch=239, batch=0 train loss <loss>=2.46287059784\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:32 INFO 140645276194624] Epoch[239] Batch[5] avg_epoch_loss=2.371198\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:32 INFO 140645276194624] #quality_metric: host=algo-1, epoch=239, batch=5 train loss <loss>=2.37119754155\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:32 INFO 140645276194624] Epoch[239] Batch [5]#011Speed: 1771.22 samples/sec#011loss=2.371198\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:33 INFO 140645276194624] Epoch[239] Batch[10] avg_epoch_loss=2.366674\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:33 INFO 140645276194624] #quality_metric: host=algo-1, epoch=239, batch=10 train loss <loss>=2.36124649048\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:33 INFO 140645276194624] Epoch[239] Batch [10]#011Speed: 1573.05 samples/sec#011loss=2.361246\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:33 INFO 140645276194624] processed a total of 662 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 627.8607845306396, \"sum\": 627.8607845306396, \"min\": 627.8607845306396}}, \"EndTime\": 1589566173.169398, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566172.541081}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:33 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1054.18691783 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:33 INFO 140645276194624] #progress_metric: host=algo-1, completed 60 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:33 INFO 140645276194624] #quality_metric: host=algo-1, epoch=239, train loss <loss>=2.36667433652\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:33 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:33 INFO 140645276194624] Epoch[240] Batch[0] avg_epoch_loss=2.372803\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:33 INFO 140645276194624] #quality_metric: host=algo-1, epoch=240, batch=0 train loss <loss>=2.37280297279\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:33 INFO 140645276194624] Epoch[240] Batch[5] avg_epoch_loss=2.346404\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:33 INFO 140645276194624] #quality_metric: host=algo-1, epoch=240, batch=5 train loss <loss>=2.34640371799\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:33 INFO 140645276194624] Epoch[240] Batch [5]#011Speed: 1988.30 samples/sec#011loss=2.346404\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:33 INFO 140645276194624] processed a total of 615 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 517.2100067138672, \"sum\": 517.2100067138672, \"min\": 517.2100067138672}}, \"EndTime\": 1589566173.687124, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566173.169476}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:33 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1188.74607534 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:33 INFO 140645276194624] #progress_metric: host=algo-1, completed 60 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:33 INFO 140645276194624] #quality_metric: host=algo-1, epoch=240, train loss <loss>=2.32917621136\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:33 INFO 140645276194624] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:33 INFO 140645276194624] Saved checkpoint to \"/opt/ml/model/state_55a5980e-b258-493d-9004-4e6ebed4396a-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 13.532876968383789, \"sum\": 13.532876968383789, \"min\": 13.532876968383789}}, \"EndTime\": 1589566173.70127, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566173.687227}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:33 INFO 140645276194624] Epoch[241] Batch[0] avg_epoch_loss=2.391033\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:33 INFO 140645276194624] #quality_metric: host=algo-1, epoch=241, batch=0 train loss <loss>=2.39103269577\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:34 INFO 140645276194624] Epoch[241] Batch[5] avg_epoch_loss=2.366957\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:34 INFO 140645276194624] #quality_metric: host=algo-1, epoch=241, batch=5 train loss <loss>=2.36695675055\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:34 INFO 140645276194624] Epoch[241] Batch [5]#011Speed: 2003.06 samples/sec#011loss=2.366957\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:34 INFO 140645276194624] Epoch[241] Batch[10] avg_epoch_loss=2.377866\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:34 INFO 140645276194624] #quality_metric: host=algo-1, epoch=241, batch=10 train loss <loss>=2.39095625877\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:34 INFO 140645276194624] Epoch[241] Batch [10]#011Speed: 1938.85 samples/sec#011loss=2.390956\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:34 INFO 140645276194624] processed a total of 649 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 543.9839363098145, \"sum\": 543.9839363098145, \"min\": 543.9839363098145}}, \"EndTime\": 1589566174.245393, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566173.70134}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:34 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1192.79795418 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:34 INFO 140645276194624] #progress_metric: host=algo-1, completed 60 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:34 INFO 140645276194624] #quality_metric: host=algo-1, epoch=241, train loss <loss>=2.37786561793\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:34 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:34 INFO 140645276194624] Epoch[242] Batch[0] avg_epoch_loss=2.320121\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:34 INFO 140645276194624] #quality_metric: host=algo-1, epoch=242, batch=0 train loss <loss>=2.32012081146\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:34 INFO 140645276194624] Epoch[242] Batch[5] avg_epoch_loss=2.350357\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:34 INFO 140645276194624] #quality_metric: host=algo-1, epoch=242, batch=5 train loss <loss>=2.35035661856\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:34 INFO 140645276194624] Epoch[242] Batch [5]#011Speed: 1987.00 samples/sec#011loss=2.350357\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:34 INFO 140645276194624] processed a total of 606 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 541.316032409668, \"sum\": 541.316032409668, \"min\": 541.316032409668}}, \"EndTime\": 1589566174.787216, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566174.245469}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:34 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1119.25235344 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:34 INFO 140645276194624] #progress_metric: host=algo-1, completed 60 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:34 INFO 140645276194624] #quality_metric: host=algo-1, epoch=242, train loss <loss>=2.3743149519\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:34 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:35 INFO 140645276194624] Epoch[243] Batch[0] avg_epoch_loss=2.417822\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:35 INFO 140645276194624] #quality_metric: host=algo-1, epoch=243, batch=0 train loss <loss>=2.41782164574\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:35 INFO 140645276194624] Epoch[243] Batch[5] avg_epoch_loss=2.430697\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:35 INFO 140645276194624] #quality_metric: host=algo-1, epoch=243, batch=5 train loss <loss>=2.43069676558\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:35 INFO 140645276194624] Epoch[243] Batch [5]#011Speed: 1668.40 samples/sec#011loss=2.430697\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:35 INFO 140645276194624] Epoch[243] Batch[10] avg_epoch_loss=2.464373\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:35 INFO 140645276194624] #quality_metric: host=algo-1, epoch=243, batch=10 train loss <loss>=2.50478391647\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:35 INFO 140645276194624] Epoch[243] Batch [10]#011Speed: 1801.29 samples/sec#011loss=2.504784\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:35 INFO 140645276194624] processed a total of 662 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 627.2540092468262, \"sum\": 627.2540092468262, \"min\": 627.2540092468262}}, \"EndTime\": 1589566175.415007, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566174.787298}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:35 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1055.20209533 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:35 INFO 140645276194624] #progress_metric: host=algo-1, completed 61 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:35 INFO 140645276194624] #quality_metric: host=algo-1, epoch=243, train loss <loss>=2.46437274326\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:35 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:35 INFO 140645276194624] Epoch[244] Batch[0] avg_epoch_loss=2.446067\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:35 INFO 140645276194624] #quality_metric: host=algo-1, epoch=244, batch=0 train loss <loss>=2.44606661797\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:35 INFO 140645276194624] Epoch[244] Batch[5] avg_epoch_loss=2.429361\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:35 INFO 140645276194624] #quality_metric: host=algo-1, epoch=244, batch=5 train loss <loss>=2.42936066786\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:35 INFO 140645276194624] Epoch[244] Batch [5]#011Speed: 1900.33 samples/sec#011loss=2.429361\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:35 INFO 140645276194624] processed a total of 605 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 566.8940544128418, \"sum\": 566.8940544128418, \"min\": 566.8940544128418}}, \"EndTime\": 1589566175.98244, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566175.415085}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:35 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1066.99668366 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:35 INFO 140645276194624] #progress_metric: host=algo-1, completed 61 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:35 INFO 140645276194624] #quality_metric: host=algo-1, epoch=244, train loss <loss>=2.44216430187\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:35 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:36 INFO 140645276194624] Epoch[245] Batch[0] avg_epoch_loss=2.638248\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:36 INFO 140645276194624] #quality_metric: host=algo-1, epoch=245, batch=0 train loss <loss>=2.63824820518\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:36 INFO 140645276194624] Epoch[245] Batch[5] avg_epoch_loss=2.510147\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:36 INFO 140645276194624] #quality_metric: host=algo-1, epoch=245, batch=5 train loss <loss>=2.51014685631\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:36 INFO 140645276194624] Epoch[245] Batch [5]#011Speed: 1945.32 samples/sec#011loss=2.510147\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:36 INFO 140645276194624] Epoch[245] Batch[10] avg_epoch_loss=2.465456\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:36 INFO 140645276194624] #quality_metric: host=algo-1, epoch=245, batch=10 train loss <loss>=2.4118268013\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:36 INFO 140645276194624] Epoch[245] Batch [10]#011Speed: 1911.44 samples/sec#011loss=2.411827\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:36 INFO 140645276194624] processed a total of 641 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 558.2878589630127, \"sum\": 558.2878589630127, \"min\": 558.2878589630127}}, \"EndTime\": 1589566176.541265, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566175.982521}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:36 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1147.95760939 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:36 INFO 140645276194624] #progress_metric: host=algo-1, completed 61 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:36 INFO 140645276194624] #quality_metric: host=algo-1, epoch=245, train loss <loss>=2.46545592221\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:36 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:36 INFO 140645276194624] Epoch[246] Batch[0] avg_epoch_loss=2.414588\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:36 INFO 140645276194624] #quality_metric: host=algo-1, epoch=246, batch=0 train loss <loss>=2.41458797455\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:36 INFO 140645276194624] Epoch[246] Batch[5] avg_epoch_loss=2.446040\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:36 INFO 140645276194624] #quality_metric: host=algo-1, epoch=246, batch=5 train loss <loss>=2.44604047139\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:36 INFO 140645276194624] Epoch[246] Batch [5]#011Speed: 1997.15 samples/sec#011loss=2.446040\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:37 INFO 140645276194624] processed a total of 624 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 507.7950954437256, \"sum\": 507.7950954437256, \"min\": 507.7950954437256}}, \"EndTime\": 1589566177.04957, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566176.541323}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:37 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1228.55889347 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:37 INFO 140645276194624] #progress_metric: host=algo-1, completed 61 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:37 INFO 140645276194624] #quality_metric: host=algo-1, epoch=246, train loss <loss>=2.42176589966\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:37 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:37 INFO 140645276194624] Epoch[247] Batch[0] avg_epoch_loss=2.588462\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:37 INFO 140645276194624] #quality_metric: host=algo-1, epoch=247, batch=0 train loss <loss>=2.58846235275\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:37 INFO 140645276194624] Epoch[247] Batch[5] avg_epoch_loss=2.482645\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:37 INFO 140645276194624] #quality_metric: host=algo-1, epoch=247, batch=5 train loss <loss>=2.48264491558\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:37 INFO 140645276194624] Epoch[247] Batch [5]#011Speed: 1960.40 samples/sec#011loss=2.482645\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:37 INFO 140645276194624] Epoch[247] Batch[10] avg_epoch_loss=2.540744\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:37 INFO 140645276194624] #quality_metric: host=algo-1, epoch=247, batch=10 train loss <loss>=2.61046237946\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:37 INFO 140645276194624] Epoch[247] Batch [10]#011Speed: 1958.37 samples/sec#011loss=2.610462\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:37 INFO 140645276194624] processed a total of 650 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 563.0550384521484, \"sum\": 563.0550384521484, \"min\": 563.0550384521484}}, \"EndTime\": 1589566177.613144, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566177.049651}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:37 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1154.19114892 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:37 INFO 140645276194624] #progress_metric: host=algo-1, completed 62 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:37 INFO 140645276194624] #quality_metric: host=algo-1, epoch=247, train loss <loss>=2.5407437628\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:37 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:37 INFO 140645276194624] Epoch[248] Batch[0] avg_epoch_loss=2.372507\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:37 INFO 140645276194624] #quality_metric: host=algo-1, epoch=248, batch=0 train loss <loss>=2.37250685692\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:38 INFO 140645276194624] Epoch[248] Batch[5] avg_epoch_loss=2.391668\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:38 INFO 140645276194624] #quality_metric: host=algo-1, epoch=248, batch=5 train loss <loss>=2.39166816076\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:38 INFO 140645276194624] Epoch[248] Batch [5]#011Speed: 1995.05 samples/sec#011loss=2.391668\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:38 INFO 140645276194624] Epoch[248] Batch[10] avg_epoch_loss=2.439124\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:38 INFO 140645276194624] #quality_metric: host=algo-1, epoch=248, batch=10 train loss <loss>=2.49607048035\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:38 INFO 140645276194624] Epoch[248] Batch [10]#011Speed: 1560.28 samples/sec#011loss=2.496070\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:38 INFO 140645276194624] processed a total of 657 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 615.9141063690186, \"sum\": 615.9141063690186, \"min\": 615.9141063690186}}, \"EndTime\": 1589566178.229541, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566177.613219}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:38 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1066.53419565 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:38 INFO 140645276194624] #progress_metric: host=algo-1, completed 62 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:38 INFO 140645276194624] #quality_metric: host=algo-1, epoch=248, train loss <loss>=2.43912376057\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:38 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:38 INFO 140645276194624] Epoch[249] Batch[0] avg_epoch_loss=2.800717\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:38 INFO 140645276194624] #quality_metric: host=algo-1, epoch=249, batch=0 train loss <loss>=2.80071687698\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:38 INFO 140645276194624] Epoch[249] Batch[5] avg_epoch_loss=2.607839\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:38 INFO 140645276194624] #quality_metric: host=algo-1, epoch=249, batch=5 train loss <loss>=2.6078394254\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:38 INFO 140645276194624] Epoch[249] Batch [5]#011Speed: 1945.50 samples/sec#011loss=2.607839\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:38 INFO 140645276194624] Epoch[249] Batch[10] avg_epoch_loss=2.539688\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:38 INFO 140645276194624] #quality_metric: host=algo-1, epoch=249, batch=10 train loss <loss>=2.45790572166\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:38 INFO 140645276194624] Epoch[249] Batch [10]#011Speed: 1943.42 samples/sec#011loss=2.457906\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:38 INFO 140645276194624] processed a total of 649 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 566.1041736602783, \"sum\": 566.1041736602783, \"min\": 566.1041736602783}}, \"EndTime\": 1589566178.796182, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566178.22961}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:38 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1146.20763509 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:38 INFO 140645276194624] #progress_metric: host=algo-1, completed 62 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:38 INFO 140645276194624] #quality_metric: host=algo-1, epoch=249, train loss <loss>=2.53968774189\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:38 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:39 INFO 140645276194624] Epoch[250] Batch[0] avg_epoch_loss=2.417272\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:39 INFO 140645276194624] #quality_metric: host=algo-1, epoch=250, batch=0 train loss <loss>=2.41727232933\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:39 INFO 140645276194624] Epoch[250] Batch[5] avg_epoch_loss=2.425487\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:39 INFO 140645276194624] #quality_metric: host=algo-1, epoch=250, batch=5 train loss <loss>=2.42548676332\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:39 INFO 140645276194624] Epoch[250] Batch [5]#011Speed: 1833.84 samples/sec#011loss=2.425487\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:39 INFO 140645276194624] processed a total of 591 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 590.1000499725342, \"sum\": 590.1000499725342, \"min\": 590.1000499725342}}, \"EndTime\": 1589566179.386765, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566178.796257}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:39 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1001.34868541 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:39 INFO 140645276194624] #progress_metric: host=algo-1, completed 62 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:39 INFO 140645276194624] #quality_metric: host=algo-1, epoch=250, train loss <loss>=2.52649815083\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:39 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:39 INFO 140645276194624] Epoch[251] Batch[0] avg_epoch_loss=2.940126\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:39 INFO 140645276194624] #quality_metric: host=algo-1, epoch=251, batch=0 train loss <loss>=2.94012618065\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:39 INFO 140645276194624] Epoch[251] Batch[5] avg_epoch_loss=2.640975\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:39 INFO 140645276194624] #quality_metric: host=algo-1, epoch=251, batch=5 train loss <loss>=2.64097476006\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:39 INFO 140645276194624] Epoch[251] Batch [5]#011Speed: 1856.32 samples/sec#011loss=2.640975\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:39 INFO 140645276194624] processed a total of 618 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 538.3341312408447, \"sum\": 538.3341312408447, \"min\": 538.3341312408447}}, \"EndTime\": 1589566179.925674, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566179.386837}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:39 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1147.7942713 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:39 INFO 140645276194624] #progress_metric: host=algo-1, completed 63 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:39 INFO 140645276194624] #quality_metric: host=algo-1, epoch=251, train loss <loss>=2.62952775955\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:39 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:40 INFO 140645276194624] Epoch[252] Batch[0] avg_epoch_loss=2.391204\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:40 INFO 140645276194624] #quality_metric: host=algo-1, epoch=252, batch=0 train loss <loss>=2.39120411873\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:40 INFO 140645276194624] Epoch[252] Batch[5] avg_epoch_loss=2.457661\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:40 INFO 140645276194624] #quality_metric: host=algo-1, epoch=252, batch=5 train loss <loss>=2.45766059558\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:40 INFO 140645276194624] Epoch[252] Batch [5]#011Speed: 1980.99 samples/sec#011loss=2.457661\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:40 INFO 140645276194624] Epoch[252] Batch[10] avg_epoch_loss=2.438667\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:40 INFO 140645276194624] #quality_metric: host=algo-1, epoch=252, batch=10 train loss <loss>=2.41587362289\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:40 INFO 140645276194624] Epoch[252] Batch [10]#011Speed: 1900.42 samples/sec#011loss=2.415874\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:40 INFO 140645276194624] processed a total of 648 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 570.4879760742188, \"sum\": 570.4879760742188, \"min\": 570.4879760742188}}, \"EndTime\": 1589566180.49674, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566179.92573}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:40 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1135.65089307 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:40 INFO 140645276194624] #progress_metric: host=algo-1, completed 63 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:40 INFO 140645276194624] #quality_metric: host=algo-1, epoch=252, train loss <loss>=2.43866651708\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:40 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:40 INFO 140645276194624] Epoch[253] Batch[0] avg_epoch_loss=2.484397\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:40 INFO 140645276194624] #quality_metric: host=algo-1, epoch=253, batch=0 train loss <loss>=2.48439669609\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:40 INFO 140645276194624] Epoch[253] Batch[5] avg_epoch_loss=2.431474\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:40 INFO 140645276194624] #quality_metric: host=algo-1, epoch=253, batch=5 train loss <loss>=2.43147424857\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:40 INFO 140645276194624] Epoch[253] Batch [5]#011Speed: 1974.34 samples/sec#011loss=2.431474\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:41 INFO 140645276194624] Epoch[253] Batch[10] avg_epoch_loss=2.499308\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:41 INFO 140645276194624] #quality_metric: host=algo-1, epoch=253, batch=10 train loss <loss>=2.58070745468\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:41 INFO 140645276194624] Epoch[253] Batch [10]#011Speed: 1673.72 samples/sec#011loss=2.580707\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:41 INFO 140645276194624] processed a total of 642 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 586.6599082946777, \"sum\": 586.6599082946777, \"min\": 586.6599082946777}}, \"EndTime\": 1589566181.083934, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566180.496811}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:41 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1094.12580356 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:41 INFO 140645276194624] #progress_metric: host=algo-1, completed 63 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:41 INFO 140645276194624] #quality_metric: host=algo-1, epoch=253, train loss <loss>=2.49930752407\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:41 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:41 INFO 140645276194624] Epoch[254] Batch[0] avg_epoch_loss=2.551751\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:41 INFO 140645276194624] #quality_metric: host=algo-1, epoch=254, batch=0 train loss <loss>=2.55175089836\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:41 INFO 140645276194624] Epoch[254] Batch[5] avg_epoch_loss=2.490074\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:41 INFO 140645276194624] #quality_metric: host=algo-1, epoch=254, batch=5 train loss <loss>=2.49007407824\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:41 INFO 140645276194624] Epoch[254] Batch [5]#011Speed: 1833.76 samples/sec#011loss=2.490074\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:41 INFO 140645276194624] Epoch[254] Batch[10] avg_epoch_loss=2.461017\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:41 INFO 140645276194624] #quality_metric: host=algo-1, epoch=254, batch=10 train loss <loss>=2.42614912987\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:41 INFO 140645276194624] Epoch[254] Batch [10]#011Speed: 1496.09 samples/sec#011loss=2.426149\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:41 INFO 140645276194624] processed a total of 675 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 644.2868709564209, \"sum\": 644.2868709564209, \"min\": 644.2868709564209}}, \"EndTime\": 1589566181.728712, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566181.084009}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:41 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1047.49901583 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:41 INFO 140645276194624] #progress_metric: host=algo-1, completed 63 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:41 INFO 140645276194624] #quality_metric: host=algo-1, epoch=254, train loss <loss>=2.46101728353\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:41 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:41 INFO 140645276194624] Epoch[255] Batch[0] avg_epoch_loss=2.363703\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:41 INFO 140645276194624] #quality_metric: host=algo-1, epoch=255, batch=0 train loss <loss>=2.36370301247\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:42 INFO 140645276194624] Epoch[255] Batch[5] avg_epoch_loss=2.384287\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:42 INFO 140645276194624] #quality_metric: host=algo-1, epoch=255, batch=5 train loss <loss>=2.38428739707\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:42 INFO 140645276194624] Epoch[255] Batch [5]#011Speed: 1951.43 samples/sec#011loss=2.384287\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:42 INFO 140645276194624] Epoch[255] Batch[10] avg_epoch_loss=2.365858\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:42 INFO 140645276194624] #quality_metric: host=algo-1, epoch=255, batch=10 train loss <loss>=2.34374251366\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:42 INFO 140645276194624] Epoch[255] Batch [10]#011Speed: 1944.89 samples/sec#011loss=2.343743\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:42 INFO 140645276194624] processed a total of 650 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 569.0820217132568, \"sum\": 569.0820217132568, \"min\": 569.0820217132568}}, \"EndTime\": 1589566182.298311, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566181.728785}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:42 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1141.96980435 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:42 INFO 140645276194624] #progress_metric: host=algo-1, completed 64 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:42 INFO 140645276194624] #quality_metric: host=algo-1, epoch=255, train loss <loss>=2.36585790461\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:42 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:42 INFO 140645276194624] Epoch[256] Batch[0] avg_epoch_loss=2.403975\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:42 INFO 140645276194624] #quality_metric: host=algo-1, epoch=256, batch=0 train loss <loss>=2.40397548676\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:42 INFO 140645276194624] Epoch[256] Batch[5] avg_epoch_loss=2.374379\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:42 INFO 140645276194624] #quality_metric: host=algo-1, epoch=256, batch=5 train loss <loss>=2.37437887987\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:42 INFO 140645276194624] Epoch[256] Batch [5]#011Speed: 1994.02 samples/sec#011loss=2.374379\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:42 INFO 140645276194624] Epoch[256] Batch[10] avg_epoch_loss=2.379390\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:42 INFO 140645276194624] #quality_metric: host=algo-1, epoch=256, batch=10 train loss <loss>=2.3854033947\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:42 INFO 140645276194624] Epoch[256] Batch [10]#011Speed: 1918.86 samples/sec#011loss=2.385403\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:42 INFO 140645276194624] processed a total of 653 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 571.9339847564697, \"sum\": 571.9339847564697, \"min\": 571.9339847564697}}, \"EndTime\": 1589566182.870734, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566182.298387}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:42 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1141.50842061 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:42 INFO 140645276194624] #progress_metric: host=algo-1, completed 64 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:42 INFO 140645276194624] #quality_metric: host=algo-1, epoch=256, train loss <loss>=2.37939002297\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:42 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:43 INFO 140645276194624] Epoch[257] Batch[0] avg_epoch_loss=2.668015\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:43 INFO 140645276194624] #quality_metric: host=algo-1, epoch=257, batch=0 train loss <loss>=2.66801476479\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:43 INFO 140645276194624] Epoch[257] Batch[5] avg_epoch_loss=2.498769\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:43 INFO 140645276194624] #quality_metric: host=algo-1, epoch=257, batch=5 train loss <loss>=2.49876928329\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:43 INFO 140645276194624] Epoch[257] Batch [5]#011Speed: 1888.91 samples/sec#011loss=2.498769\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:43 INFO 140645276194624] Epoch[257] Batch[10] avg_epoch_loss=2.476424\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:43 INFO 140645276194624] #quality_metric: host=algo-1, epoch=257, batch=10 train loss <loss>=2.4496096611\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:43 INFO 140645276194624] Epoch[257] Batch [10]#011Speed: 1986.07 samples/sec#011loss=2.449610\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:43 INFO 140645276194624] processed a total of 652 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 554.6970367431641, \"sum\": 554.6970367431641, \"min\": 554.6970367431641}}, \"EndTime\": 1589566183.42602, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566182.870813}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:43 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1175.17496775 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:43 INFO 140645276194624] #progress_metric: host=algo-1, completed 64 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:43 INFO 140645276194624] #quality_metric: host=algo-1, epoch=257, train loss <loss>=2.47642400048\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:43 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:43 INFO 140645276194624] Epoch[258] Batch[0] avg_epoch_loss=2.405208\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:43 INFO 140645276194624] #quality_metric: host=algo-1, epoch=258, batch=0 train loss <loss>=2.40520834923\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:43 INFO 140645276194624] Epoch[258] Batch[5] avg_epoch_loss=2.364494\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:43 INFO 140645276194624] #quality_metric: host=algo-1, epoch=258, batch=5 train loss <loss>=2.364493529\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:43 INFO 140645276194624] Epoch[258] Batch [5]#011Speed: 1832.17 samples/sec#011loss=2.364494\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:44 INFO 140645276194624] Epoch[258] Batch[10] avg_epoch_loss=2.334763\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:44 INFO 140645276194624] #quality_metric: host=algo-1, epoch=258, batch=10 train loss <loss>=2.29908618927\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:44 INFO 140645276194624] Epoch[258] Batch [10]#011Speed: 1826.29 samples/sec#011loss=2.299086\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:44 INFO 140645276194624] processed a total of 664 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 599.5159149169922, \"sum\": 599.5159149169922, \"min\": 599.5159149169922}}, \"EndTime\": 1589566184.026052, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566183.426097}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:44 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1107.3568004 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:44 INFO 140645276194624] #progress_metric: host=algo-1, completed 64 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:44 INFO 140645276194624] #quality_metric: host=algo-1, epoch=258, train loss <loss>=2.33476292003\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:44 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:44 INFO 140645276194624] Epoch[259] Batch[0] avg_epoch_loss=2.439840\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:44 INFO 140645276194624] #quality_metric: host=algo-1, epoch=259, batch=0 train loss <loss>=2.43983960152\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:44 INFO 140645276194624] Epoch[259] Batch[5] avg_epoch_loss=2.332455\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:44 INFO 140645276194624] #quality_metric: host=algo-1, epoch=259, batch=5 train loss <loss>=2.33245535692\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:44 INFO 140645276194624] Epoch[259] Batch [5]#011Speed: 1943.59 samples/sec#011loss=2.332455\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:44 INFO 140645276194624] processed a total of 625 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 569.4761276245117, \"sum\": 569.4761276245117, \"min\": 569.4761276245117}}, \"EndTime\": 1589566184.596037, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566184.026126}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:44 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1097.27113745 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:44 INFO 140645276194624] #progress_metric: host=algo-1, completed 65 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:44 INFO 140645276194624] #quality_metric: host=algo-1, epoch=259, train loss <loss>=2.34361732006\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:44 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:44 INFO 140645276194624] Epoch[260] Batch[0] avg_epoch_loss=2.410598\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:44 INFO 140645276194624] #quality_metric: host=algo-1, epoch=260, batch=0 train loss <loss>=2.41059827805\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:45 INFO 140645276194624] Epoch[260] Batch[5] avg_epoch_loss=2.389656\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:45 INFO 140645276194624] #quality_metric: host=algo-1, epoch=260, batch=5 train loss <loss>=2.38965594769\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:45 INFO 140645276194624] Epoch[260] Batch [5]#011Speed: 1856.39 samples/sec#011loss=2.389656\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:45 INFO 140645276194624] processed a total of 584 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 598.0391502380371, \"sum\": 598.0391502380371, \"min\": 598.0391502380371}}, \"EndTime\": 1589566185.194619, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566184.596118}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:45 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=976.340199742 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:45 INFO 140645276194624] #progress_metric: host=algo-1, completed 65 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:45 INFO 140645276194624] #quality_metric: host=algo-1, epoch=260, train loss <loss>=2.34646160603\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:45 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:45 INFO 140645276194624] Epoch[261] Batch[0] avg_epoch_loss=2.258256\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:45 INFO 140645276194624] #quality_metric: host=algo-1, epoch=261, batch=0 train loss <loss>=2.25825595856\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:45 INFO 140645276194624] Epoch[261] Batch[5] avg_epoch_loss=2.375726\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:45 INFO 140645276194624] #quality_metric: host=algo-1, epoch=261, batch=5 train loss <loss>=2.37572578589\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:45 INFO 140645276194624] Epoch[261] Batch [5]#011Speed: 1872.52 samples/sec#011loss=2.375726\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:45 INFO 140645276194624] Epoch[261] Batch[10] avg_epoch_loss=2.283297\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:45 INFO 140645276194624] #quality_metric: host=algo-1, epoch=261, batch=10 train loss <loss>=2.17238163948\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:45 INFO 140645276194624] Epoch[261] Batch [10]#011Speed: 1831.56 samples/sec#011loss=2.172382\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:45 INFO 140645276194624] processed a total of 651 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 598.6721515655518, \"sum\": 598.6721515655518, \"min\": 598.6721515655518}}, \"EndTime\": 1589566185.793819, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566185.194698}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:45 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1087.20864832 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:45 INFO 140645276194624] #progress_metric: host=algo-1, completed 65 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:45 INFO 140645276194624] #quality_metric: host=algo-1, epoch=261, train loss <loss>=2.28329662843\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:45 INFO 140645276194624] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:45 INFO 140645276194624] Saved checkpoint to \"/opt/ml/model/state_60ef8e4d-b048-485a-8d22-c7dc60aa1504-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 14.338970184326172, \"sum\": 14.338970184326172, \"min\": 14.338970184326172}}, \"EndTime\": 1589566185.808712, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566185.793893}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:46 INFO 140645276194624] Epoch[262] Batch[0] avg_epoch_loss=2.264442\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:46 INFO 140645276194624] #quality_metric: host=algo-1, epoch=262, batch=0 train loss <loss>=2.26444196701\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:46 INFO 140645276194624] Epoch[262] Batch[5] avg_epoch_loss=2.327255\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:46 INFO 140645276194624] #quality_metric: host=algo-1, epoch=262, batch=5 train loss <loss>=2.32725465298\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:46 INFO 140645276194624] Epoch[262] Batch [5]#011Speed: 1987.47 samples/sec#011loss=2.327255\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:46 INFO 140645276194624] Epoch[262] Batch[10] avg_epoch_loss=2.381482\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:46 INFO 140645276194624] #quality_metric: host=algo-1, epoch=262, batch=10 train loss <loss>=2.4465555191\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:46 INFO 140645276194624] Epoch[262] Batch [10]#011Speed: 1804.25 samples/sec#011loss=2.446556\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:46 INFO 140645276194624] processed a total of 642 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 567.0688152313232, \"sum\": 567.0688152313232, \"min\": 567.0688152313232}}, \"EndTime\": 1589566186.375908, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566185.808782}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:46 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1131.92785237 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:46 INFO 140645276194624] #progress_metric: host=algo-1, completed 65 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:46 INFO 140645276194624] #quality_metric: host=algo-1, epoch=262, train loss <loss>=2.3814823194\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:46 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:46 INFO 140645276194624] Epoch[263] Batch[0] avg_epoch_loss=2.430631\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:46 INFO 140645276194624] #quality_metric: host=algo-1, epoch=263, batch=0 train loss <loss>=2.4306306839\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:46 INFO 140645276194624] Epoch[263] Batch[5] avg_epoch_loss=2.392978\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:46 INFO 140645276194624] #quality_metric: host=algo-1, epoch=263, batch=5 train loss <loss>=2.39297775428\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:46 INFO 140645276194624] Epoch[263] Batch [5]#011Speed: 1807.02 samples/sec#011loss=2.392978\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:46 INFO 140645276194624] processed a total of 638 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 557.4448108673096, \"sum\": 557.4448108673096, \"min\": 557.4448108673096}}, \"EndTime\": 1589566186.93388, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566186.375976}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:46 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1144.28964067 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:46 INFO 140645276194624] #progress_metric: host=algo-1, completed 66 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:46 INFO 140645276194624] #quality_metric: host=algo-1, epoch=263, train loss <loss>=2.36393506527\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:46 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:47 INFO 140645276194624] Epoch[264] Batch[0] avg_epoch_loss=2.324586\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:47 INFO 140645276194624] #quality_metric: host=algo-1, epoch=264, batch=0 train loss <loss>=2.32458567619\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:47 INFO 140645276194624] Epoch[264] Batch[5] avg_epoch_loss=2.322418\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:47 INFO 140645276194624] #quality_metric: host=algo-1, epoch=264, batch=5 train loss <loss>=2.32241797447\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:47 INFO 140645276194624] Epoch[264] Batch [5]#011Speed: 1972.76 samples/sec#011loss=2.322418\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:47 INFO 140645276194624] processed a total of 611 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 524.0001678466797, \"sum\": 524.0001678466797, \"min\": 524.0001678466797}}, \"EndTime\": 1589566187.458459, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566186.933952}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:47 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1165.78828462 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:47 INFO 140645276194624] #progress_metric: host=algo-1, completed 66 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:47 INFO 140645276194624] #quality_metric: host=algo-1, epoch=264, train loss <loss>=2.28931143284\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:47 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:47 INFO 140645276194624] Epoch[265] Batch[0] avg_epoch_loss=2.244431\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:47 INFO 140645276194624] #quality_metric: host=algo-1, epoch=265, batch=0 train loss <loss>=2.24443054199\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:47 INFO 140645276194624] Epoch[265] Batch[5] avg_epoch_loss=2.303238\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:47 INFO 140645276194624] #quality_metric: host=algo-1, epoch=265, batch=5 train loss <loss>=2.30323827267\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:47 INFO 140645276194624] Epoch[265] Batch [5]#011Speed: 1961.64 samples/sec#011loss=2.303238\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:48 INFO 140645276194624] Epoch[265] Batch[10] avg_epoch_loss=2.329741\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:48 INFO 140645276194624] #quality_metric: host=algo-1, epoch=265, batch=10 train loss <loss>=2.36154470444\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:48 INFO 140645276194624] Epoch[265] Batch [10]#011Speed: 1909.73 samples/sec#011loss=2.361545\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:48 INFO 140645276194624] processed a total of 687 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 562.0701313018799, \"sum\": 562.0701313018799, \"min\": 562.0701313018799}}, \"EndTime\": 1589566188.021086, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566187.458529}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:48 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1222.01755659 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:48 INFO 140645276194624] #progress_metric: host=algo-1, completed 66 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:48 INFO 140645276194624] #quality_metric: host=algo-1, epoch=265, train loss <loss>=2.3297411962\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:48 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:48 INFO 140645276194624] Epoch[266] Batch[0] avg_epoch_loss=2.401868\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:48 INFO 140645276194624] #quality_metric: host=algo-1, epoch=266, batch=0 train loss <loss>=2.4018676281\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:48 INFO 140645276194624] Epoch[266] Batch[5] avg_epoch_loss=2.332139\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:48 INFO 140645276194624] #quality_metric: host=algo-1, epoch=266, batch=5 train loss <loss>=2.33213941256\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:48 INFO 140645276194624] Epoch[266] Batch [5]#011Speed: 1987.43 samples/sec#011loss=2.332139\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:48 INFO 140645276194624] processed a total of 630 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 523.2689380645752, \"sum\": 523.2689380645752, \"min\": 523.2689380645752}}, \"EndTime\": 1589566188.544864, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566188.021162}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:48 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1203.74657655 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:48 INFO 140645276194624] #progress_metric: host=algo-1, completed 66 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:48 INFO 140645276194624] #quality_metric: host=algo-1, epoch=266, train loss <loss>=2.31818799973\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:48 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:48 INFO 140645276194624] Epoch[267] Batch[0] avg_epoch_loss=2.316510\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:48 INFO 140645276194624] #quality_metric: host=algo-1, epoch=267, batch=0 train loss <loss>=2.31650996208\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:48 INFO 140645276194624] Epoch[267] Batch[5] avg_epoch_loss=2.329200\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:48 INFO 140645276194624] #quality_metric: host=algo-1, epoch=267, batch=5 train loss <loss>=2.32920030753\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:48 INFO 140645276194624] Epoch[267] Batch [5]#011Speed: 1997.68 samples/sec#011loss=2.329200\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:49 INFO 140645276194624] processed a total of 611 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 526.993989944458, \"sum\": 526.993989944458, \"min\": 526.993989944458}}, \"EndTime\": 1589566189.072407, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566188.544926}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:49 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1159.1380389 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:49 INFO 140645276194624] #progress_metric: host=algo-1, completed 67 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:49 INFO 140645276194624] #quality_metric: host=algo-1, epoch=267, train loss <loss>=2.33357260227\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:49 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:49 INFO 140645276194624] Epoch[268] Batch[0] avg_epoch_loss=2.324763\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:49 INFO 140645276194624] #quality_metric: host=algo-1, epoch=268, batch=0 train loss <loss>=2.3247628212\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:49 INFO 140645276194624] Epoch[268] Batch[5] avg_epoch_loss=2.322850\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:49 INFO 140645276194624] #quality_metric: host=algo-1, epoch=268, batch=5 train loss <loss>=2.32284998894\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:49 INFO 140645276194624] Epoch[268] Batch [5]#011Speed: 1977.15 samples/sec#011loss=2.322850\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:49 INFO 140645276194624] processed a total of 612 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 518.3939933776855, \"sum\": 518.3939933776855, \"min\": 518.3939933776855}}, \"EndTime\": 1589566189.591366, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566189.07249}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:49 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1180.30487004 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:49 INFO 140645276194624] #progress_metric: host=algo-1, completed 67 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:49 INFO 140645276194624] #quality_metric: host=algo-1, epoch=268, train loss <loss>=2.33391485214\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:49 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:49 INFO 140645276194624] Epoch[269] Batch[0] avg_epoch_loss=2.231273\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:49 INFO 140645276194624] #quality_metric: host=algo-1, epoch=269, batch=0 train loss <loss>=2.23127317429\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:49 INFO 140645276194624] Epoch[269] Batch[5] avg_epoch_loss=2.383757\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:49 INFO 140645276194624] #quality_metric: host=algo-1, epoch=269, batch=5 train loss <loss>=2.3837565581\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:49 INFO 140645276194624] Epoch[269] Batch [5]#011Speed: 2008.26 samples/sec#011loss=2.383757\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:50 INFO 140645276194624] Epoch[269] Batch[10] avg_epoch_loss=2.357493\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:50 INFO 140645276194624] #quality_metric: host=algo-1, epoch=269, batch=10 train loss <loss>=2.32597670555\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:50 INFO 140645276194624] Epoch[269] Batch [10]#011Speed: 1660.25 samples/sec#011loss=2.325977\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:50 INFO 140645276194624] processed a total of 643 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 576.1280059814453, \"sum\": 576.1280059814453, \"min\": 576.1280059814453}}, \"EndTime\": 1589566190.168051, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566189.591444}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:50 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1115.85438363 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:50 INFO 140645276194624] #progress_metric: host=algo-1, completed 67 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:50 INFO 140645276194624] #quality_metric: host=algo-1, epoch=269, train loss <loss>=2.35749298876\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:50 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:50 INFO 140645276194624] Epoch[270] Batch[0] avg_epoch_loss=2.370578\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:50 INFO 140645276194624] #quality_metric: host=algo-1, epoch=270, batch=0 train loss <loss>=2.37057781219\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:50 INFO 140645276194624] Epoch[270] Batch[5] avg_epoch_loss=2.378778\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:50 INFO 140645276194624] #quality_metric: host=algo-1, epoch=270, batch=5 train loss <loss>=2.3787779808\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:50 INFO 140645276194624] Epoch[270] Batch [5]#011Speed: 1951.07 samples/sec#011loss=2.378778\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:50 INFO 140645276194624] Epoch[270] Batch[10] avg_epoch_loss=2.357185\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:50 INFO 140645276194624] #quality_metric: host=algo-1, epoch=270, batch=10 train loss <loss>=2.33127436638\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:50 INFO 140645276194624] Epoch[270] Batch [10]#011Speed: 1672.50 samples/sec#011loss=2.331274\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:50 INFO 140645276194624] processed a total of 733 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 671.0071563720703, \"sum\": 671.0071563720703, \"min\": 671.0071563720703}}, \"EndTime\": 1589566190.839546, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566190.168127}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:50 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1092.20419336 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:50 INFO 140645276194624] #progress_metric: host=algo-1, completed 67 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:50 INFO 140645276194624] #quality_metric: host=algo-1, epoch=270, train loss <loss>=2.36293099324\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:50 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:51 INFO 140645276194624] Epoch[271] Batch[0] avg_epoch_loss=2.307938\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:51 INFO 140645276194624] #quality_metric: host=algo-1, epoch=271, batch=0 train loss <loss>=2.30793809891\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:51 INFO 140645276194624] Epoch[271] Batch[5] avg_epoch_loss=2.310286\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:51 INFO 140645276194624] #quality_metric: host=algo-1, epoch=271, batch=5 train loss <loss>=2.31028620402\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:51 INFO 140645276194624] Epoch[271] Batch [5]#011Speed: 1945.31 samples/sec#011loss=2.310286\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:51 INFO 140645276194624] Epoch[271] Batch[10] avg_epoch_loss=2.368797\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:51 INFO 140645276194624] #quality_metric: host=algo-1, epoch=271, batch=10 train loss <loss>=2.43900942802\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:51 INFO 140645276194624] Epoch[271] Batch [10]#011Speed: 1700.34 samples/sec#011loss=2.439009\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:51 INFO 140645276194624] processed a total of 650 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 619.1918849945068, \"sum\": 619.1918849945068, \"min\": 619.1918849945068}}, \"EndTime\": 1589566191.459264, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566190.839625}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:51 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1049.54521464 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:51 INFO 140645276194624] #progress_metric: host=algo-1, completed 68 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:51 INFO 140645276194624] #quality_metric: host=algo-1, epoch=271, train loss <loss>=2.36879676039\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:51 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:51 INFO 140645276194624] Epoch[272] Batch[0] avg_epoch_loss=2.385466\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:51 INFO 140645276194624] #quality_metric: host=algo-1, epoch=272, batch=0 train loss <loss>=2.38546586037\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:51 INFO 140645276194624] Epoch[272] Batch[5] avg_epoch_loss=2.345415\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:51 INFO 140645276194624] #quality_metric: host=algo-1, epoch=272, batch=5 train loss <loss>=2.34541455905\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:51 INFO 140645276194624] Epoch[272] Batch [5]#011Speed: 1968.64 samples/sec#011loss=2.345415\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:52 INFO 140645276194624] processed a total of 632 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 562.6130104064941, \"sum\": 562.6130104064941, \"min\": 562.6130104064941}}, \"EndTime\": 1589566192.022366, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566191.459354}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:52 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1123.09428306 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:52 INFO 140645276194624] #progress_metric: host=algo-1, completed 68 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:52 INFO 140645276194624] #quality_metric: host=algo-1, epoch=272, train loss <loss>=2.34007306099\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:52 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:52 INFO 140645276194624] Epoch[273] Batch[0] avg_epoch_loss=2.365618\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:52 INFO 140645276194624] #quality_metric: host=algo-1, epoch=273, batch=0 train loss <loss>=2.36561846733\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:52 INFO 140645276194624] Epoch[273] Batch[5] avg_epoch_loss=2.324813\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:52 INFO 140645276194624] #quality_metric: host=algo-1, epoch=273, batch=5 train loss <loss>=2.32481265068\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:52 INFO 140645276194624] Epoch[273] Batch [5]#011Speed: 1976.88 samples/sec#011loss=2.324813\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:52 INFO 140645276194624] processed a total of 635 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 538.8710498809814, \"sum\": 538.8710498809814, \"min\": 538.8710498809814}}, \"EndTime\": 1589566192.561781, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566192.022447}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:52 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1178.13410927 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:52 INFO 140645276194624] #progress_metric: host=algo-1, completed 68 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:52 INFO 140645276194624] #quality_metric: host=algo-1, epoch=273, train loss <loss>=2.33893125057\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:52 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:52 INFO 140645276194624] Epoch[274] Batch[0] avg_epoch_loss=2.407225\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:52 INFO 140645276194624] #quality_metric: host=algo-1, epoch=274, batch=0 train loss <loss>=2.40722465515\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:52 INFO 140645276194624] Epoch[274] Batch[5] avg_epoch_loss=2.379054\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:52 INFO 140645276194624] #quality_metric: host=algo-1, epoch=274, batch=5 train loss <loss>=2.37905351321\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:52 INFO 140645276194624] Epoch[274] Batch [5]#011Speed: 1833.49 samples/sec#011loss=2.379054\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:53 INFO 140645276194624] Epoch[274] Batch[10] avg_epoch_loss=2.364622\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:53 INFO 140645276194624] #quality_metric: host=algo-1, epoch=274, batch=10 train loss <loss>=2.34730472565\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:53 INFO 140645276194624] Epoch[274] Batch [10]#011Speed: 1838.89 samples/sec#011loss=2.347305\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:53 INFO 140645276194624] processed a total of 670 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 593.3969020843506, \"sum\": 593.3969020843506, \"min\": 593.3969020843506}}, \"EndTime\": 1589566193.155704, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566192.561862}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:53 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1128.88296498 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:53 INFO 140645276194624] #progress_metric: host=algo-1, completed 68 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:53 INFO 140645276194624] #quality_metric: host=algo-1, epoch=274, train loss <loss>=2.36462224614\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:53 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:53 INFO 140645276194624] Epoch[275] Batch[0] avg_epoch_loss=2.401936\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:53 INFO 140645276194624] #quality_metric: host=algo-1, epoch=275, batch=0 train loss <loss>=2.40193581581\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:53 INFO 140645276194624] Epoch[275] Batch[5] avg_epoch_loss=2.398210\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:53 INFO 140645276194624] #quality_metric: host=algo-1, epoch=275, batch=5 train loss <loss>=2.39821044604\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:53 INFO 140645276194624] Epoch[275] Batch [5]#011Speed: 1900.12 samples/sec#011loss=2.398210\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:53 INFO 140645276194624] Epoch[275] Batch[10] avg_epoch_loss=2.360783\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:53 INFO 140645276194624] #quality_metric: host=algo-1, epoch=275, batch=10 train loss <loss>=2.31587052345\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:53 INFO 140645276194624] Epoch[275] Batch [10]#011Speed: 1855.31 samples/sec#011loss=2.315871\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:53 INFO 140645276194624] processed a total of 679 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 598.9890098571777, \"sum\": 598.9890098571777, \"min\": 598.9890098571777}}, \"EndTime\": 1589566193.755186, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566193.15578}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:53 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1133.3592866 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:53 INFO 140645276194624] #progress_metric: host=algo-1, completed 69 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:53 INFO 140645276194624] #quality_metric: host=algo-1, epoch=275, train loss <loss>=2.3607832085\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:53 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:54 INFO 140645276194624] Epoch[276] Batch[0] avg_epoch_loss=2.328872\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:54 INFO 140645276194624] #quality_metric: host=algo-1, epoch=276, batch=0 train loss <loss>=2.32887196541\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:54 INFO 140645276194624] Epoch[276] Batch[5] avg_epoch_loss=2.298145\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:54 INFO 140645276194624] #quality_metric: host=algo-1, epoch=276, batch=5 train loss <loss>=2.29814533393\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:54 INFO 140645276194624] Epoch[276] Batch [5]#011Speed: 1859.77 samples/sec#011loss=2.298145\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:54 INFO 140645276194624] Epoch[276] Batch[10] avg_epoch_loss=2.318875\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:54 INFO 140645276194624] #quality_metric: host=algo-1, epoch=276, batch=10 train loss <loss>=2.34375157356\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:54 INFO 140645276194624] Epoch[276] Batch [10]#011Speed: 1930.70 samples/sec#011loss=2.343752\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:54 INFO 140645276194624] processed a total of 677 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 595.3338146209717, \"sum\": 595.3338146209717, \"min\": 595.3338146209717}}, \"EndTime\": 1589566194.351007, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566193.755264}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:54 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1136.96085103 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:54 INFO 140645276194624] #progress_metric: host=algo-1, completed 69 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:54 INFO 140645276194624] #quality_metric: host=algo-1, epoch=276, train loss <loss>=2.31887544285\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:54 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:54 INFO 140645276194624] Epoch[277] Batch[0] avg_epoch_loss=2.453668\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:54 INFO 140645276194624] #quality_metric: host=algo-1, epoch=277, batch=0 train loss <loss>=2.45366764069\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:54 INFO 140645276194624] Epoch[277] Batch[5] avg_epoch_loss=2.398170\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:54 INFO 140645276194624] #quality_metric: host=algo-1, epoch=277, batch=5 train loss <loss>=2.39816983541\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:54 INFO 140645276194624] Epoch[277] Batch [5]#011Speed: 2009.53 samples/sec#011loss=2.398170\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:54 INFO 140645276194624] Epoch[277] Batch[10] avg_epoch_loss=2.353293\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:54 INFO 140645276194624] #quality_metric: host=algo-1, epoch=277, batch=10 train loss <loss>=2.29944024086\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:54 INFO 140645276194624] Epoch[277] Batch [10]#011Speed: 1729.90 samples/sec#011loss=2.299440\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:54 INFO 140645276194624] processed a total of 680 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 624.5980262756348, \"sum\": 624.5980262756348, \"min\": 624.5980262756348}}, \"EndTime\": 1589566194.976131, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566194.351084}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:54 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1088.49993665 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:54 INFO 140645276194624] #progress_metric: host=algo-1, completed 69 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:54 INFO 140645276194624] #quality_metric: host=algo-1, epoch=277, train loss <loss>=2.35329274698\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:54 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:55 INFO 140645276194624] Epoch[278] Batch[0] avg_epoch_loss=2.379037\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:55 INFO 140645276194624] #quality_metric: host=algo-1, epoch=278, batch=0 train loss <loss>=2.37903738022\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:55 INFO 140645276194624] Epoch[278] Batch[5] avg_epoch_loss=2.346966\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:55 INFO 140645276194624] #quality_metric: host=algo-1, epoch=278, batch=5 train loss <loss>=2.34696614742\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:55 INFO 140645276194624] Epoch[278] Batch [5]#011Speed: 1974.39 samples/sec#011loss=2.346966\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:55 INFO 140645276194624] processed a total of 617 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 534.2011451721191, \"sum\": 534.2011451721191, \"min\": 534.2011451721191}}, \"EndTime\": 1589566195.510852, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566194.976208}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:55 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1154.76270005 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:55 INFO 140645276194624] #progress_metric: host=algo-1, completed 69 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:55 INFO 140645276194624] #quality_metric: host=algo-1, epoch=278, train loss <loss>=2.3408575058\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:55 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:55 INFO 140645276194624] Epoch[279] Batch[0] avg_epoch_loss=2.377922\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:55 INFO 140645276194624] #quality_metric: host=algo-1, epoch=279, batch=0 train loss <loss>=2.37792229652\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:55 INFO 140645276194624] Epoch[279] Batch[5] avg_epoch_loss=2.393576\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:55 INFO 140645276194624] #quality_metric: host=algo-1, epoch=279, batch=5 train loss <loss>=2.3935760657\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:55 INFO 140645276194624] Epoch[279] Batch [5]#011Speed: 1976.02 samples/sec#011loss=2.393576\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:56 INFO 140645276194624] Epoch[279] Batch[10] avg_epoch_loss=2.364409\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:56 INFO 140645276194624] #quality_metric: host=algo-1, epoch=279, batch=10 train loss <loss>=2.32940878868\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:56 INFO 140645276194624] Epoch[279] Batch [10]#011Speed: 1900.71 samples/sec#011loss=2.329409\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:56 INFO 140645276194624] processed a total of 646 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 556.0758113861084, \"sum\": 556.0758113861084, \"min\": 556.0758113861084}}, \"EndTime\": 1589566196.06748, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566195.510928}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:56 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1161.52783981 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:56 INFO 140645276194624] #progress_metric: host=algo-1, completed 70 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:56 INFO 140645276194624] #quality_metric: host=algo-1, epoch=279, train loss <loss>=2.3644091216\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:56 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:56 INFO 140645276194624] Epoch[280] Batch[0] avg_epoch_loss=2.356314\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:56 INFO 140645276194624] #quality_metric: host=algo-1, epoch=280, batch=0 train loss <loss>=2.35631418228\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:56 INFO 140645276194624] Epoch[280] Batch[5] avg_epoch_loss=2.422529\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:56 INFO 140645276194624] #quality_metric: host=algo-1, epoch=280, batch=5 train loss <loss>=2.42252926032\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:56 INFO 140645276194624] Epoch[280] Batch [5]#011Speed: 1980.09 samples/sec#011loss=2.422529\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:56 INFO 140645276194624] Epoch[280] Batch[10] avg_epoch_loss=2.436147\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:56 INFO 140645276194624] #quality_metric: host=algo-1, epoch=280, batch=10 train loss <loss>=2.45248908997\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:56 INFO 140645276194624] Epoch[280] Batch [10]#011Speed: 1912.25 samples/sec#011loss=2.452489\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:56 INFO 140645276194624] processed a total of 644 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 555.473804473877, \"sum\": 555.473804473877, \"min\": 555.473804473877}}, \"EndTime\": 1589566196.623371, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566196.067534}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:56 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1159.1487071 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:56 INFO 140645276194624] #progress_metric: host=algo-1, completed 70 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:56 INFO 140645276194624] #quality_metric: host=algo-1, epoch=280, train loss <loss>=2.4361473647\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:56 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:56 INFO 140645276194624] Epoch[281] Batch[0] avg_epoch_loss=2.347267\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:56 INFO 140645276194624] #quality_metric: host=algo-1, epoch=281, batch=0 train loss <loss>=2.3472673893\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:57 INFO 140645276194624] Epoch[281] Batch[5] avg_epoch_loss=2.368405\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:57 INFO 140645276194624] #quality_metric: host=algo-1, epoch=281, batch=5 train loss <loss>=2.36840494474\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:57 INFO 140645276194624] Epoch[281] Batch [5]#011Speed: 1810.72 samples/sec#011loss=2.368405\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:57 INFO 140645276194624] processed a total of 616 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 535.6628894805908, \"sum\": 535.6628894805908, \"min\": 535.6628894805908}}, \"EndTime\": 1589566197.15958, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566196.623439}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:57 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1149.71908348 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:57 INFO 140645276194624] #progress_metric: host=algo-1, completed 70 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:57 INFO 140645276194624] #quality_metric: host=algo-1, epoch=281, train loss <loss>=2.4114307642\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:57 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:57 INFO 140645276194624] Epoch[282] Batch[0] avg_epoch_loss=2.300944\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:57 INFO 140645276194624] #quality_metric: host=algo-1, epoch=282, batch=0 train loss <loss>=2.30094408989\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:57 INFO 140645276194624] Epoch[282] Batch[5] avg_epoch_loss=2.323364\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:57 INFO 140645276194624] #quality_metric: host=algo-1, epoch=282, batch=5 train loss <loss>=2.32336350282\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:57 INFO 140645276194624] Epoch[282] Batch [5]#011Speed: 1984.61 samples/sec#011loss=2.323364\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:57 INFO 140645276194624] processed a total of 606 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 535.6321334838867, \"sum\": 535.6321334838867, \"min\": 535.6321334838867}}, \"EndTime\": 1589566197.695793, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566197.159661}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:57 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1131.15195964 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:57 INFO 140645276194624] #progress_metric: host=algo-1, completed 70 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:57 INFO 140645276194624] #quality_metric: host=algo-1, epoch=282, train loss <loss>=2.32029778957\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:57 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:57 INFO 140645276194624] Epoch[283] Batch[0] avg_epoch_loss=2.357385\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:57 INFO 140645276194624] #quality_metric: host=algo-1, epoch=283, batch=0 train loss <loss>=2.35738515854\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:58 INFO 140645276194624] Epoch[283] Batch[5] avg_epoch_loss=2.329127\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:58 INFO 140645276194624] #quality_metric: host=algo-1, epoch=283, batch=5 train loss <loss>=2.32912703355\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:58 INFO 140645276194624] Epoch[283] Batch [5]#011Speed: 1576.78 samples/sec#011loss=2.329127\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:58 INFO 140645276194624] processed a total of 629 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 582.1778774261475, \"sum\": 582.1778774261475, \"min\": 582.1778774261475}}, \"EndTime\": 1589566198.278502, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566197.695858}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:58 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1080.21213325 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:58 INFO 140645276194624] #progress_metric: host=algo-1, completed 71 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:58 INFO 140645276194624] #quality_metric: host=algo-1, epoch=283, train loss <loss>=2.35964236259\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:58 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:58 INFO 140645276194624] Epoch[284] Batch[0] avg_epoch_loss=2.287878\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:58 INFO 140645276194624] #quality_metric: host=algo-1, epoch=284, batch=0 train loss <loss>=2.28787779808\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:58 INFO 140645276194624] Epoch[284] Batch[5] avg_epoch_loss=2.330130\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:58 INFO 140645276194624] #quality_metric: host=algo-1, epoch=284, batch=5 train loss <loss>=2.3301295042\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:58 INFO 140645276194624] Epoch[284] Batch [5]#011Speed: 1963.78 samples/sec#011loss=2.330130\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:58 INFO 140645276194624] Epoch[284] Batch[10] avg_epoch_loss=2.325527\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:58 INFO 140645276194624] #quality_metric: host=algo-1, epoch=284, batch=10 train loss <loss>=2.32000341415\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:58 INFO 140645276194624] Epoch[284] Batch [10]#011Speed: 1933.84 samples/sec#011loss=2.320003\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:58 INFO 140645276194624] processed a total of 696 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 618.5309886932373, \"sum\": 618.5309886932373, \"min\": 618.5309886932373}}, \"EndTime\": 1589566198.897562, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566198.278582}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:58 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1125.05726345 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:58 INFO 140645276194624] #progress_metric: host=algo-1, completed 71 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:58 INFO 140645276194624] #quality_metric: host=algo-1, epoch=284, train loss <loss>=2.325526736\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:58 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:59 INFO 140645276194624] Epoch[285] Batch[0] avg_epoch_loss=2.219270\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:59 INFO 140645276194624] #quality_metric: host=algo-1, epoch=285, batch=0 train loss <loss>=2.21927022934\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:59 INFO 140645276194624] Epoch[285] Batch[5] avg_epoch_loss=2.298887\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:59 INFO 140645276194624] #quality_metric: host=algo-1, epoch=285, batch=5 train loss <loss>=2.29888725281\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:59 INFO 140645276194624] Epoch[285] Batch [5]#011Speed: 1984.93 samples/sec#011loss=2.298887\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:59 INFO 140645276194624] Epoch[285] Batch[10] avg_epoch_loss=2.293215\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:59 INFO 140645276194624] #quality_metric: host=algo-1, epoch=285, batch=10 train loss <loss>=2.2864089489\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:59 INFO 140645276194624] Epoch[285] Batch [10]#011Speed: 1989.04 samples/sec#011loss=2.286409\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:59 INFO 140645276194624] processed a total of 642 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 552.7539253234863, \"sum\": 552.7539253234863, \"min\": 552.7539253234863}}, \"EndTime\": 1589566199.45078, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566198.897627}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:59 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1161.23826975 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:59 INFO 140645276194624] #progress_metric: host=algo-1, completed 71 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:59 INFO 140645276194624] #quality_metric: host=algo-1, epoch=285, train loss <loss>=2.29321529649\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:59 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:59 INFO 140645276194624] Epoch[286] Batch[0] avg_epoch_loss=3.014672\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:59 INFO 140645276194624] #quality_metric: host=algo-1, epoch=286, batch=0 train loss <loss>=3.01467180252\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:59 INFO 140645276194624] Epoch[286] Batch[5] avg_epoch_loss=2.625424\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:59 INFO 140645276194624] #quality_metric: host=algo-1, epoch=286, batch=5 train loss <loss>=2.62542446454\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:59 INFO 140645276194624] Epoch[286] Batch [5]#011Speed: 1945.32 samples/sec#011loss=2.625424\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:59 INFO 140645276194624] processed a total of 623 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 542.9539680480957, \"sum\": 542.9539680480957, \"min\": 542.9539680480957}}, \"EndTime\": 1589566199.99424, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566199.450853}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:59 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1147.1755548 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:59 INFO 140645276194624] #progress_metric: host=algo-1, completed 71 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:59 INFO 140645276194624] #quality_metric: host=algo-1, epoch=286, train loss <loss>=2.61280183792\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:09:59 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:00 INFO 140645276194624] Epoch[287] Batch[0] avg_epoch_loss=2.306253\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:00 INFO 140645276194624] #quality_metric: host=algo-1, epoch=287, batch=0 train loss <loss>=2.30625295639\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:00 INFO 140645276194624] Epoch[287] Batch[5] avg_epoch_loss=2.396982\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:00 INFO 140645276194624] #quality_metric: host=algo-1, epoch=287, batch=5 train loss <loss>=2.39698207378\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:00 INFO 140645276194624] Epoch[287] Batch [5]#011Speed: 2006.77 samples/sec#011loss=2.396982\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:00 INFO 140645276194624] Epoch[287] Batch[10] avg_epoch_loss=2.391450\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:00 INFO 140645276194624] #quality_metric: host=algo-1, epoch=287, batch=10 train loss <loss>=2.38481059074\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:00 INFO 140645276194624] Epoch[287] Batch [10]#011Speed: 1964.43 samples/sec#011loss=2.384811\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:00 INFO 140645276194624] processed a total of 711 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 629.5781135559082, \"sum\": 629.5781135559082, \"min\": 629.5781135559082}}, \"EndTime\": 1589566200.624356, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566199.994322}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:00 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1129.11603752 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:00 INFO 140645276194624] #progress_metric: host=algo-1, completed 72 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:00 INFO 140645276194624] #quality_metric: host=algo-1, epoch=287, train loss <loss>=2.40735999743\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:00 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:00 INFO 140645276194624] Epoch[288] Batch[0] avg_epoch_loss=2.306893\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:00 INFO 140645276194624] #quality_metric: host=algo-1, epoch=288, batch=0 train loss <loss>=2.30689263344\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:01 INFO 140645276194624] Epoch[288] Batch[5] avg_epoch_loss=2.370627\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:01 INFO 140645276194624] #quality_metric: host=algo-1, epoch=288, batch=5 train loss <loss>=2.370627443\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:01 INFO 140645276194624] Epoch[288] Batch [5]#011Speed: 1996.18 samples/sec#011loss=2.370627\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:01 INFO 140645276194624] processed a total of 617 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 585.2549076080322, \"sum\": 585.2549076080322, \"min\": 585.2549076080322}}, \"EndTime\": 1589566201.210169, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566200.624436}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:01 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1054.05769796 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:01 INFO 140645276194624] #progress_metric: host=algo-1, completed 72 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:01 INFO 140645276194624] #quality_metric: host=algo-1, epoch=288, train loss <loss>=2.34073300362\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:01 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:01 INFO 140645276194624] Epoch[289] Batch[0] avg_epoch_loss=2.369345\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:01 INFO 140645276194624] #quality_metric: host=algo-1, epoch=289, batch=0 train loss <loss>=2.36934494972\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:01 INFO 140645276194624] Epoch[289] Batch[5] avg_epoch_loss=2.361205\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:01 INFO 140645276194624] #quality_metric: host=algo-1, epoch=289, batch=5 train loss <loss>=2.36120525996\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:01 INFO 140645276194624] Epoch[289] Batch [5]#011Speed: 1928.41 samples/sec#011loss=2.361205\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:01 INFO 140645276194624] processed a total of 620 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 535.1970195770264, \"sum\": 535.1970195770264, \"min\": 535.1970195770264}}, \"EndTime\": 1589566201.745912, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566201.210237}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:01 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1158.19855964 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:01 INFO 140645276194624] #progress_metric: host=algo-1, completed 72 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:01 INFO 140645276194624] #quality_metric: host=algo-1, epoch=289, train loss <loss>=2.34867320061\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:01 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:02 INFO 140645276194624] Epoch[290] Batch[0] avg_epoch_loss=2.499136\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:02 INFO 140645276194624] #quality_metric: host=algo-1, epoch=290, batch=0 train loss <loss>=2.49913597107\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:02 INFO 140645276194624] Epoch[290] Batch[5] avg_epoch_loss=2.384840\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:02 INFO 140645276194624] #quality_metric: host=algo-1, epoch=290, batch=5 train loss <loss>=2.38483961423\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:02 INFO 140645276194624] Epoch[290] Batch [5]#011Speed: 1740.96 samples/sec#011loss=2.384840\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:02 INFO 140645276194624] processed a total of 624 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 603.0440330505371, \"sum\": 603.0440330505371, \"min\": 603.0440330505371}}, \"EndTime\": 1589566202.349488, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566201.745993}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:02 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1034.54293899 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:02 INFO 140645276194624] #progress_metric: host=algo-1, completed 72 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:02 INFO 140645276194624] #quality_metric: host=algo-1, epoch=290, train loss <loss>=2.34914731979\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:02 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:02 INFO 140645276194624] Epoch[291] Batch[0] avg_epoch_loss=2.293914\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:02 INFO 140645276194624] #quality_metric: host=algo-1, epoch=291, batch=0 train loss <loss>=2.29391384125\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:02 INFO 140645276194624] Epoch[291] Batch[5] avg_epoch_loss=2.373956\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:02 INFO 140645276194624] #quality_metric: host=algo-1, epoch=291, batch=5 train loss <loss>=2.37395596504\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:02 INFO 140645276194624] Epoch[291] Batch [5]#011Speed: 1999.15 samples/sec#011loss=2.373956\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:02 INFO 140645276194624] Epoch[291] Batch[10] avg_epoch_loss=2.367932\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:02 INFO 140645276194624] #quality_metric: host=algo-1, epoch=291, batch=10 train loss <loss>=2.36070380211\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:02 INFO 140645276194624] Epoch[291] Batch [10]#011Speed: 1833.13 samples/sec#011loss=2.360704\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:02 INFO 140645276194624] processed a total of 682 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 575.7060050964355, \"sum\": 575.7060050964355, \"min\": 575.7060050964355}}, \"EndTime\": 1589566202.925733, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566202.349572}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:02 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1184.39992713 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:02 INFO 140645276194624] #progress_metric: host=algo-1, completed 73 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:02 INFO 140645276194624] #quality_metric: host=algo-1, epoch=291, train loss <loss>=2.36793225462\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:02 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:03 INFO 140645276194624] Epoch[292] Batch[0] avg_epoch_loss=2.543306\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:03 INFO 140645276194624] #quality_metric: host=algo-1, epoch=292, batch=0 train loss <loss>=2.54330635071\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:03 INFO 140645276194624] Epoch[292] Batch[5] avg_epoch_loss=2.484994\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:03 INFO 140645276194624] #quality_metric: host=algo-1, epoch=292, batch=5 train loss <loss>=2.48499413331\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:03 INFO 140645276194624] Epoch[292] Batch [5]#011Speed: 1803.48 samples/sec#011loss=2.484994\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:03 INFO 140645276194624] Epoch[292] Batch[10] avg_epoch_loss=2.411900\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:03 INFO 140645276194624] #quality_metric: host=algo-1, epoch=292, batch=10 train loss <loss>=2.32418670654\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:03 INFO 140645276194624] Epoch[292] Batch [10]#011Speed: 1945.66 samples/sec#011loss=2.324187\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:03 INFO 140645276194624] processed a total of 662 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 602.553129196167, \"sum\": 602.553129196167, \"min\": 602.553129196167}}, \"EndTime\": 1589566203.528776, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566202.92581}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:03 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1098.46141381 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:03 INFO 140645276194624] #progress_metric: host=algo-1, completed 73 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:03 INFO 140645276194624] #quality_metric: host=algo-1, epoch=292, train loss <loss>=2.41189984842\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:03 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:03 INFO 140645276194624] Epoch[293] Batch[0] avg_epoch_loss=2.371343\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:03 INFO 140645276194624] #quality_metric: host=algo-1, epoch=293, batch=0 train loss <loss>=2.37134337425\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:03 INFO 140645276194624] Epoch[293] Batch[5] avg_epoch_loss=2.298759\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:03 INFO 140645276194624] #quality_metric: host=algo-1, epoch=293, batch=5 train loss <loss>=2.29875858625\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:03 INFO 140645276194624] Epoch[293] Batch [5]#011Speed: 2013.53 samples/sec#011loss=2.298759\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:04 INFO 140645276194624] processed a total of 592 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 520.7948684692383, \"sum\": 520.7948684692383, \"min\": 520.7948684692383}}, \"EndTime\": 1589566204.050047, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566203.52885}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:04 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1136.46641558 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:04 INFO 140645276194624] #progress_metric: host=algo-1, completed 73 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:04 INFO 140645276194624] #quality_metric: host=algo-1, epoch=293, train loss <loss>=2.1844761014\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:04 INFO 140645276194624] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:04 INFO 140645276194624] Saved checkpoint to \"/opt/ml/model/state_3c4a374f-e5b6-41d4-b27a-7904868801f6-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 12.23301887512207, \"sum\": 12.23301887512207, \"min\": 12.23301887512207}}, \"EndTime\": 1589566204.062899, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566204.050126}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:04 INFO 140645276194624] Epoch[294] Batch[0] avg_epoch_loss=2.363705\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:04 INFO 140645276194624] #quality_metric: host=algo-1, epoch=294, batch=0 train loss <loss>=2.36370539665\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:04 INFO 140645276194624] Epoch[294] Batch[5] avg_epoch_loss=2.299606\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:04 INFO 140645276194624] #quality_metric: host=algo-1, epoch=294, batch=5 train loss <loss>=2.29960628351\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:04 INFO 140645276194624] Epoch[294] Batch [5]#011Speed: 1882.05 samples/sec#011loss=2.299606\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:04 INFO 140645276194624] processed a total of 614 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 525.8209705352783, \"sum\": 525.8209705352783, \"min\": 525.8209705352783}}, \"EndTime\": 1589566204.588859, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566204.062973}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:04 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1167.43103152 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:04 INFO 140645276194624] #progress_metric: host=algo-1, completed 73 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:04 INFO 140645276194624] #quality_metric: host=algo-1, epoch=294, train loss <loss>=2.34869551659\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:04 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:04 INFO 140645276194624] Epoch[295] Batch[0] avg_epoch_loss=2.408998\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:04 INFO 140645276194624] #quality_metric: host=algo-1, epoch=295, batch=0 train loss <loss>=2.40899801254\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:04 INFO 140645276194624] Epoch[295] Batch[5] avg_epoch_loss=2.326942\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:04 INFO 140645276194624] #quality_metric: host=algo-1, epoch=295, batch=5 train loss <loss>=2.32694240411\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:04 INFO 140645276194624] Epoch[295] Batch [5]#011Speed: 2002.59 samples/sec#011loss=2.326942\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:05 INFO 140645276194624] processed a total of 640 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 508.50701332092285, \"sum\": 508.50701332092285, \"min\": 508.50701332092285}}, \"EndTime\": 1589566205.097949, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566204.58894}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:05 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1258.31911896 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:05 INFO 140645276194624] #progress_metric: host=algo-1, completed 74 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:05 INFO 140645276194624] #quality_metric: host=algo-1, epoch=295, train loss <loss>=2.30200972557\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:05 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:05 INFO 140645276194624] Epoch[296] Batch[0] avg_epoch_loss=2.158922\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:05 INFO 140645276194624] #quality_metric: host=algo-1, epoch=296, batch=0 train loss <loss>=2.15892243385\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:05 INFO 140645276194624] Epoch[296] Batch[5] avg_epoch_loss=2.264256\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:05 INFO 140645276194624] #quality_metric: host=algo-1, epoch=296, batch=5 train loss <loss>=2.26425552368\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:05 INFO 140645276194624] Epoch[296] Batch [5]#011Speed: 1854.91 samples/sec#011loss=2.264256\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:05 INFO 140645276194624] Epoch[296] Batch[10] avg_epoch_loss=2.255030\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:05 INFO 140645276194624] #quality_metric: host=algo-1, epoch=296, batch=10 train loss <loss>=2.24395985603\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:05 INFO 140645276194624] Epoch[296] Batch [10]#011Speed: 1922.61 samples/sec#011loss=2.243960\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:05 INFO 140645276194624] processed a total of 656 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 584.8491191864014, \"sum\": 584.8491191864014, \"min\": 584.8491191864014}}, \"EndTime\": 1589566205.683359, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566205.098019}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:05 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1121.42686357 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:05 INFO 140645276194624] #progress_metric: host=algo-1, completed 74 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:05 INFO 140645276194624] #quality_metric: host=algo-1, epoch=296, train loss <loss>=2.25503022021\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:05 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:05 INFO 140645276194624] Epoch[297] Batch[0] avg_epoch_loss=2.285788\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:05 INFO 140645276194624] #quality_metric: host=algo-1, epoch=297, batch=0 train loss <loss>=2.28578782082\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:06 INFO 140645276194624] Epoch[297] Batch[5] avg_epoch_loss=2.347746\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:06 INFO 140645276194624] #quality_metric: host=algo-1, epoch=297, batch=5 train loss <loss>=2.34774633249\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:06 INFO 140645276194624] Epoch[297] Batch [5]#011Speed: 2010.74 samples/sec#011loss=2.347746\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:06 INFO 140645276194624] processed a total of 637 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 523.1599807739258, \"sum\": 523.1599807739258, \"min\": 523.1599807739258}}, \"EndTime\": 1589566206.207033, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566205.683442}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:06 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1217.32173073 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:06 INFO 140645276194624] #progress_metric: host=algo-1, completed 74 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:06 INFO 140645276194624] #quality_metric: host=algo-1, epoch=297, train loss <loss>=2.31219508648\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:06 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:06 INFO 140645276194624] Epoch[298] Batch[0] avg_epoch_loss=2.311530\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:06 INFO 140645276194624] #quality_metric: host=algo-1, epoch=298, batch=0 train loss <loss>=2.31153035164\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:06 INFO 140645276194624] Epoch[298] Batch[5] avg_epoch_loss=2.374187\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:06 INFO 140645276194624] #quality_metric: host=algo-1, epoch=298, batch=5 train loss <loss>=2.37418671449\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:06 INFO 140645276194624] Epoch[298] Batch [5]#011Speed: 1939.22 samples/sec#011loss=2.374187\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:06 INFO 140645276194624] Epoch[298] Batch[10] avg_epoch_loss=2.467275\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:06 INFO 140645276194624] #quality_metric: host=algo-1, epoch=298, batch=10 train loss <loss>=2.57898044586\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:06 INFO 140645276194624] Epoch[298] Batch [10]#011Speed: 1880.60 samples/sec#011loss=2.578980\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:06 INFO 140645276194624] processed a total of 647 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 602.6220321655273, \"sum\": 602.6220321655273, \"min\": 602.6220321655273}}, \"EndTime\": 1589566206.810203, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566206.207114}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:06 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1073.4528976 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:06 INFO 140645276194624] #progress_metric: host=algo-1, completed 74 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:06 INFO 140645276194624] #quality_metric: host=algo-1, epoch=298, train loss <loss>=2.4672747742\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:06 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:07 INFO 140645276194624] Epoch[299] Batch[0] avg_epoch_loss=2.650125\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:07 INFO 140645276194624] #quality_metric: host=algo-1, epoch=299, batch=0 train loss <loss>=2.65012478828\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:07 INFO 140645276194624] Epoch[299] Batch[5] avg_epoch_loss=2.518382\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:07 INFO 140645276194624] #quality_metric: host=algo-1, epoch=299, batch=5 train loss <loss>=2.51838175456\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:07 INFO 140645276194624] Epoch[299] Batch [5]#011Speed: 2001.21 samples/sec#011loss=2.518382\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:07 INFO 140645276194624] Epoch[299] Batch[10] avg_epoch_loss=2.461878\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:07 INFO 140645276194624] #quality_metric: host=algo-1, epoch=299, batch=10 train loss <loss>=2.39407410622\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:07 INFO 140645276194624] Epoch[299] Batch [10]#011Speed: 1952.85 samples/sec#011loss=2.394074\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:07 INFO 140645276194624] processed a total of 649 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 541.7609214782715, \"sum\": 541.7609214782715, \"min\": 541.7609214782715}}, \"EndTime\": 1589566207.35248, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566206.810275}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:07 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1197.70240645 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:07 INFO 140645276194624] #progress_metric: host=algo-1, completed 75 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:07 INFO 140645276194624] #quality_metric: host=algo-1, epoch=299, train loss <loss>=2.46187827804\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:07 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:07 INFO 140645276194624] Epoch[300] Batch[0] avg_epoch_loss=2.326956\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:07 INFO 140645276194624] #quality_metric: host=algo-1, epoch=300, batch=0 train loss <loss>=2.32695555687\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:07 INFO 140645276194624] Epoch[300] Batch[5] avg_epoch_loss=2.395916\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:07 INFO 140645276194624] #quality_metric: host=algo-1, epoch=300, batch=5 train loss <loss>=2.39591594537\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:07 INFO 140645276194624] Epoch[300] Batch [5]#011Speed: 2027.23 samples/sec#011loss=2.395916\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:07 INFO 140645276194624] Epoch[300] Batch[10] avg_epoch_loss=2.362077\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:07 INFO 140645276194624] #quality_metric: host=algo-1, epoch=300, batch=10 train loss <loss>=2.32147035599\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:07 INFO 140645276194624] Epoch[300] Batch [10]#011Speed: 1962.85 samples/sec#011loss=2.321470\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:07 INFO 140645276194624] processed a total of 672 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 540.7938957214355, \"sum\": 540.7938957214355, \"min\": 540.7938957214355}}, \"EndTime\": 1589566207.893842, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566207.352557}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:07 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1242.35795917 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:07 INFO 140645276194624] #progress_metric: host=algo-1, completed 75 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:07 INFO 140645276194624] #quality_metric: host=algo-1, epoch=300, train loss <loss>=2.36207704111\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:07 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:08 INFO 140645276194624] Epoch[301] Batch[0] avg_epoch_loss=2.236625\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:08 INFO 140645276194624] #quality_metric: host=algo-1, epoch=301, batch=0 train loss <loss>=2.23662519455\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:08 INFO 140645276194624] Epoch[301] Batch[5] avg_epoch_loss=2.289250\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:08 INFO 140645276194624] #quality_metric: host=algo-1, epoch=301, batch=5 train loss <loss>=2.289249897\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:08 INFO 140645276194624] Epoch[301] Batch [5]#011Speed: 2003.13 samples/sec#011loss=2.289250\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:08 INFO 140645276194624] processed a total of 619 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 535.8870029449463, \"sum\": 535.8870029449463, \"min\": 535.8870029449463}}, \"EndTime\": 1589566208.430243, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566207.893919}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:08 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1154.8635599 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:08 INFO 140645276194624] #progress_metric: host=algo-1, completed 75 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:08 INFO 140645276194624] #quality_metric: host=algo-1, epoch=301, train loss <loss>=2.27337286472\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:08 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:08 INFO 140645276194624] Epoch[302] Batch[0] avg_epoch_loss=2.290424\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:08 INFO 140645276194624] #quality_metric: host=algo-1, epoch=302, batch=0 train loss <loss>=2.29042363167\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:08 INFO 140645276194624] Epoch[302] Batch[5] avg_epoch_loss=2.342126\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:08 INFO 140645276194624] #quality_metric: host=algo-1, epoch=302, batch=5 train loss <loss>=2.34212640921\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:08 INFO 140645276194624] Epoch[302] Batch [5]#011Speed: 1920.39 samples/sec#011loss=2.342126\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:08 INFO 140645276194624] processed a total of 618 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 517.9388523101807, \"sum\": 517.9388523101807, \"min\": 517.9388523101807}}, \"EndTime\": 1589566208.948729, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566208.430311}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:08 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1192.92581445 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:08 INFO 140645276194624] #progress_metric: host=algo-1, completed 75 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:08 INFO 140645276194624] #quality_metric: host=algo-1, epoch=302, train loss <loss>=2.3397036314\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:08 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:09 INFO 140645276194624] Epoch[303] Batch[0] avg_epoch_loss=2.398505\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:09 INFO 140645276194624] #quality_metric: host=algo-1, epoch=303, batch=0 train loss <loss>=2.39850473404\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:09 INFO 140645276194624] Epoch[303] Batch[5] avg_epoch_loss=2.309973\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:09 INFO 140645276194624] #quality_metric: host=algo-1, epoch=303, batch=5 train loss <loss>=2.3099728028\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:09 INFO 140645276194624] Epoch[303] Batch [5]#011Speed: 1974.46 samples/sec#011loss=2.309973\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:09 INFO 140645276194624] processed a total of 636 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 516.7989730834961, \"sum\": 516.7989730834961, \"min\": 516.7989730834961}}, \"EndTime\": 1589566209.466039, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566208.948808}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:09 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1230.39773512 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:09 INFO 140645276194624] #progress_metric: host=algo-1, completed 76 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:09 INFO 140645276194624] #quality_metric: host=algo-1, epoch=303, train loss <loss>=2.29205822945\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:09 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:09 INFO 140645276194624] Epoch[304] Batch[0] avg_epoch_loss=2.232881\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:09 INFO 140645276194624] #quality_metric: host=algo-1, epoch=304, batch=0 train loss <loss>=2.23288059235\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:09 INFO 140645276194624] Epoch[304] Batch[5] avg_epoch_loss=2.346459\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:09 INFO 140645276194624] #quality_metric: host=algo-1, epoch=304, batch=5 train loss <loss>=2.34645875295\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:09 INFO 140645276194624] Epoch[304] Batch [5]#011Speed: 1920.79 samples/sec#011loss=2.346459\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:09 INFO 140645276194624] processed a total of 633 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 525.1150131225586, \"sum\": 525.1150131225586, \"min\": 525.1150131225586}}, \"EndTime\": 1589566209.991711, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566209.466114}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:09 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1205.20724706 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:09 INFO 140645276194624] #progress_metric: host=algo-1, completed 76 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:09 INFO 140645276194624] #quality_metric: host=algo-1, epoch=304, train loss <loss>=2.35399260521\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:09 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:10 INFO 140645276194624] Epoch[305] Batch[0] avg_epoch_loss=2.289618\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:10 INFO 140645276194624] #quality_metric: host=algo-1, epoch=305, batch=0 train loss <loss>=2.28961801529\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:10 INFO 140645276194624] Epoch[305] Batch[5] avg_epoch_loss=2.280183\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:10 INFO 140645276194624] #quality_metric: host=algo-1, epoch=305, batch=5 train loss <loss>=2.28018260002\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:10 INFO 140645276194624] Epoch[305] Batch [5]#011Speed: 1872.02 samples/sec#011loss=2.280183\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:10 INFO 140645276194624] processed a total of 609 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 515.390157699585, \"sum\": 515.390157699585, \"min\": 515.390157699585}}, \"EndTime\": 1589566210.507689, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566209.991777}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:10 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1181.34272489 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:10 INFO 140645276194624] #progress_metric: host=algo-1, completed 76 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:10 INFO 140645276194624] #quality_metric: host=algo-1, epoch=305, train loss <loss>=2.30094928741\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:10 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:10 INFO 140645276194624] Epoch[306] Batch[0] avg_epoch_loss=2.447376\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:10 INFO 140645276194624] #quality_metric: host=algo-1, epoch=306, batch=0 train loss <loss>=2.4473760128\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:10 INFO 140645276194624] Epoch[306] Batch[5] avg_epoch_loss=2.343359\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:10 INFO 140645276194624] #quality_metric: host=algo-1, epoch=306, batch=5 train loss <loss>=2.34335927169\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:10 INFO 140645276194624] Epoch[306] Batch [5]#011Speed: 1988.55 samples/sec#011loss=2.343359\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:11 INFO 140645276194624] processed a total of 638 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 550.9660243988037, \"sum\": 550.9660243988037, \"min\": 550.9660243988037}}, \"EndTime\": 1589566211.059189, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566210.50777}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:11 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1157.76273436 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:11 INFO 140645276194624] #progress_metric: host=algo-1, completed 76 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:11 INFO 140645276194624] #quality_metric: host=algo-1, epoch=306, train loss <loss>=2.33014769554\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:11 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:11 INFO 140645276194624] Epoch[307] Batch[0] avg_epoch_loss=2.296813\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:11 INFO 140645276194624] #quality_metric: host=algo-1, epoch=307, batch=0 train loss <loss>=2.29681253433\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:11 INFO 140645276194624] Epoch[307] Batch[5] avg_epoch_loss=2.277616\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:11 INFO 140645276194624] #quality_metric: host=algo-1, epoch=307, batch=5 train loss <loss>=2.27761594454\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:11 INFO 140645276194624] Epoch[307] Batch [5]#011Speed: 1976.36 samples/sec#011loss=2.277616\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:11 INFO 140645276194624] processed a total of 547 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 470.8130359649658, \"sum\": 470.8130359649658, \"min\": 470.8130359649658}}, \"EndTime\": 1589566211.530543, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566211.05925}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:11 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1161.52884021 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:11 INFO 140645276194624] #progress_metric: host=algo-1, completed 77 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:11 INFO 140645276194624] #quality_metric: host=algo-1, epoch=307, train loss <loss>=2.26429865095\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:11 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:11 INFO 140645276194624] Epoch[308] Batch[0] avg_epoch_loss=2.340601\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:11 INFO 140645276194624] #quality_metric: host=algo-1, epoch=308, batch=0 train loss <loss>=2.34060120583\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:11 INFO 140645276194624] Epoch[308] Batch[5] avg_epoch_loss=2.294837\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:11 INFO 140645276194624] #quality_metric: host=algo-1, epoch=308, batch=5 train loss <loss>=2.29483695825\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:11 INFO 140645276194624] Epoch[308] Batch [5]#011Speed: 1863.19 samples/sec#011loss=2.294837\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:12 INFO 140645276194624] Epoch[308] Batch[10] avg_epoch_loss=2.315210\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:12 INFO 140645276194624] #quality_metric: host=algo-1, epoch=308, batch=10 train loss <loss>=2.33965783119\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:12 INFO 140645276194624] Epoch[308] Batch [10]#011Speed: 1998.30 samples/sec#011loss=2.339658\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:12 INFO 140645276194624] processed a total of 647 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 568.789005279541, \"sum\": 568.789005279541, \"min\": 568.789005279541}}, \"EndTime\": 1589566212.099852, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566211.530624}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:12 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1137.270343 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:12 INFO 140645276194624] #progress_metric: host=algo-1, completed 77 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:12 INFO 140645276194624] #quality_metric: host=algo-1, epoch=308, train loss <loss>=2.31521008231\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:12 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:12 INFO 140645276194624] Epoch[309] Batch[0] avg_epoch_loss=2.537418\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:12 INFO 140645276194624] #quality_metric: host=algo-1, epoch=309, batch=0 train loss <loss>=2.53741765022\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:12 INFO 140645276194624] Epoch[309] Batch[5] avg_epoch_loss=2.416004\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:12 INFO 140645276194624] #quality_metric: host=algo-1, epoch=309, batch=5 train loss <loss>=2.41600382328\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:12 INFO 140645276194624] Epoch[309] Batch [5]#011Speed: 2003.71 samples/sec#011loss=2.416004\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:12 INFO 140645276194624] Epoch[309] Batch[10] avg_epoch_loss=2.452191\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:12 INFO 140645276194624] #quality_metric: host=algo-1, epoch=309, batch=10 train loss <loss>=2.4956155777\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:12 INFO 140645276194624] Epoch[309] Batch [10]#011Speed: 1972.74 samples/sec#011loss=2.495616\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:12 INFO 140645276194624] processed a total of 649 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 539.9689674377441, \"sum\": 539.9689674377441, \"min\": 539.9689674377441}}, \"EndTime\": 1589566212.640343, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566212.099931}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:12 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1201.66730353 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:12 INFO 140645276194624] #progress_metric: host=algo-1, completed 77 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:12 INFO 140645276194624] #quality_metric: host=algo-1, epoch=309, train loss <loss>=2.45219098438\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:12 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:12 INFO 140645276194624] Epoch[310] Batch[0] avg_epoch_loss=3.139616\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:12 INFO 140645276194624] #quality_metric: host=algo-1, epoch=310, batch=0 train loss <loss>=3.13961625099\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:13 INFO 140645276194624] Epoch[310] Batch[5] avg_epoch_loss=2.687302\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:13 INFO 140645276194624] #quality_metric: host=algo-1, epoch=310, batch=5 train loss <loss>=2.68730223179\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:13 INFO 140645276194624] Epoch[310] Batch [5]#011Speed: 1882.07 samples/sec#011loss=2.687302\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:13 INFO 140645276194624] processed a total of 631 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 532.3340892791748, \"sum\": 532.3340892791748, \"min\": 532.3340892791748}}, \"EndTime\": 1589566213.173196, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566212.640419}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:13 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1185.11442244 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:13 INFO 140645276194624] #progress_metric: host=algo-1, completed 77 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:13 INFO 140645276194624] #quality_metric: host=algo-1, epoch=310, train loss <loss>=2.62091727257\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:13 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:13 INFO 140645276194624] Epoch[311] Batch[0] avg_epoch_loss=2.309316\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:13 INFO 140645276194624] #quality_metric: host=algo-1, epoch=311, batch=0 train loss <loss>=2.30931568146\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:13 INFO 140645276194624] Epoch[311] Batch[5] avg_epoch_loss=2.404863\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:13 INFO 140645276194624] #quality_metric: host=algo-1, epoch=311, batch=5 train loss <loss>=2.40486260255\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:13 INFO 140645276194624] Epoch[311] Batch [5]#011Speed: 1890.69 samples/sec#011loss=2.404863\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:13 INFO 140645276194624] Epoch[311] Batch[10] avg_epoch_loss=2.391168\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:13 INFO 140645276194624] #quality_metric: host=algo-1, epoch=311, batch=10 train loss <loss>=2.37473359108\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:13 INFO 140645276194624] Epoch[311] Batch [10]#011Speed: 1943.28 samples/sec#011loss=2.374734\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:13 INFO 140645276194624] processed a total of 669 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 554.8388957977295, \"sum\": 554.8388957977295, \"min\": 554.8388957977295}}, \"EndTime\": 1589566213.728552, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566213.173269}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:13 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1205.5072799 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:13 INFO 140645276194624] #progress_metric: host=algo-1, completed 78 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:13 INFO 140645276194624] #quality_metric: host=algo-1, epoch=311, train loss <loss>=2.39116759734\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:13 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:13 INFO 140645276194624] Epoch[312] Batch[0] avg_epoch_loss=2.242774\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:13 INFO 140645276194624] #quality_metric: host=algo-1, epoch=312, batch=0 train loss <loss>=2.24277353287\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:14 INFO 140645276194624] Epoch[312] Batch[5] avg_epoch_loss=2.355725\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:14 INFO 140645276194624] #quality_metric: host=algo-1, epoch=312, batch=5 train loss <loss>=2.35572481155\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:14 INFO 140645276194624] Epoch[312] Batch [5]#011Speed: 1994.78 samples/sec#011loss=2.355725\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:14 INFO 140645276194624] Epoch[312] Batch[10] avg_epoch_loss=2.318821\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:14 INFO 140645276194624] #quality_metric: host=algo-1, epoch=312, batch=10 train loss <loss>=2.27453660965\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:14 INFO 140645276194624] Epoch[312] Batch [10]#011Speed: 1981.03 samples/sec#011loss=2.274537\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:14 INFO 140645276194624] processed a total of 691 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 554.5880794525146, \"sum\": 554.5880794525146, \"min\": 554.5880794525146}}, \"EndTime\": 1589566214.283666, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566213.728629}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:14 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1245.73898258 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:14 INFO 140645276194624] #progress_metric: host=algo-1, completed 78 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:14 INFO 140645276194624] #quality_metric: host=algo-1, epoch=312, train loss <loss>=2.31882108342\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:14 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:14 INFO 140645276194624] Epoch[313] Batch[0] avg_epoch_loss=2.353103\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:14 INFO 140645276194624] #quality_metric: host=algo-1, epoch=313, batch=0 train loss <loss>=2.35310339928\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:14 INFO 140645276194624] Epoch[313] Batch[5] avg_epoch_loss=2.329877\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:14 INFO 140645276194624] #quality_metric: host=algo-1, epoch=313, batch=5 train loss <loss>=2.32987697919\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:14 INFO 140645276194624] Epoch[313] Batch [5]#011Speed: 1977.29 samples/sec#011loss=2.329877\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:14 INFO 140645276194624] Epoch[313] Batch[10] avg_epoch_loss=2.330828\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:14 INFO 140645276194624] #quality_metric: host=algo-1, epoch=313, batch=10 train loss <loss>=2.3319691658\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:14 INFO 140645276194624] Epoch[313] Batch [10]#011Speed: 1931.68 samples/sec#011loss=2.331969\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:14 INFO 140645276194624] processed a total of 659 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 557.750940322876, \"sum\": 557.750940322876, \"min\": 557.750940322876}}, \"EndTime\": 1589566214.841948, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566214.283737}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:14 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1181.24919538 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:14 INFO 140645276194624] #progress_metric: host=algo-1, completed 78 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:14 INFO 140645276194624] #quality_metric: host=algo-1, epoch=313, train loss <loss>=2.33082797311\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:14 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:15 INFO 140645276194624] Epoch[314] Batch[0] avg_epoch_loss=2.428280\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:15 INFO 140645276194624] #quality_metric: host=algo-1, epoch=314, batch=0 train loss <loss>=2.42827987671\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:15 INFO 140645276194624] Epoch[314] Batch[5] avg_epoch_loss=2.355580\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:15 INFO 140645276194624] #quality_metric: host=algo-1, epoch=314, batch=5 train loss <loss>=2.35557973385\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:15 INFO 140645276194624] Epoch[314] Batch [5]#011Speed: 1833.60 samples/sec#011loss=2.355580\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:15 INFO 140645276194624] processed a total of 630 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 599.2980003356934, \"sum\": 599.2980003356934, \"min\": 599.2980003356934}}, \"EndTime\": 1589566215.441752, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566214.842025}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:15 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1051.01251393 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:15 INFO 140645276194624] #progress_metric: host=algo-1, completed 78 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:15 INFO 140645276194624] #quality_metric: host=algo-1, epoch=314, train loss <loss>=2.36456148624\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:15 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:15 INFO 140645276194624] Epoch[315] Batch[0] avg_epoch_loss=2.444172\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:15 INFO 140645276194624] #quality_metric: host=algo-1, epoch=315, batch=0 train loss <loss>=2.44417190552\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:15 INFO 140645276194624] Epoch[315] Batch[5] avg_epoch_loss=2.359497\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:15 INFO 140645276194624] #quality_metric: host=algo-1, epoch=315, batch=5 train loss <loss>=2.35949687163\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:15 INFO 140645276194624] Epoch[315] Batch [5]#011Speed: 1960.88 samples/sec#011loss=2.359497\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:15 INFO 140645276194624] processed a total of 625 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 557.6081275939941, \"sum\": 557.6081275939941, \"min\": 557.6081275939941}}, \"EndTime\": 1589566215.999926, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566215.441835}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:16 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1120.62597467 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:16 INFO 140645276194624] #progress_metric: host=algo-1, completed 79 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:16 INFO 140645276194624] #quality_metric: host=algo-1, epoch=315, train loss <loss>=2.33545668125\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:16 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:16 INFO 140645276194624] Epoch[316] Batch[0] avg_epoch_loss=2.239238\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:16 INFO 140645276194624] #quality_metric: host=algo-1, epoch=316, batch=0 train loss <loss>=2.23923754692\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:16 INFO 140645276194624] Epoch[316] Batch[5] avg_epoch_loss=2.288782\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:16 INFO 140645276194624] #quality_metric: host=algo-1, epoch=316, batch=5 train loss <loss>=2.2887818416\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:16 INFO 140645276194624] Epoch[316] Batch [5]#011Speed: 1967.30 samples/sec#011loss=2.288782\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:16 INFO 140645276194624] Epoch[316] Batch[10] avg_epoch_loss=2.286251\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:16 INFO 140645276194624] #quality_metric: host=algo-1, epoch=316, batch=10 train loss <loss>=2.28321385384\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:16 INFO 140645276194624] Epoch[316] Batch [10]#011Speed: 1833.37 samples/sec#011loss=2.283214\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:16 INFO 140645276194624] processed a total of 678 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 628.8008689880371, \"sum\": 628.8008689880371, \"min\": 628.8008689880371}}, \"EndTime\": 1589566216.62925, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566216.000006}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:16 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1078.05393799 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:16 INFO 140645276194624] #progress_metric: host=algo-1, completed 79 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:16 INFO 140645276194624] #quality_metric: host=algo-1, epoch=316, train loss <loss>=2.28625093807\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:16 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:16 INFO 140645276194624] Epoch[317] Batch[0] avg_epoch_loss=2.416731\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:16 INFO 140645276194624] #quality_metric: host=algo-1, epoch=317, batch=0 train loss <loss>=2.41673135757\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:17 INFO 140645276194624] Epoch[317] Batch[5] avg_epoch_loss=2.362866\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:17 INFO 140645276194624] #quality_metric: host=algo-1, epoch=317, batch=5 train loss <loss>=2.36286616325\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:17 INFO 140645276194624] Epoch[317] Batch [5]#011Speed: 1642.32 samples/sec#011loss=2.362866\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:17 INFO 140645276194624] processed a total of 600 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 574.0609169006348, \"sum\": 574.0609169006348, \"min\": 574.0609169006348}}, \"EndTime\": 1589566217.203802, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566216.629325}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:17 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1044.97605748 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:17 INFO 140645276194624] #progress_metric: host=algo-1, completed 79 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:17 INFO 140645276194624] #quality_metric: host=algo-1, epoch=317, train loss <loss>=2.32820363045\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:17 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:17 INFO 140645276194624] Epoch[318] Batch[0] avg_epoch_loss=2.319469\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:17 INFO 140645276194624] #quality_metric: host=algo-1, epoch=318, batch=0 train loss <loss>=2.31946897507\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:17 INFO 140645276194624] Epoch[318] Batch[5] avg_epoch_loss=2.314474\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:17 INFO 140645276194624] #quality_metric: host=algo-1, epoch=318, batch=5 train loss <loss>=2.31447426478\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:17 INFO 140645276194624] Epoch[318] Batch [5]#011Speed: 1899.41 samples/sec#011loss=2.314474\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:17 INFO 140645276194624] processed a total of 629 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 579.1680812835693, \"sum\": 579.1680812835693, \"min\": 579.1680812835693}}, \"EndTime\": 1589566217.783497, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566217.203882}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:17 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1085.82327726 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:17 INFO 140645276194624] #progress_metric: host=algo-1, completed 79 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:17 INFO 140645276194624] #quality_metric: host=algo-1, epoch=318, train loss <loss>=2.28049345016\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:17 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:18 INFO 140645276194624] Epoch[319] Batch[0] avg_epoch_loss=2.269059\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:18 INFO 140645276194624] #quality_metric: host=algo-1, epoch=319, batch=0 train loss <loss>=2.26905941963\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:18 INFO 140645276194624] Epoch[319] Batch[5] avg_epoch_loss=2.248544\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:18 INFO 140645276194624] #quality_metric: host=algo-1, epoch=319, batch=5 train loss <loss>=2.24854433537\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:18 INFO 140645276194624] Epoch[319] Batch [5]#011Speed: 1681.64 samples/sec#011loss=2.248544\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:18 INFO 140645276194624] processed a total of 635 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 611.8021011352539, \"sum\": 611.8021011352539, \"min\": 611.8021011352539}}, \"EndTime\": 1589566218.395832, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566217.783577}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:18 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1037.717148 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:18 INFO 140645276194624] #progress_metric: host=algo-1, completed 80 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:18 INFO 140645276194624] #quality_metric: host=algo-1, epoch=319, train loss <loss>=2.27229931355\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:18 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:18 INFO 140645276194624] Epoch[320] Batch[0] avg_epoch_loss=2.315330\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:18 INFO 140645276194624] #quality_metric: host=algo-1, epoch=320, batch=0 train loss <loss>=2.31532979012\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:18 INFO 140645276194624] Epoch[320] Batch[5] avg_epoch_loss=2.315683\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:18 INFO 140645276194624] #quality_metric: host=algo-1, epoch=320, batch=5 train loss <loss>=2.31568308671\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:18 INFO 140645276194624] Epoch[320] Batch [5]#011Speed: 1800.22 samples/sec#011loss=2.315683\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:18 INFO 140645276194624] processed a total of 624 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 561.9149208068848, \"sum\": 561.9149208068848, \"min\": 561.9149208068848}}, \"EndTime\": 1589566218.958294, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566218.395912}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:18 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1110.26133701 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:18 INFO 140645276194624] #progress_metric: host=algo-1, completed 80 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:18 INFO 140645276194624] #quality_metric: host=algo-1, epoch=320, train loss <loss>=2.29973738194\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:18 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:19 INFO 140645276194624] Epoch[321] Batch[0] avg_epoch_loss=2.240687\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:19 INFO 140645276194624] #quality_metric: host=algo-1, epoch=321, batch=0 train loss <loss>=2.24068665504\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:19 INFO 140645276194624] Epoch[321] Batch[5] avg_epoch_loss=2.275508\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:19 INFO 140645276194624] #quality_metric: host=algo-1, epoch=321, batch=5 train loss <loss>=2.2755082051\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:19 INFO 140645276194624] Epoch[321] Batch [5]#011Speed: 1954.87 samples/sec#011loss=2.275508\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:19 INFO 140645276194624] Epoch[321] Batch[10] avg_epoch_loss=2.285046\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:19 INFO 140645276194624] #quality_metric: host=algo-1, epoch=321, batch=10 train loss <loss>=2.29649176598\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:19 INFO 140645276194624] Epoch[321] Batch [10]#011Speed: 1760.16 samples/sec#011loss=2.296492\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:19 INFO 140645276194624] processed a total of 665 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 582.7770233154297, \"sum\": 582.7770233154297, \"min\": 582.7770233154297}}, \"EndTime\": 1589566219.541573, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566218.958371}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:19 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1140.87865926 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:19 INFO 140645276194624] #progress_metric: host=algo-1, completed 80 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:19 INFO 140645276194624] #quality_metric: host=algo-1, epoch=321, train loss <loss>=2.28504618731\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:19 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:19 INFO 140645276194624] Epoch[322] Batch[0] avg_epoch_loss=2.295377\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:19 INFO 140645276194624] #quality_metric: host=algo-1, epoch=322, batch=0 train loss <loss>=2.29537677765\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:19 INFO 140645276194624] Epoch[322] Batch[5] avg_epoch_loss=2.277626\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:19 INFO 140645276194624] #quality_metric: host=algo-1, epoch=322, batch=5 train loss <loss>=2.27762575944\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:19 INFO 140645276194624] Epoch[322] Batch [5]#011Speed: 1500.32 samples/sec#011loss=2.277626\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:20 INFO 140645276194624] Epoch[322] Batch[10] avg_epoch_loss=2.270546\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:20 INFO 140645276194624] #quality_metric: host=algo-1, epoch=322, batch=10 train loss <loss>=2.26205096245\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:20 INFO 140645276194624] Epoch[322] Batch [10]#011Speed: 1518.60 samples/sec#011loss=2.262051\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:20 INFO 140645276194624] processed a total of 655 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 662.9831790924072, \"sum\": 662.9831790924072, \"min\": 662.9831790924072}}, \"EndTime\": 1589566220.205057, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566219.541645}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:20 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=987.813055186 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:20 INFO 140645276194624] #progress_metric: host=algo-1, completed 80 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:20 INFO 140645276194624] #quality_metric: host=algo-1, epoch=322, train loss <loss>=2.27054630626\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:20 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:20 INFO 140645276194624] Epoch[323] Batch[0] avg_epoch_loss=2.278805\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:20 INFO 140645276194624] #quality_metric: host=algo-1, epoch=323, batch=0 train loss <loss>=2.27880477905\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:20 INFO 140645276194624] Epoch[323] Batch[5] avg_epoch_loss=2.284402\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:20 INFO 140645276194624] #quality_metric: host=algo-1, epoch=323, batch=5 train loss <loss>=2.28440217177\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:20 INFO 140645276194624] Epoch[323] Batch [5]#011Speed: 1853.52 samples/sec#011loss=2.284402\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:20 INFO 140645276194624] Epoch[323] Batch[10] avg_epoch_loss=2.249993\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:20 INFO 140645276194624] #quality_metric: host=algo-1, epoch=323, batch=10 train loss <loss>=2.20870223045\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:20 INFO 140645276194624] Epoch[323] Batch [10]#011Speed: 1737.42 samples/sec#011loss=2.208702\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:20 INFO 140645276194624] processed a total of 642 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 600.6917953491211, \"sum\": 600.6917953491211, \"min\": 600.6917953491211}}, \"EndTime\": 1589566220.806277, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566220.205118}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:20 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1068.54293984 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:20 INFO 140645276194624] #progress_metric: host=algo-1, completed 81 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:20 INFO 140645276194624] #quality_metric: host=algo-1, epoch=323, train loss <loss>=2.24999310754\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:20 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:21 INFO 140645276194624] Epoch[324] Batch[0] avg_epoch_loss=2.684105\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:21 INFO 140645276194624] #quality_metric: host=algo-1, epoch=324, batch=0 train loss <loss>=2.68410539627\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:21 INFO 140645276194624] Epoch[324] Batch[5] avg_epoch_loss=2.403114\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:21 INFO 140645276194624] #quality_metric: host=algo-1, epoch=324, batch=5 train loss <loss>=2.40311419964\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:21 INFO 140645276194624] Epoch[324] Batch [5]#011Speed: 1990.32 samples/sec#011loss=2.403114\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:21 INFO 140645276194624] processed a total of 639 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 529.5979976654053, \"sum\": 529.5979976654053, \"min\": 529.5979976654053}}, \"EndTime\": 1589566221.336406, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566220.806361}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:21 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1206.33823341 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:21 INFO 140645276194624] #progress_metric: host=algo-1, completed 81 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:21 INFO 140645276194624] #quality_metric: host=algo-1, epoch=324, train loss <loss>=2.37012214661\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:21 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:21 INFO 140645276194624] Epoch[325] Batch[0] avg_epoch_loss=2.242234\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:21 INFO 140645276194624] #quality_metric: host=algo-1, epoch=325, batch=0 train loss <loss>=2.2422337532\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:21 INFO 140645276194624] Epoch[325] Batch[5] avg_epoch_loss=2.267816\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:21 INFO 140645276194624] #quality_metric: host=algo-1, epoch=325, batch=5 train loss <loss>=2.26781630516\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:21 INFO 140645276194624] Epoch[325] Batch [5]#011Speed: 1845.40 samples/sec#011loss=2.267816\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:21 INFO 140645276194624] processed a total of 628 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 552.1621704101562, \"sum\": 552.1621704101562, \"min\": 552.1621704101562}}, \"EndTime\": 1589566221.889114, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566221.336471}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:21 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1137.10643552 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:21 INFO 140645276194624] #progress_metric: host=algo-1, completed 81 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:21 INFO 140645276194624] #quality_metric: host=algo-1, epoch=325, train loss <loss>=2.29270484447\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:21 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:22 INFO 140645276194624] Epoch[326] Batch[0] avg_epoch_loss=2.303984\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:22 INFO 140645276194624] #quality_metric: host=algo-1, epoch=326, batch=0 train loss <loss>=2.30398392677\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:22 INFO 140645276194624] Epoch[326] Batch[5] avg_epoch_loss=2.312539\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:22 INFO 140645276194624] #quality_metric: host=algo-1, epoch=326, batch=5 train loss <loss>=2.31253874302\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:22 INFO 140645276194624] Epoch[326] Batch [5]#011Speed: 1979.94 samples/sec#011loss=2.312539\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:22 INFO 140645276194624] Epoch[326] Batch[10] avg_epoch_loss=2.273540\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:22 INFO 140645276194624] #quality_metric: host=algo-1, epoch=326, batch=10 train loss <loss>=2.22674183846\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:22 INFO 140645276194624] Epoch[326] Batch [10]#011Speed: 1825.00 samples/sec#011loss=2.226742\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:22 INFO 140645276194624] processed a total of 661 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 597.9580879211426, \"sum\": 597.9580879211426, \"min\": 597.9580879211426}}, \"EndTime\": 1589566222.487595, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566221.889194}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:22 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1105.22373243 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:22 INFO 140645276194624] #progress_metric: host=algo-1, completed 81 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:22 INFO 140645276194624] #quality_metric: host=algo-1, epoch=326, train loss <loss>=2.27354015004\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:22 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:22 INFO 140645276194624] Epoch[327] Batch[0] avg_epoch_loss=2.248636\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:22 INFO 140645276194624] #quality_metric: host=algo-1, epoch=327, batch=0 train loss <loss>=2.24863576889\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:22 INFO 140645276194624] Epoch[327] Batch[5] avg_epoch_loss=2.368820\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:22 INFO 140645276194624] #quality_metric: host=algo-1, epoch=327, batch=5 train loss <loss>=2.36882019043\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:22 INFO 140645276194624] Epoch[327] Batch [5]#011Speed: 1862.24 samples/sec#011loss=2.368820\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:23 INFO 140645276194624] processed a total of 632 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 550.6739616394043, \"sum\": 550.6739616394043, \"min\": 550.6739616394043}}, \"EndTime\": 1589566223.038763, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566222.48767}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:23 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1147.4386416 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:23 INFO 140645276194624] #progress_metric: host=algo-1, completed 82 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:23 INFO 140645276194624] #quality_metric: host=algo-1, epoch=327, train loss <loss>=2.34624853134\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:23 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:23 INFO 140645276194624] Epoch[328] Batch[0] avg_epoch_loss=2.361484\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:23 INFO 140645276194624] #quality_metric: host=algo-1, epoch=328, batch=0 train loss <loss>=2.36148357391\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:23 INFO 140645276194624] Epoch[328] Batch[5] avg_epoch_loss=2.330512\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:23 INFO 140645276194624] #quality_metric: host=algo-1, epoch=328, batch=5 train loss <loss>=2.33051232497\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:23 INFO 140645276194624] Epoch[328] Batch [5]#011Speed: 1699.50 samples/sec#011loss=2.330512\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:23 INFO 140645276194624] processed a total of 640 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 581.1290740966797, \"sum\": 581.1290740966797, \"min\": 581.1290740966797}}, \"EndTime\": 1589566223.620453, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566223.038845}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:23 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1101.08484371 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:23 INFO 140645276194624] #progress_metric: host=algo-1, completed 82 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:23 INFO 140645276194624] #quality_metric: host=algo-1, epoch=328, train loss <loss>=2.32862536907\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:23 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:23 INFO 140645276194624] Epoch[329] Batch[0] avg_epoch_loss=2.295224\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:23 INFO 140645276194624] #quality_metric: host=algo-1, epoch=329, batch=0 train loss <loss>=2.29522418976\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:24 INFO 140645276194624] Epoch[329] Batch[5] avg_epoch_loss=2.327830\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:24 INFO 140645276194624] #quality_metric: host=algo-1, epoch=329, batch=5 train loss <loss>=2.32782987754\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:24 INFO 140645276194624] Epoch[329] Batch [5]#011Speed: 1981.52 samples/sec#011loss=2.327830\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:24 INFO 140645276194624] Epoch[329] Batch[10] avg_epoch_loss=2.310236\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:24 INFO 140645276194624] #quality_metric: host=algo-1, epoch=329, batch=10 train loss <loss>=2.2891222477\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:24 INFO 140645276194624] Epoch[329] Batch [10]#011Speed: 1928.36 samples/sec#011loss=2.289122\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:24 INFO 140645276194624] processed a total of 674 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 578.0510902404785, \"sum\": 578.0510902404785, \"min\": 578.0510902404785}}, \"EndTime\": 1589566224.199022, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566223.620533}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:24 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1165.76524289 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:24 INFO 140645276194624] #progress_metric: host=algo-1, completed 82 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:24 INFO 140645276194624] #quality_metric: host=algo-1, epoch=329, train loss <loss>=2.31023550034\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:24 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:24 INFO 140645276194624] Epoch[330] Batch[0] avg_epoch_loss=2.484851\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:24 INFO 140645276194624] #quality_metric: host=algo-1, epoch=330, batch=0 train loss <loss>=2.4848511219\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:24 INFO 140645276194624] Epoch[330] Batch[5] avg_epoch_loss=2.280748\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:24 INFO 140645276194624] #quality_metric: host=algo-1, epoch=330, batch=5 train loss <loss>=2.28074808915\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:24 INFO 140645276194624] Epoch[330] Batch [5]#011Speed: 1726.12 samples/sec#011loss=2.280748\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:24 INFO 140645276194624] processed a total of 627 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 595.1519012451172, \"sum\": 595.1519012451172, \"min\": 595.1519012451172}}, \"EndTime\": 1589566224.794713, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566224.199097}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:24 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1053.30326537 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:24 INFO 140645276194624] #progress_metric: host=algo-1, completed 82 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:24 INFO 140645276194624] #quality_metric: host=algo-1, epoch=330, train loss <loss>=2.2457934618\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:24 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:25 INFO 140645276194624] Epoch[331] Batch[0] avg_epoch_loss=2.408430\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:25 INFO 140645276194624] #quality_metric: host=algo-1, epoch=331, batch=0 train loss <loss>=2.40842962265\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:25 INFO 140645276194624] Epoch[331] Batch[5] avg_epoch_loss=2.312332\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:25 INFO 140645276194624] #quality_metric: host=algo-1, epoch=331, batch=5 train loss <loss>=2.31233211358\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:25 INFO 140645276194624] Epoch[331] Batch [5]#011Speed: 2015.82 samples/sec#011loss=2.312332\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:25 INFO 140645276194624] Epoch[331] Batch[10] avg_epoch_loss=2.287211\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:25 INFO 140645276194624] #quality_metric: host=algo-1, epoch=331, batch=10 train loss <loss>=2.2570659399\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:25 INFO 140645276194624] Epoch[331] Batch [10]#011Speed: 1844.54 samples/sec#011loss=2.257066\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:25 INFO 140645276194624] processed a total of 647 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 564.6860599517822, \"sum\": 564.6860599517822, \"min\": 564.6860599517822}}, \"EndTime\": 1589566225.359993, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566224.794794}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:25 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1145.55270202 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:25 INFO 140645276194624] #progress_metric: host=algo-1, completed 83 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:25 INFO 140645276194624] #quality_metric: host=algo-1, epoch=331, train loss <loss>=2.28721112555\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:25 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:25 INFO 140645276194624] Epoch[332] Batch[0] avg_epoch_loss=2.339441\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:25 INFO 140645276194624] #quality_metric: host=algo-1, epoch=332, batch=0 train loss <loss>=2.3394408226\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:25 INFO 140645276194624] Epoch[332] Batch[5] avg_epoch_loss=2.265600\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:25 INFO 140645276194624] #quality_metric: host=algo-1, epoch=332, batch=5 train loss <loss>=2.26560028394\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:25 INFO 140645276194624] Epoch[332] Batch [5]#011Speed: 2014.97 samples/sec#011loss=2.265600\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:25 INFO 140645276194624] processed a total of 638 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 580.2888870239258, \"sum\": 580.2888870239258, \"min\": 580.2888870239258}}, \"EndTime\": 1589566225.940909, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566225.360066}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:25 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1099.22115001 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:25 INFO 140645276194624] #progress_metric: host=algo-1, completed 83 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:25 INFO 140645276194624] #quality_metric: host=algo-1, epoch=332, train loss <loss>=2.2865531683\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:25 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:26 INFO 140645276194624] Epoch[333] Batch[0] avg_epoch_loss=2.320920\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:26 INFO 140645276194624] #quality_metric: host=algo-1, epoch=333, batch=0 train loss <loss>=2.32092046738\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:26 INFO 140645276194624] Epoch[333] Batch[5] avg_epoch_loss=2.313989\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:26 INFO 140645276194624] #quality_metric: host=algo-1, epoch=333, batch=5 train loss <loss>=2.31398916245\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:26 INFO 140645276194624] Epoch[333] Batch [5]#011Speed: 1861.36 samples/sec#011loss=2.313989\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:26 INFO 140645276194624] processed a total of 605 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 537.161111831665, \"sum\": 537.161111831665, \"min\": 537.161111831665}}, \"EndTime\": 1589566226.478623, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566225.940992}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:26 INFO 140645276194624] #throughput_metric: host=algo-1, train throughput=1126.04860965 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:26 INFO 140645276194624] #progress_metric: host=algo-1, completed 83 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:26 INFO 140645276194624] #quality_metric: host=algo-1, epoch=333, train loss <loss>=2.29204866886\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:26 INFO 140645276194624] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:26 INFO 140645276194624] Loading parameters from best epoch (293)\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.deserialize.time\": {\"count\": 1, \"max\": 7.957220077514648, \"sum\": 7.957220077514648, \"min\": 7.957220077514648}}, \"EndTime\": 1589566226.487223, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566226.478703}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:26 INFO 140645276194624] stopping training now\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:26 INFO 140645276194624] #progress_metric: host=algo-1, completed 100 % of epochs\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:26 INFO 140645276194624] Final loss: 2.1844761014 (occurred at epoch 293)\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:26 INFO 140645276194624] #quality_metric: host=algo-1, train final_loss <loss>=2.1844761014\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:26 INFO 140645276194624] Worker algo-1 finished training.\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:26 WARNING 140645276194624] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:26 INFO 140645276194624] All workers finished. Serializing model for prediction.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"get_graph.time\": {\"count\": 1, \"max\": 114.55488204956055, \"sum\": 114.55488204956055, \"min\": 114.55488204956055}}, \"EndTime\": 1589566226.602519, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566226.487295}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:26 INFO 140645276194624] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"finalize.time\": {\"count\": 1, \"max\": 152.19712257385254, \"sum\": 152.19712257385254, \"min\": 152.19712257385254}}, \"EndTime\": 1589566226.640117, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566226.602589}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:26 INFO 140645276194624] Serializing to /opt/ml/model/model_algo-1\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:26 INFO 140645276194624] Saved checkpoint to \"/opt/ml/model/model_algo-1-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.serialize.time\": {\"count\": 1, \"max\": 6.437063217163086, \"sum\": 6.437063217163086, \"min\": 6.437063217163086}}, \"EndTime\": 1589566226.646659, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566226.640177}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:26 INFO 140645276194624] Successfully serialized the model for prediction.\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:26 INFO 140645276194624] Evaluating model accuracy on testset using 100 samples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.bind.time\": {\"count\": 1, \"max\": 0.026941299438476562, \"sum\": 0.026941299438476562, \"min\": 0.026941299438476562}}, \"EndTime\": 1589566226.647401, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566226.646706}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.score.time\": {\"count\": 1, \"max\": 548.4559535980225, \"sum\": 548.4559535980225, \"min\": 548.4559535980225}}, \"EndTime\": 1589566227.195827, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566226.647461}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:27 INFO 140645276194624] #test_score (algo-1, RMSE): 0.926431946489\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:27 INFO 140645276194624] #test_score (algo-1, mean_absolute_QuantileLoss): 56.26304253472222\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:27 INFO 140645276194624] #test_score (algo-1, mean_wQuantileLoss): 0.003541014592208744\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:27 INFO 140645276194624] #test_score (algo-1, wQuantileLoss[0.1]): 0.002239961745317971\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:27 INFO 140645276194624] #test_score (algo-1, wQuantileLoss[0.2]): 0.0031760704445696632\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:27 INFO 140645276194624] #test_score (algo-1, wQuantileLoss[0.3]): 0.00348162362104537\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:27 INFO 140645276194624] #test_score (algo-1, wQuantileLoss[0.4]): 0.0035813995793315618\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:27 INFO 140645276194624] #test_score (algo-1, wQuantileLoss[0.5]): 0.003923801155799501\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:27 INFO 140645276194624] #test_score (algo-1, wQuantileLoss[0.6]): 0.004125766212243465\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:27 INFO 140645276194624] #test_score (algo-1, wQuantileLoss[0.7]): 0.0041683071177684786\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:27 INFO 140645276194624] #test_score (algo-1, wQuantileLoss[0.8]): 0.004071382598079345\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:27 INFO 140645276194624] #test_score (algo-1, wQuantileLoss[0.9]): 0.003100818855723337\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:27 INFO 140645276194624] #quality_metric: host=algo-1, test mean_wQuantileLoss <loss>=0.00354101459221\u001b[0m\n",
      "\u001b[34m[05/15/2020 18:10:27 INFO 140645276194624] #quality_metric: host=algo-1, test RMSE <loss>=0.926431946489\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"totaltime\": {\"count\": 1, \"max\": 190844.2940711975, \"sum\": 190844.2940711975, \"min\": 190844.2940711975}, \"setuptime\": {\"count\": 1, \"max\": 10.445117950439453, \"sum\": 10.445117950439453, \"min\": 10.445117950439453}}, \"EndTime\": 1589566227.206681, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589566227.195893}\n",
      "\u001b[0m\n",
      "\n",
      "2020-05-15 18:10:37 Uploading - Uploading generated training model\n",
      "2020-05-15 18:10:37 Completed - Training job completed\n",
      "Training seconds: 254\n",
      "Billable seconds: 254\n",
      "CPU times: user 1.22 s, sys: 215 ms, total: 1.44 s\n",
      "Wall time: 6min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data_channels = {\n",
    "    \"train\": \"{}/train/\".format(s3_data_path),\n",
    "    \"test\": \"{}/test/\".format(s3_data_path)\n",
    "}\n",
    "\n",
    "estimator.fit(inputs=data_channels, wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prior to deployment we need to create a class that handles I/O with the following functions: \n",
    "\n",
    "* set_prediction_parameters() - set frequency of incoming data and length to predict\n",
    "* __encode_request() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def series_to_obj(ts, cat=None, dynamic_feat=None):\n",
    "    obj = {\"start\": str(ts.index[0]), \"target\": list(ts)}\n",
    "    if cat is not None:\n",
    "        obj[\"cat\"] = cat\n",
    "    if dynamic_feat is not None:\n",
    "        obj[\"dynamic_feat\"] = dynamic_feat \n",
    "    return obj\n",
    "\n",
    "class DeepARPredictor(sagemaker.predictor.RealTimePredictor):\n",
    "\n",
    "    def set_prediction_parameters(self, freq, prediction_length):\n",
    "        self.freq = freq\n",
    "        self.prediction_length = prediction_length\n",
    "        \n",
    "    def predict(self, ts, cat=None, encoding=\"utf-8\", num_samples=test_rows, quantiles=[\"0.1\", \"0.5\", \"0.9\"]):\n",
    "        prediction_times = [x.index[-1]+1 for x in ts]\n",
    "        req = self.__encode_request(ts, cat, encoding, num_samples, quantiles)\n",
    "        res = super(DeepARPredictor, self).predict(req)\n",
    "        return self.__decode_response(res, prediction_times, encoding)\n",
    "    \n",
    "    def __encode_request(self, ts, cat, encoding, num_samples, quantiles):\n",
    "        instances = [series_to_obj(ts[k], cat[k] if cat else None) for k in range(len(ts))]\n",
    "        configuration = {\"num_samples\": num_samples, \"output_types\": [\"quantiles\"], \"quantiles\": quantiles}\n",
    "        http_request_data = {\"instances\": instances, \"configuration\": configuration}\n",
    "        return json.dumps(http_request_data).encode(encoding)\n",
    "    \n",
    "    def __decode_response(self, response, prediction_times, encoding):\n",
    "        response_data = json.loads(response.decode(encoding))\n",
    "        list_of_df = []\n",
    "        for k in range(len(prediction_times)):\n",
    "            prediction_index = pd.DatetimeIndex(start=prediction_times[k], freq=self.freq, periods=self.prediction_length)\n",
    "            list_of_df.append(pd.DataFrame(data=response_data['predictions'][k]['quantiles'], index=prediction_index))\n",
    "        return list_of_df\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------"
     ]
    }
   ],
   "source": [
    "predictor = estimator.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.m4.xlarge',\n",
    "    predictor_cls=DeepARPredictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = symbol.Close\n",
    "test_data1 = symbol1.Close\n",
    "test_data2 = symbol2.Close\n",
    "test_data3 = symbol3.Close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_portfolio = [test_data, test_data1, test_data2, test_data3 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(test_portfolio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.predict(ts=test_data_array, quantiles=[0.10, 0.5, 0.90])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
